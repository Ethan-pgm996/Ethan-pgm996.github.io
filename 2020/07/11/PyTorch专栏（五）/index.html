<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>PyTorch专栏（五） | 艾利克斯工作室</title><meta name="description" content="前言本篇文章讲解了PyTorch专栏的第四章中的迁移学习。查看专栏历史文章，请点击下方推荐链接进入相应链接阅读。查看关于本专栏的介绍：PyTorch专栏开篇。 PyTorch之迁移学习实际中，基本没有人会从零开始（随机初始化）训练一个完整的卷积网络，因为相对于网络，很难得到一个足够大的数据集[网络很深, 需要足够大数据集]。通常的做法是在一个很大的数据集上进行预训练得到卷积网络ConvNet, 然"><meta name="keywords" content="Python深度学习"><meta name="author" content="Alexis (KangJ)"><meta name="copyright" content="Alexis (KangJ)"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://programmer996.club/2020/07/11/PyTorch%E4%B8%93%E6%A0%8F%EF%BC%88%E4%BA%94%EF%BC%89/"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta property="og:type" content="article"><meta property="og:title" content="PyTorch专栏（五）"><meta property="og:url" content="https://programmer996.club/2020/07/11/PyTorch%E4%B8%93%E6%A0%8F%EF%BC%88%E4%BA%94%EF%BC%89/"><meta property="og:site_name" content="艾利克斯工作室"><meta property="og:description" content="前言本篇文章讲解了PyTorch专栏的第四章中的迁移学习。查看专栏历史文章，请点击下方推荐链接进入相应链接阅读。查看关于本专栏的介绍：PyTorch专栏开篇。 PyTorch之迁移学习实际中，基本没有人会从零开始（随机初始化）训练一个完整的卷积网络，因为相对于网络，很难得到一个足够大的数据集[网络很深, 需要足够大数据集]。通常的做法是在一个很大的数据集上进行预训练得到卷积网络ConvNet, 然"><meta property="og:image" content="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg"><meta property="article:published_time" content="2020-07-10T23:43:49.000Z"><meta property="article:modified_time" content="2020-07-11T00:40:04.251Z"><meta name="twitter:card" content="summary"><script>var activateDarkMode = function () {
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#000')
  }
}
var activateLightMode = function () {
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#fff')
  }
}

var getCookies = function (name) {
  const value = `; ${document.cookie}`
  const parts = value.split(`; ${name}=`)
  if (parts.length === 2) return parts.pop().split(';').shift()
}

var autoChangeMode = 'false'
var t = getCookies('theme')
if (autoChangeMode === '1') {
  var isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
  var isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
  var isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined) {
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport) {
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour <= 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
    }
    window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
      if (Cookies.get('theme') === undefined) {
        e.matches ? activateDarkMode() : activateLightMode()
      }
    })
  } else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else if (autoChangeMode === '2') {
  now = new Date()
  hour = now.getHours()
  isNight = hour <= 6 || hour >= 18
  if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else {
  if (t === 'dark') activateDarkMode()
  else if (t === 'light') activateLightMode()
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css"><link rel="next" title="PyTorch专栏（四）" href="https://programmer996.club/2020/07/10/PyTorch%E4%B8%93%E6%A0%8F%EF%BC%88%E5%9B%9B%EF%BC%89/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  bookmark: {
    message_prev: 'Press',
    message_next: 'to bookmark this page'
  },
  runtime_unit: 'days',
  runtime: false,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: {"bookmark":{"message_prev":"Press","message_next":"to bookmark this page"},"chs_to_cht":"Traditional Chinese Activated Manually","cht_to_chs":"Simplified Chinese Activated Manually","day_to_night":"Dark Mode Activated Manually","night_to_day":"Light Mode Activated Manually","bgLight":"#49b1f5","bgDark":"#121212","position":"bottom-left"},
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  isPhotoFigcaption: false,
  islazyload: true,
  isanchor: false    
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: true,
  isSidebar: true,
  postUpdate: '2020-07-11 08:40:04'
}</script><noscript><style>
#nav {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 4.2.1"><link rel="alternate" href="/atom.xml" title="艾利克斯工作室" type="application/atom+xml">
</head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">Loading...</div></div></div><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">Articles</div><div class="length_num">44</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">Tags</div><div class="length_num">9</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">Categories</div><div class="length_num">16</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down menus-expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/welfare/"><i class="fa-fw fas fa-gift"></i><span> Welfare</span></a></li><li><a class="site-page" href="/Case/"><i class="fa-fw fas fa-briefcase"></i><span> Case</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page" href="/Cooperation/"><i class="fa-fw fas fa-briefcase"></i><span> Cooperation</span></a></div><div class="menus_item"><a class="site-page" href="/handshake/"><i class="fa-fw fas fa-eye"></i><span> handshake</span></a></div></div></div></div><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#前言"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#PyTorch之迁移学习"><span class="toc-number">2.</span> <span class="toc-text">PyTorch之迁移学习</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#转移学习的两个主要场景："><span class="toc-number">3.</span> <span class="toc-text">转移学习的两个主要场景：</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#导入相关的包"><span class="toc-number">4.</span> <span class="toc-text">导入相关的包</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#加载数据"><span class="toc-number">5.</span> <span class="toc-text">加载数据</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#可视化部分图像数据"><span class="toc-number">6.</span> <span class="toc-text">可视化部分图像数据</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#训练模型"><span class="toc-number">7.</span> <span class="toc-text">训练模型</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#可视化模型的预测结果"><span class="toc-number">8.</span> <span class="toc-text">可视化模型的预测结果</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#场景1：微调ConvNet"><span class="toc-number">9.</span> <span class="toc-text">场景1：微调ConvNet</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#训练和评估模型"><span class="toc-number">10.</span> <span class="toc-text">训练和评估模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Epoch-1-24"><span class="toc-number">10.1.</span> <span class="toc-text">Epoch 1&#x2F;24</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Parameters-of-newly-constructed-modules-have-requires-grad-True-by-default"><span class="toc-number">11.</span> <span class="toc-text">Parameters of newly constructed modules have requires_grad&#x3D;True by default</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Observe-that-only-parameters-of-final-layer-are-being-optimized-as"><span class="toc-number">12.</span> <span class="toc-text">Observe that only parameters of final layer are being optimized as</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#opposed-to-before"><span class="toc-number">13.</span> <span class="toc-text">opposed to before.</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Decay-LR-by-a-factor-of-0-1-every-7-epochs"><span class="toc-number">14.</span> <span class="toc-text">Decay LR by a factor of 0.1 every 7 epochs</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Epoch-0-24"><span class="toc-number">14.1.</span> <span class="toc-text">Epoch 0&#x2F;24</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Epoch-24-24"><span class="toc-number">14.2.</span> <span class="toc-text">Epoch 24&#x2F;24</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#学习交流"><span class="toc-number">15.</span> <span class="toc-text">学习交流</span></a></li></ol></div></div></div><div class="code-close" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg)"><nav id="nav"><span class="pull-left" id="blog_name"><a class="blog_title" id="site-name" href="/">艾利克斯工作室</a></span><span class="pull-right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down menus-expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/welfare/"><i class="fa-fw fas fa-gift"></i><span> Welfare</span></a></li><li><a class="site-page" href="/Case/"><i class="fa-fw fas fa-briefcase"></i><span> Case</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page" href="/Cooperation/"><i class="fa-fw fas fa-briefcase"></i><span> Cooperation</span></a></div><div class="menus_item"><a class="site-page" href="/handshake/"><i class="fa-fw fas fa-eye"></i><span> handshake</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">PyTorch专栏（五）</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="Created 2020-07-11 07:43:49"><i class="far fa-calendar-alt fa-fw"></i> Created 2020-07-11</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="Updated 2020-07-11 08:40:04"><i class="fas fa-history fa-fw"></i> Updated 2020-07-11</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fas fa-inbox fa-fw post-meta__icon"></i><a class="post-meta__categories" href="/categories/PyTorch%E4%B8%93%E6%A0%8F/">PyTorch专栏</a></span></div><div class="meta-secondline"> <span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta__icon"></i><span>Word count:</span><span class="word-count">1.9k</span><span class="post-meta__separator">|</span><i class="far fa-clock fa-fw post-meta__icon"></i><span>Reading time: 8 min</span></span></div><div class="meta-thirdline"><span class="post-meta-pv-cv"><span class="post-meta__separator">|</span><i class="far fa-eye fa-fw post-meta__icon"></i><span>Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>本篇文章讲解了PyTorch专栏的第四章中的迁移学习。查看专栏历史文章，请点击下方推荐链接进入相应链接阅读。查看关于本专栏的介绍：PyTorch专栏开篇。</p>
<h1 id="PyTorch之迁移学习"><a href="#PyTorch之迁移学习" class="headerlink" title="PyTorch之迁移学习"></a>PyTorch之迁移学习</h1><p>实际中，基本没有人会从零开始（随机初始化）训练一个完整的卷积网络，因为相对于网络，很难得到一个足够大的数据集[网络很深, 需要足够大数据集]。通常的做法是在一个很大的数据集上进行预训练得到卷积网络ConvNet, 然后将这个ConvNet的参数作为目标任务的初始化参数或者固定这些参数。</p>
<h1 id="转移学习的两个主要场景："><a href="#转移学习的两个主要场景：" class="headerlink" title="转移学习的两个主要场景："></a>转移学习的两个主要场景：</h1><ul>
<li>微调<strong>Convnet</strong>：使用预训练的网络(如在<code>imagenet 1000</code>上训练而来的网络)来初始化自己的网络，而不是随机初始化。其他的训练步骤不变。</li>
<li>将<strong>Convnet</strong>看成固定的特征提取器:首先固定ConvNet除了最后的全连接层外的其他所有层。最后的全连接层被替换成一个新的随机<br>初始化的层，只有这个新的层会被训练[只有这层参数会在反向传播时更新]</li>
</ul>
<p>下面是利用PyTorch进行迁移学习步骤，要解决的问题是训练一个模型来对蚂蚁和蜜蜂进行分类。</p>
<h1 id="导入相关的包"><a href="#导入相关的包" class="headerlink" title="导入相关的包"></a>导入相关的包</h1><pre><code># License: BSD
# Author: Sasank Chilamkurthy

from __future__ import print_function, division

import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
import numpy as np
import torchvision
from torchvision import datasets, models, transforms
import matplotlib.pyplot as plt
import time
import os
import copy

plt.ion()   # interactive mode</code></pre><h1 id="加载数据"><a href="#加载数据" class="headerlink" title="加载数据"></a>加载数据</h1><p>今天要解决的问题是训练一个模型来分类蚂蚁ants和蜜蜂bees。ants和bees各有约120张训练图片。每个类有75张验证图片。从零开始在<br>如此小的数据集上进行训练通常是很难泛化的。由于我们使用迁移学习，模型的泛化能力会相当好。<br>该数据集是imagenet的一个非常小的子集。从<a href="https://download.pytorch.org/tutorial/hymenoptera_data.zip" target="_blank" rel="noopener">此处</a>下载数据，并将其解压缩到当前目录。</p>
<pre><code>＃训练集数据扩充和归一化
＃在验证集上仅需要归一化
data_transforms = {
    &#39;train&#39;: transforms.Compose([
        transforms.RandomResizedCrop(224), #随机裁剪一个area然后再resize
        transforms.RandomHorizontalFlip(), #随机水平翻转
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    &#39;val&#39;: transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
}

data_dir = &#39;data/hymenoptera_data&#39;
image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),
                                          data_transforms[x])
                  for x in [&#39;train&#39;, &#39;val&#39;]}
dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,
                                             shuffle=True, num_workers=4)
              for x in [&#39;train&#39;, &#39;val&#39;]}
dataset_sizes = {x: len(image_datasets[x]) for x in [&#39;train&#39;, &#39;val&#39;]}
class_names = image_datasets[&#39;train&#39;].classes

device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</code></pre><h1 id="可视化部分图像数据"><a href="#可视化部分图像数据" class="headerlink" title="可视化部分图像数据"></a>可视化部分图像数据</h1><p>可视化部分训练图像，以便了解数据扩充。</p>
<pre><code>def imshow(inp, title=None):
    &quot;&quot;&quot;Imshow for Tensor.&quot;&quot;&quot;
    inp = inp.numpy().transpose((1, 2, 0))
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    inp = std * inp + mean
    inp = np.clip(inp, 0, 1)
    plt.imshow(inp)
    if title is not None:
        plt.title(title)
    plt.pause(0.001)  # pause a bit so that plots are updated


# 获取一批训练数据
inputs, classes = next(iter(dataloaders[&#39;train&#39;]))

# 批量制作网格
out = torchvision.utils.make_grid(inputs)

imshow(out, title=[class_names[x] for x in classes])</code></pre><img src= "/img/loading.gif" data-src="/images/p20.jpg">

<h1 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h1><p>编写一个通用函数来训练模型。下面将说明：</p>
<ul>
<li>调整学习速率</li>
<li>保存最好的模型</li>
</ul>
<p>下面的参数scheduler是一个来自 <code>torch.optim.lr_scheduler</code>的学习速率调整类的对象(LR scheduler object)。</p>
<pre><code>def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    since = time.time()

    best_model_wts = copy.deepcopy(model.state_dict())
    best_acc = 0.0

    for epoch in range(num_epochs):
        print(&#39;Epoch {}/{}&#39;.format(epoch, num_epochs - 1))
        print(&#39;-&#39; * 10)

        # 每个epoch都有一个训练和验证阶段
        for phase in [&#39;train&#39;, &#39;val&#39;]:
            if phase == &#39;train&#39;:
                scheduler.step()
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode

            running_loss = 0.0
            running_corrects = 0

            # 迭代数据.
            for inputs, labels in dataloaders[phase]:
                inputs = inputs.to(device)
                labels = labels.to(device)

                # 零参数梯度
                optimizer.zero_grad()

                # 前向
                # track history if only in train
                with torch.set_grad_enabled(phase == &#39;train&#39;):
                    outputs = model(inputs)
                    _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)

                    # 后向+仅在训练阶段进行优化
                    if phase == &#39;train&#39;:
                        loss.backward()
                        optimizer.step()

                # 统计
                running_loss += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels.data)

            epoch_loss = running_loss / dataset_sizes[phase]
            epoch_acc = running_corrects.double() / dataset_sizes[phase]

            print(&#39;{} Loss: {:.4f} Acc: {:.4f}&#39;.format(
                phase, epoch_loss, epoch_acc))

            # 深度复制mo
            if phase == &#39;val&#39; and epoch_acc &gt; best_acc:
                best_acc = epoch_acc
                best_model_wts = copy.deepcopy(model.state_dict())

        print()

    time_elapsed = time.time() - since
    print(&#39;Training complete in {:.0f}m {:.0f}s&#39;.format(
        time_elapsed // 60, time_elapsed % 60))
    print(&#39;Best val Acc: {:4f}&#39;.format(best_acc))

    # 加载最佳模型权重
    model.load_state_dict(best_model_wts)
    return model</code></pre><h1 id="可视化模型的预测结果"><a href="#可视化模型的预测结果" class="headerlink" title="可视化模型的预测结果"></a>可视化模型的预测结果</h1><pre><code>#一个通用的展示少量预测图片的函数
def visualize_model(model, num_images=6):
    was_training = model.training
    model.eval()
    images_so_far = 0
    fig = plt.figure()

    with torch.no_grad():
        for i, (inputs, labels) in enumerate(dataloaders[&#39;val&#39;]):
            inputs = inputs.to(device)
            labels = labels.to(device)

            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)

            for j in range(inputs.size()[0]):
                images_so_far += 1
                ax = plt.subplot(num_images//2, 2, images_so_far)
                ax.axis(&#39;off&#39;)
                ax.set_title(&#39;predicted: {}&#39;.format(class_names[preds[j]]))
                imshow(inputs.cpu().data[j])

                if images_so_far == num_images:
                    model.train(mode=was_training)
                    return
        model.train(mode=was_training)</code></pre><h1 id="场景1：微调ConvNet"><a href="#场景1：微调ConvNet" class="headerlink" title="场景1：微调ConvNet"></a>场景1：微调ConvNet</h1><p>加载预训练模型并重置最终完全连接的图层。</p>
<pre><code>model_ft = models.resnet18(pretrained=True)
num_ftrs = model_ft.fc.in_features
model_ft.fc = nn.Linear(num_ftrs, 2)

model_ft = model_ft.to(device)

criterion = nn.CrossEntropyLoss()

# 观察所有参数都正在优化
optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)

# 每7个epochs衰减LR通过设置gamma=0.1
exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)</code></pre><h1 id="训练和评估模型"><a href="#训练和评估模型" class="headerlink" title="训练和评估模型"></a>训练和评估模型</h1><p>（1）训练模型<br>该过程在CPU上需要大约15-25分钟，但是在GPU上，它只需不到一分钟。</p>
<pre><code>model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,
                       num_epochs=25)</code></pre><ul>
<li>输出<pre><code>Epoch 0/24</code></pre></li>
</ul>
<hr>
<p>train Loss: 0.7032 Acc: 0.6025<br>val Loss: 0.1698 Acc: 0.9412</p>
<h2 id="Epoch-1-24"><a href="#Epoch-1-24" class="headerlink" title="Epoch 1/24"></a>Epoch 1/24</h2><p>train Loss: 0.6411 Acc: 0.7787<br>val Loss: 0.1981 Acc: 0.9281<br>·<br>·<br>·<br>Epoch 24/24</p>
<hr>
<p>train Loss: 0.2812 Acc: 0.8730<br>val Loss: 0.2647 Acc: 0.9150</p>
<p>Training complete in 1m 7s<br>Best val Acc: 0.941176</p>
<pre><code>（2）模型评估效果可视化</code></pre><p>visualize_model(model_ft)</p>
<pre><code>* 输出
&lt;img src=&quot;/images/p21.jpg&quot;&gt;

# 场景2：ConvNet作为固定特征提取器
在这里需要冻结除最后一层之外的所有网络。通过设置`requires_grad == Falsebackward()`来冻结参数，这样在反向传播backward()的时候他们的梯度就不会被计算。</code></pre><p>model_conv = torchvision.models.resnet18(pretrained=True)<br>for param in model_conv.parameters():<br>    param.requires_grad = False</p>
<h1 id="Parameters-of-newly-constructed-modules-have-requires-grad-True-by-default"><a href="#Parameters-of-newly-constructed-modules-have-requires-grad-True-by-default" class="headerlink" title="Parameters of newly constructed modules have requires_grad=True by default"></a>Parameters of newly constructed modules have requires_grad=True by default</h1><p>num_ftrs = model_conv.fc.in_features<br>model_conv.fc = nn.Linear(num_ftrs, 2)</p>
<p>model_conv = model_conv.to(device)</p>
<p>criterion = nn.CrossEntropyLoss()</p>
<h1 id="Observe-that-only-parameters-of-final-layer-are-being-optimized-as"><a href="#Observe-that-only-parameters-of-final-layer-are-being-optimized-as" class="headerlink" title="Observe that only parameters of final layer are being optimized as"></a>Observe that only parameters of final layer are being optimized as</h1><h1 id="opposed-to-before"><a href="#opposed-to-before" class="headerlink" title="opposed to before."></a>opposed to before.</h1><p>optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)</p>
<h1 id="Decay-LR-by-a-factor-of-0-1-every-7-epochs"><a href="#Decay-LR-by-a-factor-of-0-1-every-7-epochs" class="headerlink" title="Decay LR by a factor of 0.1 every 7 epochs"></a>Decay LR by a factor of 0.1 every 7 epochs</h1><p>exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)</p>
<pre><code>## 训练和评估
（1）训练模型
在CPU上，与前一个场景相比，这将花费大约一半的时间，因为不需要为大多数网络计算梯度。但需要计算转发。</code></pre><p>model_conv = train_model(model_conv, criterion, optimizer_conv,<br>                         exp_lr_scheduler, num_epochs=25)</p>
<pre><code>* 输出</code></pre><h2 id="Epoch-0-24"><a href="#Epoch-0-24" class="headerlink" title="Epoch 0/24"></a>Epoch 0/24</h2><p>train Loss: 0.6400 Acc: 0.6434<br>val Loss: 0.2539 Acc: 0.9085<br>·<br>·<br>·<br>Epoch 23/24</p>
<hr>
<p>train Loss: 0.2988 Acc: 0.8607<br>val Loss: 0.2151 Acc: 0.9412</p>
<h2 id="Epoch-24-24"><a href="#Epoch-24-24" class="headerlink" title="Epoch 24/24"></a>Epoch 24/24</h2><p>train Loss: 0.3519 Acc: 0.8484<br>val Loss: 0.2045 Acc: 0.9412</p>
<p>Training complete in 0m 35s<br>Best val Acc: 0.954248</p>
<pre><code>（2）模型评估效果可视化</code></pre><p>visualize_model(model_conv)</p>
<p>plt.ioff()<br>plt.show()</p>
<p>```</p>
<ul>
<li>输出<img src= "/img/loading.gif" data-src="/images/p22.jpg">


</li>
</ul>
<h1 id="学习交流"><a href="#学习交流" class="headerlink" title="学习交流"></a>学习交流</h1><p>为了方便大家更好地与作者进行沟通交流，为此针对这个专栏成立了QQ读者交流群，大家想近距离与我沟通，都可以来加入。<br>扫描二维码进群可获得 自动微分 章节的Python 源代码和Jupyter 源代码链接<br>扫描二维码进群可获得 神经网络 章节的Python 源代码和Jupyter 源代码链接<br>加入方式：扫描下方QQ群二维码，即可加入交流群&lt;群满可在右下方在线与我沟通&gt;。</p>
<p align="left">
    <img src= "/img/loading.gif" data-src="/images/qun.jpg" alt="Sample" width="300" height="350">
    <!-- <img src= "/img/loading.gif" data-src="/images/TIM.jpg" alt="Sample"  width="300" height="250"> -->
</p></div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">Alexis (KangJ)</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://programmer996.club/2020/07/11/PyTorch%E4%B8%93%E6%A0%8F%EF%BC%88%E4%BA%94%EF%BC%89/">https://programmer996.club/2020/07/11/PyTorch%E4%B8%93%E6%A0%8F%EF%BC%88%E4%BA%94%EF%BC%89/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Python%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">Python深度学习</a></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" data-sites="wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><button class="reward-button" type="button"><i class="fas fa-qrcode"></i> Donate<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="post-qr-code__img" src="/images/pay.jpg" alt="wechat" onclick="window.open('/images/pay.jpg')"/><div class="post-qr-code__desc">wechat</div></li></ul></div></button></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2020/07/10/PyTorch%E4%B8%93%E6%A0%8F%EF%BC%88%E5%9B%9B%EF%BC%89/"><img class="next-cover" data-src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">PyTorch专栏（四）</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fas fa-thumbs-up fa-fw"></i><span> Related Articles</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2020/07/02/Pytorch专栏开篇/" title="PyTorch专栏开篇"><img class="relatedPosts_cover" data-src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2020-07-02</div><div class="relatedPosts_title">PyTorch专栏开篇</div></div></a></div><div class="relatedPosts_item"><a href="/2020/07/03/Pytorch专栏（一）/" title="Pytorch专栏（一）"><img class="relatedPosts_cover" data-src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2020-07-03</div><div class="relatedPosts_title">Pytorch专栏（一）</div></div></a></div><div class="relatedPosts_item"><a href="/2020/07/06/Pytorch专栏（二）/" title="Pytorch专栏（二）"><img class="relatedPosts_cover" data-src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2020-07-06</div><div class="relatedPosts_title">Pytorch专栏（二）</div></div></a></div></div></div></article></main><footer id="footer" style="background-image: url(https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg)" data-type="photo"><div id="footer-wrap"><div class="copyright">&copy;2018 - 2020 By Alexis (KangJ)</div><div class="framework-info"><span>Driven </span><a href="https://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div><div class="icp"><a href="http://www.beian.miit.gov.cn/state/outPortal/loginPortal.action" target="_blank" rel="noopener"><img class="icp-icon" src="/img/icp.png"/><span>晋ICP备19013202号</span></a></div></div></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="font_plus" type="button" title="Increase Font Size"><i class="fas fa-plus"></i></button><button id="font_minus" type="button" title="Decrease Font Size"><i class="fas fa-minus"></i></button><button id="translateLink" type="button" title="Switch Between Traditional Chinese And Simplified Chinese">繁</button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="chat_btn" type="button" title="rightside.chat_btn"><i class="fas fa-sms"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module" defer></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js" async></script><script>var endLoading = function () {
  document.body.style.overflow = 'auto';
  document.getElementById('loading-box').classList.add("loaded")
}
window.addEventListener('load',endLoading)</script><script>(function(d, w, c) {
    w.ChatraID = 'KNGoAf4sGNJs6n5zG';
    var s = d.createElement('script');
    w[c] = w[c] || function() {
        (w[c].q = w[c].q || []).push(arguments);
    };
    s.async = true;
    s.src = 'https://call.chatra.io/chatra.js';
    if (d.head) d.head.appendChild(s);
})(document, window, 'Chatra');

if (true) {
  var chatBtn = document.getElementById("chat_btn")
    chatBtn.addEventListener("click", function(){
      Chatra('openChat')
    });
} else {
  if (true) {
    function chatBtnHide () {
      Chatra('hide')
    }
    function chatBtnShow () {
      Chatra('show')
    }
  }
}</script></body></html>