<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Django-PYTHON Web框架</title>
    <url>/2020/03/21/Django-PYTHON-Web%E6%A1%86%E6%9E%B6/</url>
    <content><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>本章开始不再介绍 Python 标准库，如有需求可编辑基础技术发送至邮箱或者添加好友回复即可。开始介绍一个著名的 Web 框架：Django。</p>
<a id="more"></a>
<p>首先简要介绍什么是 Web 框架，接着介绍使用 Django 开发应用。从基础开始介绍 Django，并开发一个“Hello World”应用。接着逐步深入，介绍开发实际应用时所要了解的内容。这个路线图也组成了本章的架构： 首先夯实基础；然后介绍中级应用，这个应用会涉及Twitter、电子邮件和 OAuth（OAuth 是一个开放的授权协议，用于通过应用编程接口[API]访问数据）。<br>本章旨在介绍一款工具，Python 开发者每天都会用这款工具解决实际问题。通过本章， 读者会学到一些技能和足够的知识，来通过 Django 构建更复杂的工具。读者可以带着这些技能去学习任何其他Python Web 框架。首先，了解什么是 Web 框架。</p>
<h1 id="Web-框架"><a href="#Web-框架" class="headerlink" title="Web 框架"></a>Web 框架</h1><p>Django 是由一个开发团队作为单个突出创建的，但并不是所有框架都遵循这种哲学。以TurboGears 为例，这是一个非常优秀的全栈系统，由分散在全世界的开发者开发，其作为胶水代码，将栈中其他独立的组件组合起来，如ToscaWidgets（高级 Web 部件，它可利用多种JavaScript 框架，如 Ex1tJs、jQuery 等）、SQLAlchemy（ORM）、Pylons（Web 服务器），还有Genshi（模板化）。遵循这种架构样式的框架能提供很好的灵活性，用户可以选择不同的模板系统、JS 库、生成原始 SQL 语句的工具，以及不同的 Web 服务器。只须牺牲一点一致性和放弃单一工具的追求。但对框架的使用也许与之前的方式没什么区别。<br>Pyramid 是另外一个非常著名的 Web 框架，这是 repoze.bfg（或简称 BFG）和 Pylons 的继承者。Pyramid 的方式更加简单，它只提供一些基础功能，如URL 分派、模板化、安全和一些资源。如果需要其他功能，必须手动添加。这种极简的方式带来的好处就是 Pyramid 拥有完整的测试和文档，以及从Pylons 和BFG 社区继承的用户，让Pyramid 成为今日Python Web 框架中有力的竞争者。<br>如果读者刚接触到 Python，可能会了解 Rails 或 PHP，这两者原先只想将语言嵌入到HTML 中，后来扩展成一个庞大框架。Python 的好处就是不必局限于“一种语言，一种框架” 的形式。从 Python 中可以选择许多框架，就如同本章起始处的引用所说的那样。Web 服务器网关接口（WSGI）标准的建立加速了 Web 框架的发展。Python WSGI 由PEP 333 定义，参见：[<a href="http://python.org/dev/peps/pep-0333]。" target="_blank" rel="noopener">http://python.org/dev/peps/pep-0333]。</a><br>如果读者还不了解 WSGI，这里有必要简要说明一下。WSGI 不是实际的代码或 API，而定义了一系列接口，让 Web 框架的开发者无须为框架创建自定义 Web 服务器，也让应用程序开发者可以自行选择 Web 服务器。有了WSGI，应用开发者就可以方便地切换（或开发新的）WSGI 兼容的服务器，而无须担心需要改变应用代码。<br>当热情的 Python 开发者不满足已有的框架时，他们就会创建一个新框架。Python 中 Web 框架的数目比关键字的数目还多。其他框架还包括 web2py、web.py、Tornado、Diesel 和 Zope。可以在 Python 官网的维基页面[<a href="http://wiki.python.org/moin/WebFrameworks]" target="_blank" rel="noopener">http://wiki.python.org/moin/WebFrameworks]</a> 来了解这些框架。<br>回到正文，现在在这些 Web 开发的相关知识的基础上来学习Django。</p>
<h1 id="Django-简介"><a href="#Django-简介" class="headerlink" title="Django 简介"></a>Django 简介</h1><p>Django 自称是“能够很好地应对应用上线期限的 Web 框架”。其最初在 21 世纪初发布， 由 Lawrence Journal-Wor ld 报业的在线业务的 Web 开发者创建。2005 年正式发布，引入了以“新闻业的时间观开发应用”的方式。本章中我们会使用   Django  开发一个简单的博客应用， 下一章会用 Google App Engine 开发相同的应用，比较两者来看 Django 的开发速度（这里的博客比较简单，读者需要自行完善）。尽管会直接给出这个例子，但在介绍的过程中仍然会详细解释示例。</p>
<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>在介绍 Django 开发之前，首先安装必需的组件，这包括依赖组件和 Django 本身。<br>预备条件<br>在安装 Django 之前，必须先安装 Python。由于读者已经读到本书第 10 章了，因此假设已经安装了 Python。大多数兼容POSIX 的系统（Mac  OS X、Linux、*BSD）都已经安装了Python。只有微软 Windows 需要自行下载并安装 Python。<br>Apache 是 Web 服务器中的王者，因此大多数部署都会使用这款服务器。Django 团队建议使用 mod_wdgi 这个Apache 模块，并提供了安装指南：[<a href="http://docs.djangoproject.com/en/dev/topics/install/]" target="_blank" rel="noopener">http://docs.djangoproject.com/en/dev/topics/install/]</a></p>
<pre><code>#install-apache-and-mod-wsgi</code></pre><p>同时也提供了完整的开发文档，参见  [<a href="http://docs.djangoproject.com/en/dev/howto/deployment/modwsgi/]。还有一份更好的文档，其中介绍了使用一个" target="_blank" rel="noopener">http://docs.djangoproject.com/en/dev/howto/deployment/modwsgi/]。还有一份更好的文档，其中介绍了使用一个</a>   Apache  实例来持有多个   Django  Web  站点（项目），参见   [<a href="http://forum.webfaction.com/viewtopic.php?id=3646]" target="_blank" rel="noopener">http://forum.webfaction.com/viewtopic.php?id=3646]</a> 。如果想了解  mod_python，只能在老的  Django  安装包或在mod_wsgi 成为标准之前的一些操作系统的发行版中寻找。官方已经不支持 mod_python（实际上，从Django 1.5 开始，就移除了 mod_python）。<br>在结束对Web服务器的讨论之前 ①，还需要提醒读者，在生产环境的服务器中并不是一定要使用Apache，还可以有其他选择，其中有些内存占用量更少，速度更快。也许其中一个就更适合你的应用。可以在[<a href="http://code.djangoproject.com/wiki/ServerArrangements]中查找符合要求的Web服务器。" target="_blank" rel="noopener">http://code.djangoproject.com/wiki/ServerArrangements]中查找符合要求的Web服务器。</a><br>Django 需要用到数据库。当前的标准版 Django 只可运行基于 SQL 的关系数据库管理系统（RDBMS）。用户主要使用 4 种数据库，分别是 PostgreSQL、MySQL、Oracle 和 SQLite。其中最容易设置的是 SQLite。另外，SQLite 是这 4 个当中唯一一个无须部署数据库服务器的，所以使用起来也是最简单的。当然，简单并不代表无能，SQLite  功能和另外三个一样强大。<br>① 除非到了开发阶段，否则无需 Web 服务器，因此可以在后面安装。Django 自带了开发服务器（刚刚已经看到），可以用于创建和测试应用。<br>为什么 SQLite 很容易设置？SQLite 数据库适配器是所有 Python 版本中自带的（从 2.5 开始）。注意，这里说的是适配器。有些 Python 发行版自带了 SQLite 本身，有些会使用系统上安装的 SQLite。而其他东西则需要手动下载和安装。<br>Django 支持众多关系数据库，SQLite 只是其中一种，所以如果不喜欢 SQLite，可以使用其 他数据库，特别是如果公司已经使用了某一款基于服务器的数据库。关于 Django 和数据库安装的更多内容，可以参考 [<a href="http://docs.djangoproject.com/en/dev/topics/install/#data-base-installation]。" target="_blank" rel="noopener">http://docs.djangoproject.com/en/dev/topics/install/#data-base-installation]。</a><br>最近还有快速发展的非关系数据库（NoSQL）。大概这是因为这种类型的系统提供了额外的可扩展性，能面对不断增长的数据量。如果处理像 Facebook、Twitter 或类似服务那样的海量数据，关系数据库需要手动分区（切分）。如果需要使用 NoSQL 数据库，如 MongoDB 或 Google App Engine 的原生Datastore，可以尝试 Django-nonrel，这样用户就可以选择使用关系或非关系数据库。（需要说明一下，Goolge App Engine 也有一个关系数据库（兼容MySQL），即   Google Cloud SQL）。<br>可以从 [<a href="http://www.allbuttonspressed.com/projects/django-nonrel]" target="_blank" rel="noopener">http://www.allbuttonspressed.com/projects/django-nonrel]</a> 下载Django-nonrel，以及其适配器，参见 [<a href="https://github.com/FlaPer87/django-mongodb-engine]（Django" target="_blank" rel="noopener">https://github.com/FlaPer87/django-mongodb-engine]（Django</a> 和MongoDB），或者 [<a href="http://www.allbuttonspressed.com/projects/djangoappengine]（Django" target="_blank" rel="noopener">http://www.allbuttonspressed.com/projects/djangoappengine]（Django</a> 和Google App Engine 的 Datastore）。在本书编写时，由于 Django-nonrel 是Django 的分支，因此只能安装其中一个。主要原因是因为需要在开发环境和生产环境中使用相同的版本。如同在 <a href="http://www" target="_blank" rel="noopener">http://www</a>. allbuttonspressed.com/projects/django-nonrel 上说的那样，“（Django-nonrel）只对 Django 进行了一丁点修改（可能少于 100 行）”。Django-nonrel 可作为压缩文件下载，所以直接解压它， 在对应的目录中执行下面的命令。</p>
<pre><code>$ sudo python setup.py install</code></pre><p>如果下载Django 压缩包，其安装方法完全相同（如下所示），所以完全可以跳过下一节， 直接开始学习教程。</p>
<h1 id="安装-Django"><a href="#安装-Django" class="headerlink" title="安装 Django"></a>安装 Django</h1><p>有多种方法可以安装 Django，下面对这些安装方法按难易程度排序，越靠前的越简单。<br>Python 包管理器<br>操作系统包管理器<br>官方发布的压缩包<br>源码库<br>最简单的下载和安装方式是使用 Python 包管理工具，如 Setuptools 中的 easy_install<br>（[<a href="http://packages.python.org/distribute/easy_install.html]），或" target="_blank" rel="noopener">http://packages.python.org/distribute/easy_install.html]），或</a>    pip（[<a href="http://pip.openplans.org]），所有平台上都可使用这两个工具。对于">http://pip.openplans.org]），所有平台上都可使用这两个工具。对于</a> Windows 用户，使用 Setuptools 时需要将 easy_install.exe<br>文件放在Python 安装目录下的 Scripts 文件夹中。此时只须在 DOS 命令行窗口中使用一条命令就能安装 Django。</p>
<pre><code>C:\WINDOWS\system32&gt;easy_install django 
Searching for django
Reading http://pypi.python.org/simple/django/ 
Reading http://www.djangoproject.com/
Best match: Django 1.2.7
Downloading http://media.djangoproject.com/releases/1.2/Django- 1.2.7.tar.gz
Processing Django-1.2.7.tar.gz
. . .
Adding django 1.2.7 to easy-install.pth file
Installing django-admin.py script to c:\python27\Scripts
Installed c:\python27\lib\site-packages\django-1.2.7-py2.7.egg 
Processing dependencies for django
Finished processing dependencies for django</code></pre><p>为了无须输入easy_install.exe的全路径，建议将C:\Python2x\Scipts添加到PATH环境变量 ① 中，其中 2.x根据Python的版本来决定。如果使用的是POSIX系统，easy_install会安装到众所周知的/usr/bin或/usr/local/bin中，所以无须再将其添加到PATH中，但可能需要使用sudo命令来将软件安装到一些典型的系统目录中，如/usr/local。命令如下所示。</p>
<pre><code>$ sudo easy_install django</code></pre><p>pip 的命令（不使用 virtuabanv）如下所示。</p>
<pre><code>$ pip install django ＃sudo</code></pre><p>只有在安装到需要超级用户权限的路径中时才会用到sudo；如果安装到用户目录中则不需要。这里还建议使用“容器”环境，如 virtualenv。使用 virtualenv 可以同时安装多个版本的Python、Django、数据库等。每个环境在独立的容器中运行，可以自由创建、管理、执行、销毁。关于 virtualenv 的更多内容可以参见 [<a href="http://pypi.python.org/pypi/virtualenv]。" target="_blank" rel="noopener">http://pypi.python.org/pypi/virtualenv]。</a><br>另一种安装 Django 的方式是使用操作系统自带的包管理器（前提是系统有包管理器）。一般仅限于 POSIX 类的操作系统，如 Linux 和 Mac OS X。操作命令如下所示。</p>
<pre><code>(Linux) $ sudo COMMAND install django 
(Mac OS X) $ sudo port install django</code></pre><p>① Windows 系统用户可以修改PATH 环境变量。首先右击“我的电脑”，接着选择“属性”。在弹出的对话框中，选择“高级”标签，最后单击“环境变量”按钮。<br>对于 Linux 用户，COMMAND 是对应发行版的包管理器，如 apt-get、yum、aptitude 等。可以从 [<a href="http://docs.djangoproject.com/en/dev/misc/distributions]" target="_blank" rel="noopener">http://docs.djangoproject.com/en/dev/misc/distributions]</a> 中找到不同发行版的安装指导。<br>除了上面提到的方法之外，还可以从 Django 网站直接下载并安装原始发布的压缩包。下载并解压后，就可以使用普通的命令进行安装。</p>
<pre><code>$ sudo python setup.py install</code></pre><p>在 [<a href="http://docs.djangoproject.com/en/dev/topics/install/#installing-an-official-release]" target="_blank" rel="noopener">http://docs.djangoproject.com/en/dev/topics/install/#installing-an-official-release]</a> 中可以找到更详细的安装指南。<br>专业开发者可能更喜欢从 Subversion 源码树中自行获取最新的源码。关于这种安装过程，可以参考 [<a href="http://docs.djangoproject.com/en/dev/topics/install/#installing-the-development-version]。" target="_blank" rel="noopener">http://docs.djangoproject.com/en/dev/topics/install/#installing-the-development-version]。</a><br>最后，[<a href="http://docs.djangoproject.com/en/dev/topics/install/#install-the-django-code]" target="_blank" rel="noopener">http://docs.djangoproject.com/en/dev/topics/install/#install-the-django-code]</a> 包含了所有的安装指南。<br>下一步是设置服务器，确保所有组件安装完毕并能正常工作。但在此之前，先介绍一些基本的 Django 概念、项目（project）和应用（app）。</p>
<h1 id="项目和应用"><a href="#项目和应用" class="headerlink" title="项目和应用"></a>项目和应用</h1><p>Django 中的项目和应用是什么？简单来说，可以认为项目是一系列文件，用来创建并运行一个完整的 Web 站点。在项目文件夹下，有一个或多个子文件夹，每个子文件夹有特定的功能，称为应用。应用并不一定要位于项目文件夹中。应用可以专注于项目某一方面的功能， 或可以作为通用组件，用于不同的项目。应用是一个具有特定功能的子模块，这些子模块组合起来就能完成 Web  站点的功能。如管理用户/读者反馈、更新实时信息、处理数据、从站点聚合数据等。<br>从Pinax 平台上能找到比较著名的可重用的 Django 应用。其中包括（但不限于）验证模块（OpenID 支持、密码管理等）、消息处理（E-mail 验证、通知、用户间联系、兴趣小组、主题讨论等），以及其他功能，如项目管理、博客、标签、导入联系人等。关于 Pinax 的更多内容可以访问其网站：[<a href="http://pinaxproject.com]。">http://pinaxproject.com]。</a><br>项目和应用的概念简化了可插拔的使用方式，同时也强烈鼓励了敏捷设计和代码重用。现在知道了什么是项目和应用，下面开始创建一个项目。</p>
<h1 id="在-Django-中创建项目"><a href="#在-Django-中创建项目" class="headerlink" title="在 Django 中创建项目"></a>在 Django 中创建项目</h1><p> Django 带有一个名为 django-admin.py 的工具，它可以简化任务，如创建前面提到的项目目录。在 POSIX 平台上，它一般会安装到/usr/local/bin、/usr/bin 这样的目录中。如果使用的是 Windows 系统，它会安装到 Scripts 文件夹下，该文件夹位于 Python 安装目录下，如 C:\Python37\Scripts 。无论是 POSIX 还是 Windows 系统， 都应该确保django-admin.py 位于 PATH 环境变量中，这样它在可以在命令行中执行（否则需要使用全路径名调用解释器）。<br> 对于 Windows 系统，需要手动将 C:\Python27 和 C:\Python37\Scripts（或自己设定的其他 Python 安装路径）添加到 PATH 变量中。首先打开控制面板，单击“系统”；或右击“我的电脑”，接着选择“属性”。在打开的窗口中选择“高级”标签，单击“环境变量”按钮。可以选择编辑单个用户的  PATH 项（上方的列表框），或者所有用户的  PATH（下方的列表框），接着在 Variable  Value 文本框中的末尾添加“;C:\Python37;C:\Python37\Scripts”<br> 在（任意一个平台上）设置好 PATH 以后，应该可以执行 Python 并获得一个交互式解释器，并查看 Django 的 django-admin.py 命令的使用方法。打开 UNIX shell 或 DOS 命令行，执行命令的名称。如果一切正常，就继续下面的内容。<br>下一步是到转到需要放置代码的文件夹或目录中。要在当前目录中创建项目，可以使用下面的命令（这里使用比较常见的项目名，如 mysite，读者也可以使用其他名称）。</p>
<pre><code>$ django-admin.py startproject mysite</code></pre><p>在 Django 中，基本的项目含有 4 个文件，分别是 init .py、manage.py、setting.py、urls.py（后面会添加到应用中）</p>
<pre><code>文   件   名    描述/用途
 __init__ .py    告诉Python 这是一个软件包
urls.py    全局    URL 配置(“URLconf”)
settings.py        项目相关的配置
manage.py        应用的命令行接口</code></pre><p>细心地童鞋会注意到，startproject 命令创建的每个文件都是纯Python 源码文件，没有.ini 文件、XML 数据，或其他配置语法。Django 尽力坚持“纯粹的 Python”这一信条。这样既可以在不向框架添加复杂东西的情况下拥有灵活性，同时也可以根据不同的情况从其他文件导入额外的配置，或动态计算数值，而不是硬编码。Django 中不适用其他内容，只有纯 Python。读者也可能注意到了 django-admin.py 也是 Python 脚本。其作为用户和项目之间的命令行接口。而 manage.py 同样可以用这种方式管理应用（这两条命令都有 Help 选项，可以从中了解到关于使用方面更多的信息）。</p>
<h1 id="运行开发服务器"><a href="#运行开发服务器" class="headerlink" title="运行开发服务器"></a>运行开发服务器</h1><p>到目前为止，还没有创建一个应用。尽管如此，已经可以使用一些 Django 功能了。其中一个最方便的是 Django 内置的 Web 服务器。该服务器运行在本地，专门用于开发阶段。注意，这里强烈建议不要用这个服务器部署公开页面，因为其仅用于开发用途。</p>
<p>为什么会存在这个开发服务器？主要有以下几点原因。<br>1．使用开发服务器，可以直接运行与测试项目和应用，无需完整的生产环境。<br>2．当改动 Python 源码文件并重新载入模块时，开发服务器会自动检测。这样既能节省时间，也能方便地使用系统，无须每次编辑代码后手动重启。<br>3．开发服务器知道如何为 Django 管理应用程序寻找和显示静态媒体文件，所以无须立即了解管理方面的内容（后面会介绍相关内容，现在只是不要把它与django-admin.py 脚本弄混了）。</p>
<p>通过项目中的 manage.py 工具，可以使用下面这个简单的命令运行开发服务器。</p>
<pre><code>(POSIX) $ python ./manage.py runserver
(PCs) C:\py\django\mysite&gt; python manage.py runserver</code></pre><p>如果使用POSIX 系统，并使用来授予脚本执行许可，就无须显式调用，如 ./manage.py runserver。在 DOS 命令行窗口中也同样可以做到，只需 Python 正确安装到 Windows 注册表中即可。<br>启动服务器后，应该能看到和下面例子相似的输出（Windows 使用不同的键组合来退出程序）。</p>
<pre><code>Validating models...
0 errors found.
Django version 1.2, using settings &#39;mysite.settings&#39; 
Development server is running at http://127.0.0.1:8000/ 
Quit the server with CONTROL-C.
在浏览器中打开链接（http://127.0.0.1:8000/或 http://localhost:8000/），就可以看到 Django的欢迎页面。
如果需要使用不同的端口运行服务器，可以在命令行中指定。例如，如果需要在端口 8080 运行它，
可以使用这条命令：
$ python ./manage.py runserver 8080。
读者可以在下面这个链接中找到所有的 runserver 选项：http://docs.djangoproject.com/en/dev/ref/django-admin/#django-a dmin-runserver。</code></pre><h1 id="创建应用（App）"><a href="#创建应用（App）" class="headerlink" title="创建应用（App）"></a>创建应用（App）</h1><p>既然拥有了一个项目，就可以在其中创建应用。为了创建一个博客应用，继续使用 manage.py：</p>
<pre><code>$ ./manage.py startapp blog</code></pre><p>如之前的项目一样，这里可以自行起名字，并不一定要使用 blog 这个名称。这一步与启动一个项目同样简单。现在在项目目录中有了一个 blog 目录。下面介绍了其中的内容，首先用POSIX 格式列出其中的内容</p>
<pre><code>$ ls -l blog 
total 24
-rw-r--r-- 1 wesley admin 0 Feb 21 08:08 init .py
-rw-r--r-- 1 wesley admin 175 Feb 21 08:08 models.py
-rw-r--r-- 1 wesley admin 514 Feb 21 08:08 tests.py
-rw-r--r-- 1 wesley admin 26 Feb 21 08:08 views.py

文  件   名    描     述 / 目 的
    init   .py     告诉Python 这是一个包
urls.py             应用的 URL 配置文件（“URLconf”），这个文件并不像项目的 URLconf 那样自动创建（所以上面的截图中没有）
models.py         数据模型
views.py         视图函数（即 MVC 中的控制器）
tests.py         单元测试</code></pre><p>与项目类似，应用也是一个 Python 包。但在这里，models.py 和 views.py 文件中目前还没有真正的代码，需要开发者在今后添加代码。单元测试文件 tests.py 也是如此。同样，即使可以使用项目的 URLconf 来分派访问，也不会自动创建本地应用的 URLconf。这需要手动创建它，接着使用项目 URLconf 里的 include()指令将请求分配给应用的URLconf。<br>了让Django 知道这个新的应用是项目的一部分，需要编辑settings.py（可以将其理解为配置文件）。使用编辑器打开这个文件，找到位于底部的 INSTALLED_APPS 这个元组。将应用名称（blog）添加到元组的末尾，如下所示。</p>
<pre><code>INSTALLED_APPS = (
   . . .
   &#39;blog&#39;,
)</code></pre><p>虽然结尾的逗号不是必需的，但如果今后向该元组中添加其他项，就无须添加逗号。Django 使用INSTALLED_APPS 来配置系统的不同部分，包括自动管理应用程序和测试框架。</p>
]]></content>
      <categories>
        <category>Web 框架</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>HTTP 模块</title>
    <url>/2020/03/18/HTTP-%E6%A8%A1%E5%9D%97/</url>
    <content><![CDATA[<p>python中的http/https请求使用urllib库，使用urllib的request模块的发送get和post请求。  </p>
<a id="more"></a>
<h2 id="get请求"><a href="#get请求" class="headerlink" title="get请求"></a>get请求</h2><p>请求网页地址并返回网页html内容，示例如下：</p>
<pre><code>from urllib import request


def getHtml(url):
    with request.urlopen(url) as r:
        data = r.read()
        return data.decode(&quot;utf-8&quot;)


print(getHtml(&quot;http://vipstone.cnblogs.com&quot;))</code></pre><p>对返回的数据进行编码处理data.decode(“utf-8”)即可。</p>
<h2 id="post请求"><a href="#post请求" class="headerlink" title="post请求"></a>post请求</h2><p>post请求并传递参数，对参数进行encode处理，示例如下：</p>
<pre><code>from urllib import request, parse


params = parse.urlencode([(&quot;name&quot;, &quot;老王&quot;), (&quot;pwd&quot;, &quot;123456&quot;)])
req = request.Request(&quot;http://127.0.0.1:8360/video/login&quot;)
req.add_header(&quot;User-Agent&quot;, &quot;Mozilla/6.0 (iPhone; CPU iPhone OS 8_0 like Mac OS X) AppleWebKit/536.26 (KHTML, like Gecko) Version/8.0 Mobile/10A5376e Safari/8536.25&quot;)

with request.urlopen(req, data=params.encode(&quot;utf-8&quot;)) as r:
    data = r.read()
    print(data.decode(&quot;utf-8&quot;))</code></pre><p>如上所示，需要使用urllib的parse对参数进行编码处理，也可以给http头添加内容。</p>
]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Flask-PYTHON Web框架</title>
    <url>/2020/03/21/Flask-PYTHON-Web%E6%A1%86%E6%9E%B6/</url>
    <content><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>Flask是一个基于Python开发并且依赖jinja2模板和Werkzeug WSGI服务的一个微型框架，</p>
<a id="more"></a>
<p>对于Werkzeug本质是Socket服务端，其用于接收http请求并对请求进行预处理，然后触发Flask框架，开发人员基于Flask框架提供的功能对请求进行相应的处理，并返回给用户，如果要返回给用户复杂的内容时，需要借助jinja2模板来实现对模板的处理，即：将模板和数据进行渲染，将渲染后的字符串返回给用户浏览器。</p>
<h1 id="学习资源"><a href="#学习资源" class="headerlink" title="学习资源"></a>学习资源</h1><p>Flask官网：<a href="http://flask.pocoo.org/" target="_blank" rel="noopener">http://flask.pocoo.org/</a><br>Flask中文翻译：<a href="http://dormousehole.readthedocs.io/en/latest/" target="_blank" rel="noopener">http://dormousehole.readthedocs.io/en/latest/</a><br>Jinja文档：<a href="http://jinja.pocoo.org/docs/dev/templates/" target="_blank" rel="noopener">http://jinja.pocoo.org/docs/dev/templates/</a><br>Jinja中文文档：<a href="http://docs.jinkan.org/docs/jinja2/" target="_blank" rel="noopener">http://docs.jinkan.org/docs/jinja2/</a></p>
<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>本示例基于window系统。<br>1.安装pip和virtualenv（若以安装忽略）：</p>
<pre><code>easy_install pip
easy_install virtualenv</code></pre><p>2.创建项目目录firstPython。目录下执行cmd，</p>
<pre><code>virtualenv flask</code></pre><p>  这里会在当前目录下生成flask文件夹，里边自动添加了一些python相关的包和解释器等文件。<br>3.安装flask和扩展包</p>
<pre><code>flask\Scripts\pip install flask
flask\Scripts\pip install flask-login
flask\Scripts\pip install flask-openid
flask\Scripts\pip install flask-sqlalchemy
flask\Scripts\pip install sqlalchemy-migrate
flask\Scripts\pip install flask-whooshalchemy
flask\Scripts\pip install flask-wtf
flask\Scripts\pip install flask-babel
flask\Scripts\pip install flup
flask\Scripts\pip install --no-deps lamson chardet flask-mail</code></pre><p>  上面是一些常用扩展包，目前用不上，可以只引用flask。注意，执行的pip路径是flask\Scripts\pip，这样调用本工程下的pip。</p>
<h1 id="启动服务-测试"><a href="#启动服务-测试" class="headerlink" title="启动服务 测试"></a>启动服务 测试</h1><p>1.创建hello.py:</p>
<pre><code>from flask import Flask
app = Flask(name)
@app.route(&quot;/&quot;)
def hello():
    return &quot;Hello World!&quot;
if name == &#39;main&#39;:
   app.run()</code></pre><p>2.运行hello.py:<br>当前目录下cmd：</p>
<pre><code>python hello.py</code></pre><p>成功后访问地址默认端口5000.显示Hello world！</p>
]]></content>
      <categories>
        <category>Web 框架</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux入门-基础教程</title>
    <url>/2020/03/22/Linux%E5%85%A5%E9%97%A8-%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<h1 id="1-1-Linux操作系统简介"><a href="#1-1-Linux操作系统简介" class="headerlink" title="1. 1 Linux操作系统简介"></a>1. 1 Linux操作系统简介</h1><p>Linux是一套免费使用和自由传播的类Unix操作系统，是一个基于POSIX和UNIX的多用户、多任务、支持多线程和多CPU的操作系统。它能运行主要的UNIX工具软件、应用程序和网络协议。它支持32位和64位硬件。Linux继承了Unix以网络为核心的设计思想，是一个性能稳定的多用户网络操作系统。</p>
<a id="more"></a>
<p>1991年的10月5日，Linux创始人林纳斯·托瓦兹（Linus Torvalds）在comp.os.minix新闻组上发布消息，正式向外宣布Linux内核的诞生，1994年3月，Linux 1.0发布，代码量17万行，当时是按照完全自由免费的协议发布，随后正式采用GPL（General Public License的缩写，是一份GNU通用公共授权）协议。<br>Linux具有如下优点：<br>稳定、免费或者花费少<br> 安全性高<br>多任务，多用户<br>耗资源少<br>由于内核小，所以它可以支持多种电子产品，如：Android手机、PDA等。</p>
<h1 id="1-2-Linux发展趋势"><a href="#1-2-Linux发展趋势" class="headerlink" title="1. 2 Linux发展趋势"></a>1. 2 Linux发展趋势</h1><p>随着IT产业的不断发展，用户对网站体验要求也越来越高，而目前主流网站后端承载系统都是Linux系统，目前Android手机全部基于Linux内核研发。企业大数据、云存储、虚拟化等先进技术都是基于Linux系统。<br>2010年据有关权威部门统计：将来几年内我国软件行业的从业机会十分庞大，中国每年对软件人才的需求将达到50万人左右。而对于Linux 专业人才的就业前景，更是广阔；据悉在未来5-10年内 Linux 专业人才的需求将达到 120 万+！尤其是有经验的资深的Linux工程师目前非常的缺乏，薪资也是非常诱人，平均月薪都是15-20K，能力强的薪资更高。所以机会对每个人都是公平的，关键是我们每个人如何去行动，选择大于努力。</p>
<h1 id="1-3-Linux系统安装"><a href="#1-3-Linux系统安装" class="headerlink" title="1. 3      Linux系统安装"></a>1. 3      Linux系统安装</h1><p>在安装Linux系统之前，先来了解windows系统结构，windows系统一般是安装在C盘系统盘，同样Linux也有类似的系统盘（/根分区），Linux通常分区为（根分区/、swap分区），Linux系统以文件的存储方式，所有的文件都是存储在某个目录下的，类似于windows的文件夹。<br>对于文件系统的属性来说，windows文件系统类型一般是ntfs、fat32等，而Linux文件系统类型则为ext2、ext3、ext4等（文件系统：是操作系统用于明确磁盘或分区上的文件的方法和数据结构，文件系统由三部分组成：与文件管理有关软件、被管理文件以及实施文件管理所需数据结构。）<br>安装 Linux系统是每一个初学者的第一个门槛。在这个过程中间，最大的困惑莫过于给硬盘进行分区。虽然现在各种发行版本的 Linux 已经提供了友好的图形交互界面，但是很多人还是感觉无从下手。这其中的原因主要是不清楚 Linux 的分区规定。就好比如果我们了解了windows分区的规则，系统盘C、数据盘D等，就很好分区了。<br>在 Linux 中规定，每一个硬盘设备最多只能有 4个主分区（其中包含扩展分区）构成，任何一个扩展分区都要占用一个主分区号码，也就是在一个硬盘中，主分区和扩展分区一共最多是 4 个。<br>下面正式来安装Linux系统，安装系统前需要准备如下软件：<br>VMware workstation 10.0<br>CentOS 5.8 x86_i386.iso<br>安装图解如下：<br>第一步  新建虚拟机<br>第二步，选择相关选项<br>第三步选择“稍后安装操作系统”<br>第四步，选择客户机操作系统类型<br>第五步，设置虚拟机硬盘大小为20G，最低不能小于5G<br>第六步，虚拟机新建完成<br>第七步，修改虚拟机内存为512M，并添加ISO镜像<br>自此，虚拟机新建完成，接下来点击“启动此虚拟机”进行Linux系统安装，Linux系统安装图解如下：<br>第一步，进入安装界面，直接按Enter回车键即可。第二步，光盘检测，选择SKIP跳过。第三步，选择安装过程中的语言，初学者可以选择“简体中文”。第四步，选择初始化整个硬盘，清除所有数据。第五步，选择分区方式为“自定义分区“。第五步，点击“新建“-首先创建一个swap交换分区，大小为物理内存的2倍（1024M）。第六步，继续创建分区，选择“新建“，然后创建根分区/，如下图选择，大小为剩余所有空间即可。第七步，默认点击下一步，同时默认DHCP配置，时钟选择上海，去掉UTC勾，点击下一步。第八步，设置root密码，至少六位，点击下一步。第九步，系统安装包选择，这里选择“现在定制“。第十步，系统安装包选择，左侧选择“开发“—-右侧选择”开发工具“和“开发库”，语言选择“支持中文“，其他一概不选择。安装完毕会提示“reboot“，直接回车即可。</p>
<h1 id="1-4-Linux学习技巧"><a href="#1-4-Linux学习技巧" class="headerlink" title="1. 4      Linux学习技巧"></a>1. 4      Linux学习技巧</h1><p>初学者可以自己安装虚拟机，然后把linux常用命令例如cd、ls、chmod、useradd、vi等等多练习几十遍，把自己敲打命令的熟练程度提升上来。<br>然后根据文档搭建Linux下常见的各种服务（DHCP、SAMBA、DNS、Apache、Mysql等），遇到问题后可以在google搜索，搜索的时候多看几篇文章，综合最好的文章来解决问题。<br>能够熟练的搭建服务后，理解每个服务的完整配置和优化，可以拓展思维。例如LAMP，我们一般是把所有服务放在一台机器上，如果分开多台该如何部署呢？等等。<br>平时多积累shell编程，可以在网上查找前辈们写的非常好的shell，自己下载下来多练习几遍，从中吸取，不断提高。<br>建立一个自己的学习博客，把平时工作学习中的知识都记录在里面，这样也可以供别人来参考同时也能提高自己的编写文档及方案的能力。<br>通过以上学习能够满足企业的一般应有，需要达到资深级别，还需要深入学习集群架构、负载均衡、自动化运维、运维开发等知识。最后还是一句话：多练习才是硬道理！实践出真知！</p>
<h1 id="1-Linux系统篇"><a href="#1-Linux系统篇" class="headerlink" title="1.   Linux系统篇"></a>1.   Linux系统篇</h1><h1 id="2-1-Linux系统管理"><a href="#2-1-Linux系统管理" class="headerlink" title="2.1            Linux系统管理"></a>2.1            Linux系统管理</h1><p>通过前两章的学习，我们已经能够独立安装Linux系统，已经掌握了Linux学习的技巧，那接下来，我们将系统的来了解Linux系统各目录、权限及常用命令的使用。</p>
<h1 id="2-1-1-Linux目录初识"><a href="#2-1-1-Linux目录初识" class="headerlink" title="2.1. 1         Linux目录初识"></a>2.1. 1         Linux目录初识</h1><p>通过前面的学习,我们已经能够独立安装完一个linux系统，那接下来我们来熟悉一下Linux系统里面的各个目录文件夹的大致功能：<br>主要的目录树的有/、/root、/home、/usr、/bin等目录。下面是一个典型的linux目录结构如下：  </p>
<pre><code>/bin 存放必要的命令 
/boot 存放内核以及启动所需的文件
/dev 存放设备文件 
/etc 存放系统配置文件 
/home 普通用户的宿主目录，用户数据存放在其主目录中 
/lib 存放必要的运行库 
/mnt 存放临时的映射文件系统，通常用来挂载使用。
 /proc 存放存储进程和系统信息 
/root 超级用户的主目录 
/sbin 存放系统管理程序 
/tmp 存放临时文件
/usr 存放应用程序，命令程序文件、程序库、手册和其它文档。 
/var 系统默认日志存放目录</code></pre><h1 id="2-1-2-Linux必备命令"><a href="#2-1-2-Linux必备命令" class="headerlink" title="2.1. 2         Linux必备命令"></a>2.1. 2         Linux必备命令</h1><p>默认进入系统，我们会看到这样的字符:   </p>
<pre><code>[root@localhost ~]#,其中#代表当前是root用户登录，如果是$表示当前为普通用户。
我们了解linux由很多目录文件构成，那我们来学习第一个Linux命令：
cd命令， cd  /home  ；解析：进入/home目录
cd /root 进入/root目录 ；cd ../返回上一级目录;cd  ./当前目录；（.和..可以理解为相对路径；例如cd /hom/test ，cd加完整的路径，可以理解为绝对路径）
接下来继续学习更多的命令：
   ls  ./ 查看当前目录所有的文件和目录。
ls  -a 查看所有的文件，包括隐藏文件,以.开头的文件。

pwd显示当前所在的目录。
mkdir创建目录，用法mkdir  test ，命令后接目录的名称。
rmdir 删除空目录
rm 删除文件或者目录，用法 rm –rf  test.txt (-r表示递归，-f表示强制)。
cp 拷贝文件，用法,cp  old.txt  /tmp/new.txt ，常用来备份；如果拷贝目录
需要加 –r参数。

mv 重命名或者移动文件或者目录，用法, mv old.txt new.txt
touch 创建文件，用法，touch test.txt，如果文件存在，则表示修改当前文件时间。
Useradd创建用户，用法 useradd wugk ，userdel删除用户。
Groupadd创建组，用法 groupadd wugk1 ，groupdel删除组。

find查找文件或目录，用法 find  /home  -name  “test.txt”,命令格式为:
find 后接查找的目录，-name指定需要查找的文件名称，名称可以使用*表示所有。
find  /home  -name  “*.txt” ;查找/home目录下，所有以.txt结尾的文件或者目录。
vi 修改某个文件，vi有三种模式：
命令行模式、文本输入模式、末行模式。
默认vi打开一个文件，首先是命令行模式，然后按i进入文本输入模式，可以在文件里写入字符等等信息。
写完后，按esc进入命令模式，然后输入:进入末行模式，例如输入:wq表示保存退出。
如果想直接退出，不保存，可以执行:q!， q!叹号表示强制退出。
cat 查看文件内容，用法 cat test.txt 可以看到test.txt内容
more 查看文件内容，分页查看，cat是全部查看，如果篇幅很多，只能看到最后的篇幅。可以使用cat和more同时使用,例如： cat  test.txt |more 分页显示text内容，|符号是管道符，用于把|前的输出作为后面命令的输入。
echo 回显，用法 echo ok，会显示ok，输入什么就打印什么。
echo  ok  &gt; test.txt ；把ok字符覆盖test.txt内容，&gt;表示追加并覆盖的意思。
&gt;&gt;两个大于符号，表示追加，echo ok &gt;&gt; test.txt,表示向test.txt文件追加OK字符，不覆盖原文件里的内容。
初学者常见的命令就如上所示，当然还有很多深入的命令需要学习，后面的课程会讲解。</code></pre><h1 id="2-1-3-Linux用户权限管理"><a href="#2-1-3-Linux用户权限管理" class="headerlink" title="2.1. 3         Linux用户权限管理"></a>2.1. 3         Linux用户权限管理</h1><p>在Linux操作系统中，root的权限是最高的，相当于windows的administrator，拥有最高权限，能执行任何命令和操作。在系统中，通过UID来区分用户的权限级别，UID等于0，表示此用户具有最高权限，也就是管理员。其他的用户UID依次增加，通过/etc/passwd用户密码文件可以查看到每个用户的独立的UID。<br>每一个文件或者目录的权限，都包含一个用户权限、一个组的权限、其他人权限，例如下：<br>标红第一个root表示该文件所有者是root用户，第二个root代表该文件的所属的组为root组，其他用户这里默认不标出。</p>
<pre><code> [root@node1 ~]# ls -l monitor_log.sh
-rw-r–r– 1 root root 91 May  7 20:21 monitor_log.sh
[root@node1 ~]#
如果我们想改变某个文件的所有者或者所属的组，可以使用命令chown
chown  –R  test:test  monitor_log.sh即可。
每个Linux文件具有四种访问权限：可读(r)、可写(w)、可执行(x)和无权限(-)。
利用ls -l命令可以看到某个文件或目录的权限，它以显示数据的第一个字段为
 准。第一个字段由10个字符组成，如下：
    [root@node1 ~]# ls -l monitor_log.sh
-rw-r–r– 1 root root 91 May  7 20:21 monitor_log.sh
[root@node1 ~]#
    第一位表示文件类型，-表示文件，d表示目录；后面每三位为一组。
   第一组：2-4位表示文件所有者的权限，即用户user权限，简称u
   第二组：5-7位表示文件所有者所属组成员的权限，group权限，简称g
   第三组：8-10位表示所有者所属组之外的用户的权限，other权限，简称o
从上面这个文件，我们可以看出，monito_log.sh文件对应的权限为：
root用户具有读和写的权限，root组具有读的权限，其他人具有读的权限。
为了能更简单快捷的使用和熟悉权限，rwx权限可以用数字来表示，分别表示为r（4）、w（2）、x（1）。
Monitor_log.sh权限可以表示为：644
如果给某个文件授权，命令为chmod：chmod 777 monitor_log.sh</code></pre><h1 id="2-1-4-Linux网络配置管理"><a href="#2-1-4-Linux网络配置管理" class="headerlink" title="2.1. 4         Linux网络配置管理"></a>2.1. 4         Linux网络配置管理</h1><p>熟悉了常用的命令和Linux权限，那接下来如何让所在的Linux系统上网呢？管理linux服务器网络有哪些命令呢？<br>   Linux服务器默认网卡配置文件在/etc/sysconfig/network-scripts/下，命名的名称一般为:ifcfg-eth0 ifcfg-eth1 ，eth0表示第一块网卡，eth1表示第二块网卡，依次类推。一般DELL R720标配有4块千兆网卡。<br>   修改网卡的IP，可以使用命令: vi /etc/sysconfig/network-scripts/ifcfg-eth0 如果是DHCP获取的IP，默认配置如下：</p>
<pre><code># Advanced Micro Devices [AMD] 79c970 [PCnet32 LANCE]
DEVICE=eth0
BOOTPROTO=dhcp
HWADDR=00:0c:29:52:c7:4e
ONBOOT=yes
TYPE=Ethernet
如果是静态配置的IP，ifcfg-eth0网卡配置内容如下：
# Advanced Micro Devices [AMD] 79c970 [PCnet32 LANCE]
DEVICE=eth0
BOOTPROTO=static
HWADDR=00:0c:29:52:c7:4e
ONBOOT=yes
TYPE=Ethernet
IPADDR=192.168.33.10
NETMASK=255.255.255.0
GATEWAY=192.168.33.1
网卡参数详解如下：
DEVICE=eth0   #物理设备名
ONBOOT=yes   # [yes|no]（重启网卡是否激活设备）
BOOTPROTO=static #[none|static|bootp|dhcp]（不使用协议|静态分配|BOOTP协议|DHCP协议）

TYPE=Ethernet  #网卡类型
IPADDR=192.168.33.10 #IP 地址
NETMASK=255.255.255.0 #子网掩码
GATEWAY=192.168.33.1 #网关地址
网卡配置完毕，重启网卡，命令: /etc/init.d/network restart 即可。
查看ip命令：ifconfig 查看当前服务器所有网卡的IP，可以单独指定，ifconfig eth0 查看eth0的IP地址。
网卡配置完毕，如果来配置DNS，首先要知道DNS配置在哪个目录文件下，vi  /etc/resolv.conf 文件:
在该文件里面添加如下两条：
nameserver 202.106.0.20
nameserver 8.8.8.8</code></pre><p>从上到下，分别表示主DNS，备DNS。配置完毕后，不需要重启网卡,DNS立即生效。<br>可以ping <a href="http://www.ai8py.com" target="_blank" rel="noopener">www.ai8py.com</a> 看看效果:IP配置完毕后，我们可以通过远程工具来连接Linux服务器，常见的Linux远程连接工具有:putty、secureCRT（主流）、xshell、xmanger等工具。</p>
<h1 id="2-1-5-Linux软件包管理必备命令"><a href="#2-1-5-Linux软件包管理必备命令" class="headerlink" title="2.1. 5         Linux软件包管理必备命令"></a>2.1. 5         Linux软件包管理必备命令</h1><pre><code>rpm -q 包名
    选项：-q    查询
        -a    查询所有已安装的包
rpm -qi 包名
选项：
    -i  查询软件信息
    -p  查询未安装包信息
rpm -ql 包名
选项：
    -l  列表
    -p  查询未安装包信息
rpm -qR 包名
选项：
    -R  查询软件包的依赖性
    -p  查询未安装包信息
1.挂载packages目录
2.安装必须要输入包全名
rpm -ivh 包全名
选项：
    -i(install)     安装
    -v(verbose)     显示详细信息
    -h(hash)        显示进度
    --nodeps        不检测依赖性
rpm -Uvh 包名
选项：
    -U(upgrade)     升级
rpm -e 包名
选项：
    -e(erase)   卸载</code></pre><h1 id="2-Linux服务篇"><a href="#2-Linux服务篇" class="headerlink" title="2.   Linux服务篇"></a>2.   Linux服务篇</h1><h1 id="3-1-Linux服务部署"><a href="#3-1-Linux服务部署" class="headerlink" title="3.1            Linux服务部署"></a>3.1            Linux服务部署</h1><h1 id="3-1-1-构建NTP时间服务器"><a href="#3-1-1-构建NTP时间服务器" class="headerlink" title="3.1. 1         构建NTP时间服务器"></a>3.1. 1         构建NTP时间服务器</h1><p>NTP服务器是用于局域网服务器时间同步使用的，可以保证局域网所有的服务器与时间服务器的时间保持一致，某些应用对时间实时性要求高的必须统一时间。<br>互联网的时间服务器也有很多，例如ntpdate ntp.fudan.edu.cn 复旦大学的NTP免费提供互联网时间同步。<br>NTP服务器监听端口为UDP的123，那就需要在本地防火墙开启运行客户端访问123端口，vi /etc/sysconfig/iptables添加如下规则：</p>
<pre><code>-A INPUT -m state –state NEW -m udp -p udp –dport 123 -j ACCEPT
NTP时间服务器配置：
yum install ntp ntpdate -y 即可！
修改ntp.conf配置文件
cp  /etp/ntp.conf /etc/ntp.conf.bak
vi /etc/ntp.conf 只修改如下两行，把#号去掉即可！
server 127.127.1.0     # local clock
fudge  127.127.1.0 stratum 10
以守护进程启动ntpd
/etc/init.d/ntpd start 即可
（注意*： ntpd启动后，客户机要等几分钟再与其进行时间同步，否则会提示“no server suitable for synchronization found”错误。）
配置时间同步客户机
crontab -e
增加一行，在每天的6点10分与时间同步服务器进行同步
10 06 * * * /usr/sbin/ntpdate ntp-server的ip &gt;&gt;/usr/local/logs/crontab/ntpdate.log
备注：如果客户机没有ntpdate，可以yum –y install ntp 即可！
以下是ntp服务器配置文件内容(局域网NTP，如果需要跟外网同步，添加外网server即可)
driftfile /var/lib/ntp/drift
restrict default kod nomodify notrap nopeer noquery
restrict -6 default kod nomodify notrap nopeer noquery
restrict 127.0.0.1
restrict -6 ::1
server  127.127.1.0     # local clock
fudge   127.127.1.0 stratum 10
includefile /etc/ntp/crypto/pw
keys /etc/ntp/keys
下面是参数详解：

restrict default ignore    # 关闭所有的 NTP 要求封包
restrict 127.0.0.1    # 开启内部递归网络接口 lo
restrict 192.168.0.0 mask 255.255.255.0 nomodify    #在内部子网里面的客户端可以进行网络校时，但不能修改NTP服务器的时间参数。
server 198.123.30.132    #198.123.30.132作为上级时间服务器参考
restrict 198.123.30.132    #开放server 访问我们ntp服务的权限
driftfile /var/lib/ntp/drift    在与上级时间服务器联系时所花费的时间，记录在driftfile参数后面的文件内
broadcastdelay 0.008    #广播延迟时间
 自此NTP服务搭建完毕，然后在所有客户端crontab里面添加如下语句：
0  0   *  *  * /usr/sbin/ntpdate  10.0.0.155 &gt;&gt;/data/logs/ntp.log 2&gt;&amp;1</code></pre><h1 id="3-1-2-构建DHCP服务器"><a href="#3-1-2-构建DHCP服务器" class="headerlink" title="3.1. 2         构建DHCP服务器"></a>3.1. 2         构建DHCP服务器</h1><p>DHCP(Dynamic Host Configuration Protocol，动态主机配置协议)是一个局域网的网络协议，使用UDP协议工作，主要用途：给内部网络或网络服务供应商自动分配IP地址，DHCP有3个端口，其中UDP67和UDP68为正常的DHCP服务端口，分别作为DHCP Server和DHCP Client的服务端口。<br>DHCP可以部署在服务器、交换机或者服务器，可以控制一段IP地址范围，客户机登录服务器时就可以自动获得DHCP服务器分配的IP地址和子网掩码。其中DHCP所在服务器的需要安装TCP/IP协议，需要设置静态IP地址、子网掩码、默认网关。<br>正式安装DHCP服务：<br>Yum  install  dhcp dhcp-devel –y 即可，然后修改DHCP /etc/dhcpd.conf配置文件内容如下：</p>
<pre><code>ddns-update-style interim;
ignore client-updates;
next-server  192.168.0.79;
filename “pxelinux.0”;
allow booting;
allow bootp; 
subnet 192.168.0.0 netmask 255.255.255.0 {
# — default gateway
option routers          192.168.0.1;
option subnet-mask      255.255.252.0;
#   option nis-domain       “domain.org”;
#  option domain-name “192.168.0.10”;
#   option domain-name-servers  192.168.0.11;
#   option ntp-servers      192.168.1.1;
#   option netbios-name-servers  192.168.1.1;
# — Selects point-to-point node (default is hybrid). Don’t change this unless
# — you understand Netbios very well
#   option netbios-node-type 2;
range  dynamic-bootp  192.168.0.100 192.168.0.200;
host ns {
hardware ethernet  00:1a:a0:2b:38:81;
fixed-address 192.168.0.101;}
}
参数解析如下：

选    项    解    释

ddns-update-style interim|ad-hoc|none     参数用来设置DHCP服务器与DNS服务器的动态信息更新模式：interim为DNS互动更新模式，ad-hoc为特殊DNS更新模式，none为不支持动态更新模式。
next-server ip    pxeclient远程安装系统，指定tftp server 地址
filename    开始启动文件的名称，应用于无盘安装，可以是tftp的相对或绝对路径  
ignore client-updates    为忽略客户端更新
subnet-mask    为客户端设定子网掩码
option routers    为客户端指定网关地址
domain-name    为客户端指明DNS名字
domain-name-servers    为客户端指明DNS服务器的IP地址
host-name    为客户端指定主机名称
broadcast-address    为客户端设定广播地址
ntp-server    为客户端设定网络时间服务器的IP地址
time-offset    为客户端设定格林威治时间的偏移时间，单位是秒
注意如上配置，需要修改成对应服务器网段IP，然后重启DHCP服务，/etc/init.d/dhcpd restart即可。
客户端要从这个DHCP服务器获取IP，需要做简单的设置，如果是linux需要把/etc/sysconfig/network-scritps/ifcfg-eth0里BOOTPROTO相改成dhcp即可，windows机器的话，需要修改本地连接，把它设置成自动获取IP即可。
BOOTPROTO=dhcp</code></pre><h1 id="3-1-3-搭建Samba服务器"><a href="#3-1-3-搭建Samba服务器" class="headerlink" title="3.1. 3         搭建Samba服务器"></a>3.1. 3         搭建Samba服务器</h1><p>Samba是在Linux和UNIX系统上实现SMB协议的一个免费软件，由服务器及客户端程序构成，<br>SMB（Server Messages Block，信息服务块）是一种在局域网上共享文件和打印机的一种通信协议，它为局域网内的不同计算机之间提供文件及打印机等资源的共享服务。<br>SMB协议是客户机/服务器型协议，客户机通过该协议可以访问服务器上的共享文件系统、打印机及其他资源。通过设置“NetBIOS over TCP/IP”使得Samba不但能与局域网络主机分享资源，还能与全世界的电脑分享资源。<br>安装SAMBA服务器：<br>Yum install  samba –y<br>安装完毕，然后做如下设置（过滤#号行、空行如下命令）<br>cp /etc/samba/smb.conf /etc/samba/smb.conf.bak ;egrep -v “#|^$” /etc/samba/smb.conf.bak |grep -v “^;” &gt;/etc/samba/smb.conf<br>查看smb.conf配置文件如下：</p>
<pre><code>[global]
        workgroup = MYGROUP
        server string = Samba Server Version %v
        security = share
        passdb backend = tdbsam
        load printers = yes
        cups options = raw

[temp]
     comment=Temporary file space
     path=/tmp
     read only=no
     public=yes

[data]
     comment=Temporary file space
     path=/data
     read only=no
     public=yes
根据需求修改之后重启服务：
[root@node1 ~]# /etc/init.d/smb restart
Shutting down SMB services:                                [FAILED]
Shutting down NMB services:                                [FAILED]
Starting SMB services:                                     [  OK  ]
Starting NMB services:                                     [  OK  ]


workgroup =    WORKGROUP 设Samba Server 所要加入的工作组或者域。
server string = Samba Server Version %v    Samba Server 的注释，可以是任何字符串，也可以不填。宏%v表示显示Samba的版本号。




security = user    1.share：用户访问Samba Server不需要提供用户名和口令, 安全性能较低。
2. user：Samba Server共享目录只能被授权的用户访问,由Samba Server负责检查账号和密码的正确性。账号和密码要在本Samba Server中建立。
3. server：依靠其他Windows NT/2000或Samba Server来验证用户的账号和密码,是一种代理验证。此种安全模式下,系统管理员可以把所有的Windows用户和口令集中到一个NT系统上,使用Windows NT进行Samba认证, 远程服务器可以自动认证全部用户和口令,如果认证失败,Samba将使用用户级安全模式作为替代的方式。
4. domain：域安全级别,使用主域控制器(PDC)来完成认证。
comment = test    是对该共享的描述，可以是任意字符串。
path = /home/test    共享目录路径
browseable= yes/no     用来指定该共享是否可以浏览。
writable = yes/no    writable用来指定该共享路径是否可写。
available = yes/no    available用来指定该共享资源是否可用
admin users = admin    该共享的管理者
valid users = test    允许访问该共享的用户
invalid users = test    禁止访问该共享的用户
write list = test    允许写入该共享的用户
public = yes/no    public用来指定该共享是否允许guest账户访问。
 在浏览器里面访问方式为：\\192.168.33.10 （SMB文件共享服务端IP），如何没有权限访问，需要注意防火墙和selinux设置，可以使用如下命令关闭：
/etc/init.d/iptables stop ;sed  –i   ‘/SELINUX/s/enforcing/disabled’  /etc/sysconfig/selinux</code></pre><h1 id="3-1-4-搭建NFS服务器"><a href="#3-1-4-搭建NFS服务器" class="headerlink" title="3.1. 4         搭建NFS服务器"></a>3.1. 4         搭建NFS服务器</h1><p>NFS 是Network File System的缩写，即网络文件系统。一种使用于分散式文件系统的协定，由Sun公司开发，于1984年向外公布。功能是通过网络让不同的机器、不同的操作系统能够彼此分享个别的数据，让应用程序在客户端通过网络访问位于服务器磁盘中的数据，是在类Unix系统间实现磁盘文件共享的一种方法。<br>NFS在文件传送或信息传送过程中依赖于RPC协议。RPC，远程过程调用 (Remote Procedure Call) 是能使客户端执行其他系统中程序的一种机制。NFS本身是没有提供信息传输的协议和功能的。<br>NFS应用场景，常用于高可用文件共享，多台服务器共享同样的数据，可扩展性比较差，本身高可用方案不完善，取而代之的数据量比较大的可以采用MFS、TFS、HDFS等等分布式文件系统。<br>NFS安装配置：</p>
<pre><code>Yum  install nfs*  portmap  -y </code></pre><p>安装成功即可。NFS安装完毕，需要创建共享目录，共享目录在/etc/exports文件里面配置，可配置参数如下：</p>
<pre><code>/data/      192.168.33.11(rw,sync,no_hide,no_all_squash)</code></pre><p>在配置文件中添加如上一行，然后重启Portmap，NFS服务即可，/etc/init.d/portmap restart ;/etc/init.d/nfs restart<br>第一列/data/表示需要共享的目录。<br>IP表示允许哪个客户端访问。<br>IP后括号里的设置表示对该共享文件的权限。</p>
<pre><code>ro                      只读访问
rw                      读写访问
sync                    所有数据在请求时写入共享
hide                    在NFS共享目录中不共享其子目录
no_hide                 共享NFS目录的子目录
all_squash              共享文件的UID和GID映射匿名用户anonymous，适合公用目录。
no_all_squash           保留共享文件的UID和GID（默认）
root_squash             root用户的所有请求映射成如anonymous用户一样的权限（默认）
no_root_squas           root用户具有根目录的完全管理访问权限Linux客户端，如何想使用这个NFS文件系统，需要在客户端挂载，挂载命令为：
Mount –t  nfs  192.168.33.10:/data/    /mnt 即可。如果有报错根据错误信息排查。常见问题有rpc服务没有启动、防火墙没关闭、selinux未关闭等问题。（拓展* 有兴趣的童鞋可以研究MFS（分布式文件系统）。）</code></pre><h1 id="3-1-5-搭建FTP服务器"><a href="#3-1-5-搭建FTP服务器" class="headerlink" title="3.1. 5         搭建FTP服务器"></a>3.1. 5         搭建FTP服务器</h1><p>FTP 是文件传输协议，正是由于这种协议使得主机间可以共享文件。 FTP 使用TCP 生成一个虚拟连接用于控制信息，然后再生成一个单独的 TCP 连接用于数据传输。<br>vsftpd是一款在Linux发行版中最主流的FTP服务器程序；特点是小巧轻快，安全易用；能让其自身特点得发发挥和掌握。<br>目前在开源操作系统中常用的FTP服务器程序主要有vsftpd、ProFTPD、PureFTPd和wuftpd等，这么多FTP服务器程序，关键在于自己熟练哪一个就使用哪一个。今天我们来研究一下VSFTPD简单安装及使用。安装命令: </p>
<pre><code>yum  install vsftpd*  -y修改配置文件如下：
#vsftpd config 2014 by wugk
anonymous_enable=NO    //禁止匿名用户访问
local_enable=YES  //允许本地用户登录FTP
write_enable=YES   //运行用户在FTP目录有写入的权限
local_umask=022   //设置本地用户的文件生成掩码为022，默认是077
dirmessage_enable=YES //激活目录信息,当远程用户更改目录时,将出现提示信息
xferlog_enable=YES   //启用上传和下载日志功能
connect_from_port_20=YES  //启用FTP数据端口的连接请求
xferlog_std_format=YES  //是否使用标准的ftpd xferlog日志文件格式
listen=YES  //使vsftpd处于独立启动监听端口模式
pam_service_name=vsftpd //设置PAM认证服务配置文件名称，文件存放在/etc/pam.d/目录
userlist_enable=YES   //用户列表中的用户是否允许登录FTP服务器,默认是不允许
tcp_wrappers=YES    //使用tcp_wrqppers作为主机访问控制方式</code></pre><p>1)    第一种方法就是使用系统用户登录FTP，但是也是比较危险的，先测试系统用户登录FTP，在Linux系统上创建useradd  test 用户，并为其设置名，然后在xp客户端打开我的电脑资源里面访问 <a href="ftp://192.168.33.10，输入用户名和密码即可访问，进行创建和删除操作。">ftp://192.168.33.10，输入用户名和密码即可访问，进行创建和删除操作。</a><br>2)    第二种方法比较安全，配置相对复杂一点，就是使用vsftpd虚拟用户登录FTP服务器进行常见的操作。<br>Ø       首先安装FTP 虚拟用户需要用到的软件及认证模块</p>
<pre><code>yum install pam* db4* –skip-broken –y</code></pre><p>创建并生成vsftpd数据库文件vi /etc/vsftpd/ftpusers.txt，内容如下：<br>第一行为FTP虚拟用户，登录用户名，第二行为密码，第三行为用户名，依次类推。</p>
<pre><code>wugk
1
wugk1
1
Ø       生成数据库文件命令：
db_load -T -t hash -f /etc/vsftpd/ftpusers.txt /etc/vsftpd/vsftpd_login.db
chmod 700 /etc/vsftpd/vsftpd_login.db
Ø       配置PAM验证文件：
在配置文件vi /etc/pam.d/vsftpd 行首加入如下两行认证语句：（如果是32位，lib64需改成lib，如果RedHat，加入的语句不一样，需注意）
auth    sufficient      /lib64/security/pam_userdb.so     db=/etc/vsftpd/vsftpd_login
account sufficient      /lib64/security/pam_userdb.so      db=/etc/vsftpd/vsftpd_login
Ø       创建vsftpd映射本地用户:
所有的FTP虚拟用户需要使用一个系统用户，这个系统用户不需要密码，也不需要登录。主要用来做虚拟用户映射使用。
useradd  –d /home/ftpuser –s /sbin/nologin ftpuser
Ø       修改完整版配置文件内容如下：
anonymous_enable=NO
local_enable=YES
write_enable=YES
local_umask=022
dirmessage_enable=YES
xferlog_enable=YES
connect_from_port_20=YES
xferlog_file=/var/log/vsftpd.log
xferlog_std_format=YES
ascii_upload_enable=YES
ascii_download_enable=YES
listen=YES
guest_enable=YES
guest_username=ftpuser
pam_service_name=vsftpd
user_config_dir=/etc/vsftpd/vsftpd_user_conf
virtual_use_local_privs=YES

   保存重启,/etc/init.d/vsftpd restart 即可使用虚拟用户登录，这时候所有的虚拟用户共同使用/home/ftpuser目录上传下载，如果想使用自己独立的目录，可以在/etc/vsftpd/vsftpd_user_conf目录创建各自的配置文件，如给wugk创建独立的配置文件：
vi /etc/vsftpd/vsftpd_user_conf/wugk ，内容如下，建立自己的FTP目录。
local_root=/home/ftpsite/wugk
write_enable=YES
anon_world_readable_only=YES
anon_upload_enable=YES
anon_mkdir_write_enable=YES
anon_other_write_enable=YES</code></pre><p> 重启，使用客户端登录FTP，测试即可。关于FTP讲解就到此，windows还可以使用Server-U来搭建FTP服务器端，有兴趣的童鞋可以研究一下。</p>
<h1 id="FTP主被动模式"><a href="#FTP主被动模式" class="headerlink" title="FTP主被动模式"></a>FTP主被动模式</h1><h1 id="FTP主动模式："><a href="#FTP主动模式：" class="headerlink" title="FTP主动模式："></a>FTP主动模式：</h1><p>客户端从一个任意的非特权端口N（N&gt;1024）连接到FTP服务器的port 21命令端口。然后客户端开始监听端口N+1，并发送FTP命令“port N+1”到FTP服务器。接着服务器会从它自己的数据端口（20）连接到客户端指定的数据端口（N+1）。</p>
<h1 id="FTP被动模式："><a href="#FTP被动模式：" class="headerlink" title="FTP被动模式："></a>FTP被动模式：</h1><p>客户端从一个任意的非特权端口N（N&gt;1024）连接到FTP服务器的port 21命令端口。然后客户端开始监听端口N+1，同时客户端提交 PASV命令。服务器会开启一个任意的非特权端口（P &gt;1024），并发送PORT P命令给客户端。然后客户端发起从本地端口N+1到服务器的端口P的连接用来传送数据。</p>
]]></content>
      <categories>
        <category>基础教程</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Shell编程-基础教程</title>
    <url>/2020/03/22/Linux-Shell%E7%BC%96%E7%A8%8B-%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<h1 id="Linux-Shell-编程"><a href="#Linux-Shell-编程" class="headerlink" title="Linux Shell 编程"></a>Linux Shell 编程</h1><p>由于Linux不同于Windows，Linux是内核与界面分离的，它可以脱离图形界面而单独运行，同样也可以在内核的基础上运行图形化的桌面。</p>
<a id="more"></a>
<p>这样，在Linux系统中，就出现了两种shell表现形式，一种是在无图形界面下的终端运行环境下的shell，另一种是桌面上运行的类似Windows 的MS-DOS运行窗口，前者我们一般习惯性地简称为终端，后者一般直接称为shell<br><img src= "/img/loading.gif" data-src="/images/shell.png" alt="Shell图解"></p>
<h1 id="什么是Shell脚本？"><a href="#什么是Shell脚本？" class="headerlink" title="什么是Shell脚本？"></a>什么是Shell脚本？</h1><p>Shell脚本（英语：Shell script）是一种电脑程序与文本文件，内容由一连串的shell命令组成，经由Unix Shell直译其内容后运作。被当成是一种脚本语言来设计，其运作方式与直译语言相当，由Unix shell扮演命令行解释器的角色，在读取shell script之后，依序运行其中的shell命令，之后输出结果。利用Shell script可以进行系统管理，文件操作等。<br>在Unix及所有的类Unix系统中，如Linux、FreeBSD等操作系统，都存在Shell Script。依照Unix shell的各种不同类型，Shell script也有各种不同方言。在DOS、OS/2、Microsoft Windows中的批处理文件，跟shell script有类似的功能。<br>来看一个实例</p>
<pre><code>#!/bin/sh
cd ~
mkdir shell_tut
cd shell_tut
for ((i=0; i&lt;10; i++)); do
    touch test_$i.txt
done
实例解析：
第1行：指定脚本解释器，这里是用/bin/sh做解释器的
第2行：切换到当前用户的home目录
第3行：创建一个目录shell_tut
第4行：切换到shell_tut目录
第5行：循环条件，一共循环10次
第6行：创建一个test_1…10.txt文件
第7行：循环体结束</code></pre><p>cd, mkdir, touch都是系统自带的程序，一般在/bin或者/usr/bin目录下。for, do, done是sh脚本语言的关键字。</p>
<h1 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h1><p>shell编程跟java、php编程一样，只要有一个能编写代码的文本编辑器和一个能解释执行的脚本解释器就可以了。<br>当前主流的操作系统都支持shell编程，本文档所述的shell编程是指Linux下的shell，讲的基本都是POSIX标准下的功能，所以，也适用于Unix及BSD（如Mac OS）。<br>Linux<br>Linux默认安装就带了shell解释器。<br>Mac OS<br>Mac OS不仅带了sh、bash这两个最基础的解释器，还内置了ksh、csh、zsh等不常用的解释器。<br>Windows上的模拟器<br>windows出厂时没有内置shell解释器，需要自行安装，为了同时能用grep, awk, curl等工具，最好装一个cygwin或者mingw来模拟linux环境。</p>
<h1 id="脚本解释器"><a href="#脚本解释器" class="headerlink" title="脚本解释器"></a>脚本解释器</h1><h1 id="sh"><a href="#sh" class="headerlink" title="sh"></a>sh</h1><p>即Bourne shell，POSIX（Portable Operating System Interface）标准的shell解释器，它的二进制文件路径通常是/bin/sh，由Bell Labs开发。</p>
<h1 id="bash"><a href="#bash" class="headerlink" title="bash"></a>bash</h1><p>Bash是Bourne shell的替代品，属GNU Project，二进制文件路径通常是/bin/bash。业界通常混用bash、sh、和shell，比如你会经常在招聘运维工程师的文案中见到：熟悉Linux Bash编程，精通Shell编程。<br>在CentOS里，/bin/sh是一个指向/bin/bash的符号链接:</p>
<pre><code>[root@centosraw ~]# ls -l /bin/*sh
-rwxr-xr-x. 1 root root 903272 Feb 22 05:09 /bin/bash
-rwxr-xr-x. 1 root root 106216 Oct 17  2012 /bin/dash
lrwxrwxrwx. 1 root root      4 Mar 22 10:22 /bin/sh -&gt; bash
但在Mac OS上不是，/bin/sh和/bin/bash是两个不同的文件，尽管它们的大小只相差100字节左右:

iMac:~ wuxiao$ ls -l /bin/*sh
-r-xr-xr-x  1 root  wheel  1371648  6 Nov 16:52 /bin/bash
-rwxr-xr-x  2 root  wheel   772992  6 Nov 16:52 /bin/csh
-r-xr-xr-x  1 root  wheel  2180736  6 Nov 16:52 /bin/ksh
-r-xr-xr-x  1 root  wheel  1371712  6 Nov 16:52 /bin/sh
-rwxr-xr-x  2 root  wheel   772992  6 Nov 16:52 /bin/tcsh
-rwxr-xr-x  1 root  wheel  1103984  6 Nov 16:52 /bin/zsh</code></pre><h1 id="高级编程语言"><a href="#高级编程语言" class="headerlink" title="高级编程语言"></a>高级编程语言</h1><p>理论上讲，只要一门语言提供了解释器（而不仅是编译器），这门语言就可以胜任脚本编程，常见的解释型语言都是可以用作脚本编程的，如：Perl、Tcl、Python、PHP、Ruby。Perl是最老牌的脚本编程语言了，Python这些年也成了一些linux发行版的预置解释器。</p>
<p>编译型语言，只要有解释器，也可以用作脚本编程，如C shell是内置的（/bin/csh），Java有第三方解释器Jshell，Ada有收费的解释器AdaScript。</p>
<p>如下是一个PHP Shell Script示例（假设文件名叫test.php）：</p>
<pre><code>#!/usr/bin/php
&lt;?php
for ($i=0; $i &lt; 10; $i++) {
    echo $i . &quot;\n&quot;;
}</code></pre><p>执行：</p>
<pre><code>/usr/bin/php test.php</code></pre><p>或者：</p>
<pre><code>chmod +x test.php
./test.php</code></pre><h1 id="如何选择shell编程语言"><a href="#如何选择shell编程语言" class="headerlink" title="如何选择shell编程语言"></a>如何选择shell编程语言</h1><h1 id="熟悉-vs-陌生"><a href="#熟悉-vs-陌生" class="headerlink" title="熟悉 vs 陌生"></a>熟悉 vs 陌生</h1><p>如果你已经掌握了一门编程语言（如PHP、Python、Java、JavaScript），建议你就直接使用这门语言编写脚本程序，虽然某些地方会有点啰嗦，但你能利用在这门语言领域里的经验（单元测试、单步调试、IDE、第三方类库）。</p>
<p>新增的学习成本很小，只要学会怎么使用shell解释器（Jshell、AdaScript）就可以了。</p>
<h1 id="简单-vs-高级"><a href="#简单-vs-高级" class="headerlink" title="简单 vs 高级"></a>简单 vs 高级</h1><p>如果你觉得自己熟悉的语言（如Java、C）写shell脚本实在太啰嗦，你只是想做一些备份文件、安装软件、下载数据之类的事情，学着使用sh，bash会是一个好主意。</p>
<p>shell只定义了一个非常简单的编程语言，所以，如果你的脚本程序复杂度较高，或者要操作的数据结构比较复杂，那么还是应该使用Python、Perl这样的脚本语言，或者是你本来就已经很擅长的高级语言。因为sh和bash在这方面很弱，比如说：</p>
<p>它的函数只能返回字串，无法返回数组<br>它不支持面向对象，你无法实现一些优雅的设计模式<br>它是解释型的，一边解释一边执行，连PHP那种预编译都不是，如果你的脚本包含错误(例如调用了不存在的函数)，只要没执行到这一行，就不会报错</p>
<h1 id="环境兼容性"><a href="#环境兼容性" class="headerlink" title="环境兼容性"></a>环境兼容性</h1><p>如果你的脚本是提供给别的用户使用，使用sh或者bash，你的脚本将具有最好的环境兼容性，perl很早就是linux标配了，python这些年也成了一些linux发行版的标配，至于mac os，它默认安装了perl、python、ruby、php、java等主流编程语言。</p>
<h1 id="写一个shell脚本"><a href="#写一个shell脚本" class="headerlink" title="写一个shell脚本"></a>写一个shell脚本</h1><p>编写</p>
<p>打开文本编辑器，新建一个文件，扩展名为sh（sh代表shell），扩展名并不影响脚本执行，见名知意就好，如果你用php写shell 脚本，扩展名就用php好了。</p>
<p>输入一些代码，第一行一般是这样：</p>
<pre><code>#!/bin/bash
#!/usr/bin/php</code></pre><p>“#!”是一个约定的标记，它告诉系统这个脚本需要什么解释器来执行。</p>
<p>运行<br>运行Shell脚本有两种方法：</p>
<p>作为可执行程序</p>
<pre><code>chmod +x test.sh
./test.sh</code></pre><p>注意，一定要写成./test.sh，而不是test.sh，运行其它二进制的程序也一样，直接写test.sh，linux系统会去PATH里寻找有没有叫test.sh的，而只有/bin, /sbin, /usr/bin，/usr/sbin等在PATH里，你的当前目录通常不在PATH里，所以写成test.sh是会找不到命令的，要用./test.sh告诉系统说，就在当前目录找。</p>
<p>通过这种方式运行bash脚本，第一行一定要写对，好让系统查找到正确的解释器。</p>
<p>这里的”系统”，其实就是shell这个应用程序（想象一下Windows Explorer），但我故意写成系统，是方便理解，既然这个系统就是指shell，那么一个使用/bin/sh作为解释器的脚本是不是可以省去第一行呢？是的。</p>
<h1 id="作为解释器参数"><a href="#作为解释器参数" class="headerlink" title="作为解释器参数"></a>作为解释器参数</h1><p>这种运行方式是，直接运行解释器，其参数就是shell脚本的文件名，如：</p>
<pre><code>/bin/sh test.sh
/bin/php test.php</code></pre><p>这种方式运行的脚本，不需要在第一行指定解释器信息，写了也没用。</p>
]]></content>
      <categories>
        <category>基础教程</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Python的 global 到底干嘛的？-PYTHON</title>
    <url>/2020/03/29/Python%E7%9A%84-global-%E5%88%B0%E5%BA%95%E5%B9%B2%E5%98%9B%E7%9A%84%EF%BC%9F-PYTHON/</url>
    <content><![CDATA[<h1 id="为什么要有global"><a href="#为什么要有global" class="headerlink" title="为什么要有global."></a>为什么要有global.</h1><a id="more"></a>
<p>一个变量被多个函数引用，想让全局变量被所有函数共享和修改。有的伙伴可能会想，这还不简单：  </p>
<pre><code>i = 5
def f():
    print(i)

def g():
    print(i)
    pass

f()
g()</code></pre><p>f和g两个函数都能共享变量i，程序也没有报错。所以他们依然不明白为什么要用global.<br>但是，如果想要对i递增，这样：  </p>
<pre><code>def h():
    i += 1

h()</code></pre><h1 id="此时执行程序，bang-出错了！抛出异常：UnboundLocalError"><a href="#此时执行程序，bang-出错了！抛出异常：UnboundLocalError" class="headerlink" title="此时执行程序，bang, 出错了！抛出异常：UnboundLocalError."></a>此时执行程序，bang, 出错了！抛出异常：UnboundLocalError.</h1><p>原因是 编译器在解释i+=1时会把i解析为函数h()内的局部变量，很显然在此函数内，编译器找不到对变量i的定义，所以会报错。</p>
<p>global就是为解决此问题而被提出的。</p>
<p>在函数h内，显示地告诉编译器i为全局变量，然后编译器会在函数外面寻找i的定义，执行完i+=1后，i还为全局变量，值加1：</p>
<pre><code>i = 0
def h():
    global i
    i += 1

h()
print(i)</code></pre><p>你懂了吗？</p>
]]></content>
      <categories>
        <category>技术资讯</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL备份与恢复</title>
    <url>/2020/04/03/MySQL%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/</url>
    <content><![CDATA[<p>备份的主要目的是灾难恢复，备份还可以测试应用、回滚数据修改、查询历史数据、审计等。</p>
<a id="more"></a>
<h1 id="一、MySQL完全备份与恢复"><a href="#一、MySQL完全备份与恢复" class="headerlink" title="一、MySQL完全备份与恢复"></a>一、MySQL完全备份与恢复</h1><p>1、数据备份的重要性<br>在企业中数据的价值至关重要，数据保障了企业业务的正常运行。因此，数据的安全性及数据的可靠性是运维的重中之重，任何数据的丢失都可能对企业产生严重的后果。<br>通常情况下造成数据丢失的原因如下几种：</p>
<pre><code>程序错误
人为操作错误
运算错误
磁盘故障
灾难（火灾、地震）和盗窃</code></pre><h1 id="二、数据库备份类型"><a href="#二、数据库备份类型" class="headerlink" title="二、数据库备份类型"></a>二、数据库备份类型</h1><p>1、从物理与逻辑的角度：<br>数据库备份可以分为物理备份和逻辑备份。物理备份是对数据库操作系统的物理文件（如数据文件、日志文件等）的备份。这种类型的备份适用于在出现问题时需要快速恢复的大型重要数据库。</p>
<pre><code>物理备份又可以分为冷备份（脱机备份）、热备份（联机备份）和温备份。
冷备份：在数据库关闭状态下进行备份操作；

热备份：在数据库处于运行状态时进行备份操作，该备份方法依赖数据库的日志文件；

温备份：数据库锁定表格（不可写入，但可读取）的状态下进行备份；

逻辑备份是对数据库逻辑组件（如表等数据库对象）的备份，表示为逻辑数据库结构（create database、create table语句）和内容（insert语句或分隔文本文件）的信息。这种类型的备份使用于可以编辑数据值或表结构较小的数据量，或者在不同的机器体系上重新创建数据。</code></pre><p>2、从数据库的备份策略角度：</p>
<pre><code>从数据库的备份策略角度，数据库的备份可分为完全备份、差异备份和增量备份。其中呢，完整备份是实现差异、增量备份的基础。

完整备份：每次对数据进行完整的备份，即对整个数据库的备份。备份与恢复的操作非常简单，但是数据存在大量的重复，会占用大量的磁盘空间，备份的时间也很长。

差异备份：备份那些自从上次完全备份之后被修改过的所有文件，备份的时间点是从上次完整备份起，备份数据会越来越大，恢复数据时，只需恢复上次的完全备份和最近的一次差异备份。

增量备份：只有在那些在上次完全备份或增量备份后被修改的文件才会被备份，以上次完整备份或上次增量备份的时间为时间点，仅仅备份这之间的数据变化，因而备份的数据量也小，占用空间小，备份速度快，但恢复时，需要从上一次的完整备份开始到最后一次增量备份之间的所有增量依次恢复，一旦中间的数据发生损坏，将导致数据的丢失。</code></pre><h1 id="三、常见的备份方法"><a href="#三、常见的备份方法" class="headerlink" title="三、常见的备份方法"></a>三、常见的备份方法</h1><p>MySQL数据库的备份可以采用很多种方式，如直接打包数据库文件（物理冷备份）、专用备份工具（mysqldump）、二进制日志增量备份、第三方工具备份等。</p>
<p>1、物理冷备份<br>物理冷备份时需要在数据库处于关闭状态下，能够较好地保证数据库的完整性。物理冷备份一般用于非核心业务，这类业务一般都允许中断，物理冷备份的特点就是速度快，恢复时也是最为简单。</p>
<p>2、专用备份工具mysqldump或mysqlhotcopy<br>mysqldump程序和mysqlhotcopy都可以做备份。mysqqldump是客户端常用逻辑备份程序，能够产生一组被执行以再现原始数据库对象定义和表数据的SQL语句。它可以转储一个到多个MySQL数据库，对其进行备份或传输到远程SQL服务器。mysqldump更为通用，因为它可以备份各种表。mysqlhotcopy仅适用于某些存储引擎。</p>
<p>3、通过启用二进制日志进行增量备份<br>MySQL支持增量备份，进行增量备份时必须启用二进制日志。二进制日志文件为用户提供复制，对执行备份点后进行的数据库更改所需的信息进行恢复。如果进行增量备份（包含自上次完全备份或增量备份以来发生的数据修改），需要刷新二进制日志。</p>
<h1 id="四、数据库完全备份操作"><a href="#四、数据库完全备份操作" class="headerlink" title="四、数据库完全备份操作"></a>四、数据库完全备份操作</h1><p>1、备份前准备</p>
<pre><code>[root@centos01 ~]# mysqladmin -u root password  &lt;!--mysql数据库设置密码--&gt;
New password:             &lt;!--输入密码--&gt;
Confirm new password:        &lt;!--确认密码--&gt;
[root@centos01 ~]# mysql -uroot -ppwd@123    &lt;!--登录MySQL数据库--&gt;
mysql&gt; create database benet;        &lt;!--创建benet数据库--&gt;
mysql&gt; use benet;             &lt;!--切换到benet数据库创建表--&gt;
mysql&gt; create table 一班学生成绩 (姓名 char(3),班级 char(5),学号 char(8),语文 char(3),
数学char(3),英语 char(3),理综 char(3), primary key (学号));  
&lt;!--创建表，表名字为一班学生成绩，第一列名字是姓名，第二列名字为班级，第三列名字
为学号，第四列名字为语文，第五列名字为数学，第六列名字为英语，第七列名字为理综--&gt;
mysql&gt; insert into 一班学生成绩 value (&#39;张三&#39;,&#39;一班&#39;,&#39;20170822&#39;,&#39;110&#39;,&#39;105&#39;,&#39;92&#39;,&#39;235&#39;);  
                   &lt;!--表中插入数据--&gt;
mysql&gt;  insert into 一班学生成绩 value (&#39;李四&#39;,&#39;一班&#39;,&#39;20170820&#39;,&#39;95&#39;,&#39;115&#39;,&#39;110&#39;,&#39;260&#39;);  
                   &lt;!--表中插入数据--&gt;
mysql&gt; insert into 一班学生成绩 value (&#39;王五&#39;,&#39;一班&#39;,&#39;20170818&#39;,&#39;95&#39;,&#39;103&#39;,&#39;108&#39;,&#39;270&#39;);  
                   &lt;!--表中插入数据--&gt;
mysql&gt; insert into 一班学生成绩 value (&#39;赵六&#39;,&#39;一班&#39;,&#39;20170816&#39;,&#39;100&#39;,&#39;109&#39;,&#39;112&#39;,&#39;265&#39;); 
                   &lt;!--表中插入数据--&gt;
mysql&gt; select * from benet.一班学生成绩;   &lt;!--查看一班学生成绩表中所有数据--&gt;</code></pre><p><img src= "/img/loading.gif" data-src="/images/sql1.png" alt="alt"><br>2、物理冷备份与恢复<br>物理冷备份一般用tar命令直接打包数据库文件夹，而在进行备份之前需要使用“systemctl stop mysqld”命令关闭mysql服务。</p>
<p>1）备份数据库<br>创建一个/bak目录作为备份数据存储路径，使用tar创建备份文件。整个数据库文件夹备份属于完全备份。</p>
<pre><code>[root@centos01 ~]# systemctl stop mysqld  &lt;!--停止mysql服务--&gt;
[root@centos01 ~]mkdir /bak/   &lt;!--创建存储备份目录--&gt;
[root@centos01 ~]# tar zcf /bak/mysql_all-$(date +%F).mysql.gz /usr/local/mysql/data/    
                 &lt;!--直接tar打包数据库文件--&gt;
[root@centos01 ~]# ls /bak/     &lt;!--查看备份的数据--&gt;
-rw-r--r-- 1 root root 766598 10月 31 03:57 /bak/mysql_all-2019-10-31.mysql.gz</code></pre><p>2）恢复数据库</p>
<pre><code>[root@centos01 ~]mkdir test  &lt;!--创建恢复数据目录--&gt;
[root@centos01 ~]# tar zxvf /bak/mysql_all-2019-10-31.mysql.gz  -C ./test/   
                &lt;!--解压缩备份数据到恢复目录--&gt;
[root@centos01 data]# cd /usr/local/mysql/data/  &lt;!--进入数据原始位置--&gt;
[root@centos01 data]# rm -rf ./*  &lt;!--删除数据--&gt;
[root@centos01 ~]# cd ./test/usr/local/mysql/data/  &lt;!--切换到恢复目录--&gt;
[root@centos01 date]#mv ./* /usr/local/mysql/data/    &lt;!--将恢复目录数据恢复到原始位置--&gt;
[root@centos01 ~]# systemctl start mysqld  &lt;!--启动mysql服务--&gt;</code></pre><p>3、mysqldump备份与恢复<br>通过mysqldump命令可以将指定的库、表或全部的库导出为SQL脚本，便于该命令在不同版本的MySQL服务器上使用。<br>1）备份恢复所有数据库</p>
<pre><code>[root@centos01 ~]# mysqldump -uroot -ppwd@123 --opt --all-databases &gt; ./test/benet_databases.sql     &lt;!--备份所有库,opt选项是优化执行速度--&gt;
[root@centos01 ~]# mysql -uroot -p     &lt;!--登录数据库--&gt;
Enter password:          &lt;!--数据密码--&gt;
mysql&gt; show databases;         &lt;!--查看所有数据库--&gt;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| benet              |
| mysql              |
| performance_schema |
| test               |
+--------------------+
mysql&gt; drop database benet;  &lt;!--删除benet数据库--&gt;
mysql&gt; show databases;      &lt;!--查看数据库是否删除--&gt;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
| test               |
+--------------------+
[root@centos01 ~]# mysql -u root -p &lt; ./test/benet_databases.sql 
Enter password:     &lt;!--恢复所有数据库--&gt;
mysql&gt; show databases;     &lt;!--查看数据库是否恢复--&gt;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| benet              |
| mysql              |
| performance_schema |
| test               |
+--------------------+
mysql&gt; source ./test/benet_databases.sql 
             &lt;!--也可以通过这种方法恢复误删除的数据库--&gt;</code></pre><p>2）备份恢复数据库中的表</p>
<pre><code>[root@centos01 ~]# mysqldump -uroo t -ppwd@123 benet 一班学生成绩 &gt; ./test/benet_一班学生成绩.sql   
                         &lt;!--备份数据库下的表--&gt;
[root@centos01 ~]# mysql -uroot -p       &lt;!--登录数据库--&gt;
Enter password:        &lt;!--输入密码--&gt;
mysql&gt; use benet;      &lt;!--切换到benet数据库--&gt;
mysql&gt; drop table 一班学生成绩;      &lt;!--删除一班学生成绩表--&gt;
mysql&gt; show tables;        &lt;!--查看表是否删除--&gt; 
Empty set (0.00 sec)
[root@centos01 ~]# mysql -uroot -p benet &lt; ./test/benet_一班学生成绩.sql  
                           &lt;!--恢复误删除的表--&gt;
[root@centos01 ~]# mysql -uroot -p    &lt;!--登录数据库--&gt;
Enter password:           &lt;!--输入密码--&gt;
mysql&gt; use benet;         &lt;!--切换到benet数据库--&gt;
Database changed
mysql&gt; show tables;    &lt;!--查看误删除的表是否恢复--&gt;
+--------------------+
| Tables_in_benet    |
+--------------------+
| 一班学生成绩       |
+--------------------+
1 row in set (0.00 sec)</code></pre><h1 id="五、MySQL增量备份与恢复"><a href="#五、MySQL增量备份与恢复" class="headerlink" title="五、MySQL增量备份与恢复"></a>五、MySQL增量备份与恢复</h1><p>使用mysqldump进行完全备份，备份的数据中有重复数据，备份时间与恢复时间过长。而增量备份就是备份自上一次备份之后增加或改变的文件或内容。</p>
<p>1、MySQL增量备份的特点<br>与完全备份不同，增量备份没有重复数据，备份量不大，时间短；但其恢复麻烦，需要上次完全备份及完全备份之后所有的增量备份才能恢复，而且要对所有增量备份进行逐个反推恢复。可以通过MySQL提供的二进制日志间接实现增量备份。</p>
<p>2、MySQL增量备份与恢复<br>二进制日志保存了所有更新或者可能更新数据库的操作。二进制日志在启动MySQL服务器后开始记录，并在文件达到二进制日志所设置的最大值或者接收到flush logs命令后重新创建新的日志文件，生成二进制文件序列，并及时把这些日志保存到安全的存储位置，即可完成一个时间段的增量备份。<br>要进行MySQL的增量备份，首先要开启二进制日志功能，开启MySQL的二进制日志功能的实现方法如下：</p>
<pre><code>[root@centos01 ~]# vim /etc/my.cnf       &lt;!--进入MySQL配置文件--&gt;
.......    &lt;!--此处省略部分内容--&gt;
log-bin=mysql-bin      &lt;!--开启二进制日志功能--&gt;
[root@centos01 ~]# systemctl restart mysqld   &lt;!--重启MySQL服务--&gt;
[root@centos01 ~]# ls -l /usr/local/mysql/data/
......             &lt;!--此处省略部分内容--&gt;
-rw-rw---- 1 mysql mysql    27299 10月 31 00:00 mysql-bin.000001
-rw-rw---- 1 mysql mysql  1031892 10月 31 00:00 mysql-bin.000002
-rw-rw---- 1 mysql mysql     1574 10月 31 14:13 mysql-bin.000003
-rw-rw---- 1 mysql mysql   507535 11月  1 09:37 mysql-bin.000004
-rw-rw---- 1 mysql mysql   507229 11月  1 09:40 mysql-bin.000005
-rw-rw---- 1 mysql mysql       95 11月  1 09:37 mysql-bin.index
drwx------ 2 mysql mysql     4096 10月 31 00:00 performance_schema
drwxr-xr-x 2 mysql mysql       20 10月 30 23:56 test</code></pre><p>1）增量备份</p>
<pre><code>[root@centos01 ~]# mysqladmin -uroot -ppwd@123 flush-logs  &lt;!--刷新二进制日志--&gt;
[root@centos01 ~]# ls -l /usr/local/mysql/data/     &lt;!--查看二进制日志文件--&gt;
......   &lt;!--此处省略部分内容--&gt;
-rw-rw---- 1 mysql mysql    27299 10月 31 00:00 mysql-bin.000001
-rw-rw---- 1 mysql mysql  1031892 10月 31 00:00 mysql-bin.000002
-rw-rw---- 1 mysql mysql     1574 10月 31 14:13 mysql-bin.000003
-rw-rw---- 1 mysql mysql   507535 11月  1 09:37 mysql-bin.000004
-rw-rw---- 1 mysql mysql   507272 11月  1 09:49 mysql-bin.000005
-rw-rw---- 1 mysql mysql      107 11月  1 09:49 mysql-bin.000006
-rw-rw---- 1 mysql mysql      114 11月  1 09:49 mysql-bin.index
drwx------ 2 mysql mysql     4096 10月 31 00:00 performance_schema
drwxr-xr-x 2 mysql mysql       20 10月 30 23:56 test
[root@centos01 ~]# mysql -uroot -ppwd@123  &lt;!--登录mysql数据库--&gt;
mysql&gt; use benet;           &lt;!--切换到benet数据库--&gt;
mysql&gt; insert into 一班学生成绩 value (&#39;李宁&#39;,&#39;二班&#39;,&#39;20170824&#39;,&#39;92&#39;,&#39;98&#39;,&#39;105&#39;,&#39;235&#39;);            
                    &lt;!--录入新的数据--&gt;
Query OK, 1 row affected (0.01 sec)
mysql&gt; insert into 一班学生成绩 value (&#39;陈铭&#39;,&#39;二班&#39;,&#39;20170826&#39;,&#39;111&#39;,&#39;107&#39;,&#39;96&#39;,&#39;204&#39;);           
                    &lt;!--录入新的数据--&gt;
Query OK, 1 row affected (0.00 sec)
mysql&gt; select *from 一班学生成绩;    &lt;!--查看新数据是否录入--&gt;
+--------+--------+----------+--------+--------+--------+--------+
| 姓名   | 班级   | 学号     | 语文   | 数学   | 英语   | 理综   |
+--------+--------+----------+--------+--------+--------+--------+
| 赵六   | 一班   | 20170816 | 100    | 109    | 112    | 265    |
| 王五   | 一班   | 20170818 | 95     | 103    | 108    | 270    |
| 李四   | 一班   | 20170820 | 95     | 115    | 110    | 260    |
| 张三   | 一班   | 20170822 | 110    | 105    | 92     | 235    |
| 李宁   | 二班   | 20170824 | 92     | 98     | 105    | 235    |
| 陈铭   | 二班   | 20170826 | 111    | 107    | 96     | 204    |
+--------+--------+----------+--------+--------+--------+--------+
6 rows in set (0.00 sec)
[root@centos01 ~]# mysqladmin -uroot -ppwd@123 flush-logs  
                          &lt;!--刷新二进制日志--&gt;
[root@centos01 ~]# ls -l /usr/local/mysql/data/    
                               &lt;!--查看二进制日志文件--&gt;
......          &lt;!--此处省略部分内容--&gt;
-rw-rw---- 1 mysql mysql    27299 10月 31 00:00 mysql-bin.000001
-rw-rw---- 1 mysql mysql  1031892 10月 31 00:00 mysql-bin.000002
-rw-rw---- 1 mysql mysql     1574 10月 31 14:13 mysql-bin.000003
-rw-rw---- 1 mysql mysql   507535 11月  1 09:37 mysql-bin.000004
-rw-rw---- 1 mysql mysql   507272 11月  1 09:49 mysql-bin.000005
-rw-rw---- 1 mysql mysql      649 11月  1 09:58 mysql-bin.000006
-rw-rw---- 1 mysql mysql      107 11月  1 09:58 mysql-bin.000007
-rw-rw---- 1 mysql mysql      133 11月  1 09:58 mysql-bin.index
drwx------ 2 mysql mysql     4096 10月 31 00:00 performance_schema
drwxr-xr-x 2 mysql mysql       20 10月 30 23:56 test
[root@centos01 ~]# cp /usr/local/mysql/data/mysql-bin.000006 /root/test/   
                            &lt;!--复制二进制日志--&gt;</code></pre><p>2）模拟误操作删除一班学生成绩表</p>
<pre><code>[root@centos01 ~]# mysql -uroot -ppwd@123 -e &#39;drop table benet.一班学生成绩;&#39;       
                    &lt;!--删除一班学生成绩表--&gt;
[root@centos01 ~]# mysql -uroot -ppwd@123 -e &#39;select * from benet.一班学生成绩;&#39;   
                      &lt;!--查看表是否删除--&gt;
ERROR 1146 (42S02) at line 1: Table &#39;benet.一班学生成绩&#39; doesn&#39;t exist
3）恢复误删除的表
[root@centos01 ~]# mysql -uroot -ppwd@123 &lt; ./test/benet_databases.sql   
                     &lt;!--恢复完全备份--&gt;
[root@centos01 ~]# mysql -uroot -ppwd@123 -e &#39;select * from benet.一班学生成绩;&#39;        
                        &lt;!--查看完全备份数据是否恢复--&gt;
+--------+--------+----------+--------+--------+--------+--------+
| 姓名   | 班级   | 学号     | 语文   | 数学   | 英语   | 理综   |
+--------+--------+----------+--------+--------+--------+--------+
| 赵六   | 一班   | 20170816 | 100    | 109    | 112    | 265    |
| 王五   | 一班   | 20170818 | 95     | 103    | 108    | 270    |
| 李四   | 一班   | 20170820 | 95     | 115    | 110    | 260    |
| 张三   | 一班   | 20170822 | 110    | 105    | 92     | 235    |
+--------+--------+----------+--------+--------+--------+--------+
[root@centos01 ~]# mysqlbinlog --no-defaults /root/test/mysql-bin.000006 |mysql -u root -p 
                   &lt;!--恢复增量备份--&gt;
Enter password:       &lt;!--输入密码--&gt;
[root@centos01 ~]# mysql -uroot -ppwd@123 -e &#39;select * from benet.一班学生成绩;&#39;      
                     &lt;!--查看增量恢复数据是否恢复--&gt;
+--------+--------+----------+--------+--------+--------+--------+
| 姓名   | 班级   | 学号     | 语文   | 数学   | 英语   | 理综   |
+--------+--------+----------+--------+--------+--------+--------+
| 赵六   | 一班   | 20170816 | 100    | 109    | 112    | 265    |
| 王五   | 一班   | 20170818 | 95     | 103    | 108    | 270    |
| 李四   | 一班   | 20170820 | 95     | 115    | 110    | 260    |
| 张三   | 一班   | 20170822 | 110    | 105    | 92     | 235    |
| 李宁   | 二班   | 20170824 | 92     | 98     | 105    | 235    |
| 陈铭   | 二班   | 20170826 | 111    | 107    | 96     | 204    |
+--------+--------+----------+--------+--------+--------+--------+</code></pre><p>3、基于位置恢复</p>
<pre><code>[root@centos01 ~]# mysql -uroot -ppwd@123 -e &#39;drop table benet.一班学生成绩;&#39;   
                &lt;!--删除一班学生成绩表--&gt;
[root@centos01 ~]# mysql -uroot -ppwd@123 -e &#39;select * from benet.一班学生成绩;&#39;  
                 &lt;!--查看表是否删除--&gt;
ERROR 1146 (42S02) at line 1: Table &#39;benet.一班学生成绩&#39; doesn&#39;t exist
[root@centos01 ~]# mysql -uroot -ppwd@123 &lt; ./test/benet_databases.sql     
               &lt;!--恢复完全备份--&gt;
[root@centos01 ~]# mysql -uroot -ppwd@123 -e &#39;select * from benet.一班学生成绩;&#39;     
               &lt;!--查看完全备份是否恢复--&gt;
+--------+--------+----------+--------+--------+--------+--------+
| 姓名   | 班级   | 学号     | 语文   | 数学   | 英语   | 理综   |
+--------+--------+----------+--------+--------+--------+--------+
| 赵六   | 一班   | 20170816 | 100    | 109    | 112    | 265    |
| 王五   | 一班   | 20170818 | 95     | 103    | 108    | 270    |
| 李四   | 一班   | 20170820 | 95     | 115    | 110    | 260    |
| 张三   | 一班   | 20170822 | 110    | 105    | 92     | 235    |
+--------+--------+----------+--------+--------+--------+--------+
[root@centos01 ~]# mysqlbinlog --no-defaults /root/test/mysql-bin.000006       
                &lt;!--查看二进制日志文件确认恢复的位置或时间点--&gt;
......         &lt;!--此处省略部分内容--&gt;
# at 176                  &lt;!--at就是我们称之为操作ID，下面紧跟的是时间标记--&gt;
#191101  9:55:33 server id 1  end_log_pos 329   Query   thread_id=9 exec_time=0 error_code=0
use benet/*!*/;
SET TIMESTAMP=1572573333/*!*/;
insert into 一班学生成绩 value (&#39;李宁&#39;,&#39;二班&#39;,&#39;20170824&#39;,&#39;92&#39;,&#39;98&#39;,&#39;105&#39;,&#39;235&#39;)
/*!*/;
# at 329
#191101  9:55:33 server id 1  end_log_pos 356   Xid = 278
COMMIT/*!*/;
# at 356
#191101  9:55:43 server id 1  end_log_pos 425   Query   thread_id=9 exec_time=0 error_code=0
SET TIMESTAMP=1572573343/*!*/;
BEGIN
/*!*/;
# at 425       &lt;!--at就是我们称之为操作ID，下面紧跟的是时间标记--&gt;
#191101  9:55:43 server id 1  end_log_pos 579   Query   thread_id=9 exec_time=0 error_code=0
SET TIMESTAMP=1572573343/*!*/;
insert into 一班学生成绩 value (&#39;陈铭&#39;,&#39;二班&#39;,&#39;20170826&#39;,&#39;111&#39;,&#39;107&#39;,&#39;96&#39;,&#39;204&#39;)
/*!*/;
[root@centos01 ~]# mysqlbinlog --no-defaults --stop-position=&#39;425&#39; /root/test/mysql-bin.000006 |mysql -uroot -p       &lt;!--基于ID恢复增量备份--&gt;
Enter password:       &lt;!--输入密码--&gt;
[root@centos01 ~]# mysql -uroot -ppwd@123 -e &#39;select * from benet.一班学生成绩;&#39;    
               &lt;!--查看数据是否恢复--&gt;
+--------+--------+----------+--------+--------+--------+--------+
| 姓名   | 班级   | 学号     | 语文   | 数学   | 英语   | 理综   |
+--------+--------+----------+--------+--------+--------+--------+
| 赵六   | 一班   | 20170816 | 100    | 109    | 112    | 265    |
| 王五   | 一班   | 20170818 | 95     | 103    | 108    | 270    |
| 李四   | 一班   | 20170820 | 95     | 115    | 110    | 260    |
| 张三   | 一班   | 20170822 | 110    | 105    | 92     | 235    |
| 李宁   | 二班   | 20170824 | 92     | 98     | 105    | 235    |
+--------+--------+----------+--------+--------+--------+--------+</code></pre><p>上述命令中“–stop-position”指定的是停止的位置，如果仅恢复“陈铭”的信息，跳过“李宁”的信息恢复，可以使用“–start-position”选项指定开始恢复数据的位置。这时所恢复的数据是从指定位置开始直到二进制日志文件的最后。</p>
<pre><code>[root@centos01 ~]# mysql -uroot -ppwd@123 -e &#39;drop table benet.一班学生成绩;&#39;    
                   &lt;!--删除一班学生成绩表--&gt;
[root@centos01 ~]# mysql -uroot -ppwd@123 -e &#39;select * from benet.一班学生成绩;&#39;  
                  &lt;!--查看表是否删除--&gt;
ERROR 1146 (42S02) at line 1: Table &#39;benet.一班学生成绩&#39; doesn&#39;t exist
[root@centos01 ~]# mysql -uroot -ppwd@123 &lt; ./test/benet_databases.sql      
                          &lt;!--恢复完全备份--&gt;
[root@centos01 ~]# mysqlbinlog --no-defaults --start-position=&#39;425&#39; /root/test/mysql-bin.000006 |mysql -uroot -p       &lt;!--基于ID恢复增量备份--&gt;
Enter password:        &lt;!--输入密码--&gt;
[root@centos01 ~]# mysql -uroot -ppwd@123 -e &#39;select * from benet.一班学生成绩;&#39;    
                 &lt;!--查看数据是否恢复--&gt;
+--------+--------+----------+--------+--------+--------+--------+
| 姓名   | 班级   | 学号     | 语文   | 数学   | 英语   | 理综   |
+--------+--------+----------+--------+--------+--------+--------+
| 赵六   | 一班   | 20170816 | 100    | 109    | 112    | 265    |
| 王五   | 一班   | 20170818 | 95     | 103    | 108    | 270    |
| 李四   | 一班   | 20170820 | 95     | 115    | 110    | 260    |
| 张三   | 一班   | 20170822 | 110    | 105    | 92     | 235    |
| 陈铭   | 二班   | 20170826 | 111    | 107    | 96     | 204    |
+--------+--------+----------+--------+--------+--------+--------+</code></pre><p>4、基于时间点恢复<br>基于时间点恢复数据所使用的选项是“–stop-datetime”，指定的时间同样也是查询二进制日志所得。执行一下操作可以实现仅恢复到9:55:43之前的数据，即不恢复“陈铭”的信息。</p>
<pre><code>[root@centos01 ~]# mysql -uroot -ppwd@123 -e &#39;drop table benet.一班学生成绩;&#39; 
                      &lt;!--删除一班学生成绩表--&gt;
[root@centos01 ~]# mysql -uroot -ppwd@123 -e &#39;select * from benet.一班学生成绩;&#39;  
                 &lt;!--查看表是否删除--&gt;
ERROR 1146 (42S02) at line 1: Table &#39;benet.一班学生成绩&#39; doesn&#39;t exist
[root@centos01 ~]# mysql -uroot -ppwd@123 &lt; ./test/benet_databases.sql    
                   &lt;!--恢复完全备份--&gt;
[root@centos01 ~]# mysqlbinlog --no-defaults --stop-datetime=&#39;2019-11-01  9:55:43&#39; /root/test/mysql-bin.000006 |mysql -uroot -p     
                         &lt;!--基于时间点恢复增量备份--&gt;
Enter password:       &lt;!--输入密码--&gt;
[root@centos01 ~]# mysql -uroot -ppwd@123 -e &#39;select * from benet.一班学生成绩;&#39;    
                           &lt;!--查看数据是否恢复--&gt;
+--------+--------+----------+--------+--------+--------+--------+
| 姓名   | 班级   | 学号     | 语文   | 数学   | 英语   | 理综   |
+--------+--------+----------+--------+--------+--------+--------+
| 赵六   | 一班   | 20170816 | 100    | 109    | 112    | 265    |
| 王五   | 一班   | 20170818 | 95     | 103    | 108    | 270    |
| 李四   | 一班   | 20170820 | 95     | 115    | 110    | 260    |
| 张三   | 一班   | 20170822 | 110    | 105    | 92     | 235    |
| 李宁   | 二班   | 20170824 | 92     | 98     | 105    | 235    |
+--------+--------+----------+--------+--------+--------+--------+
执行以下操作可以实现仅恢复“陈铭”的信息，跳过“李宁”的信息恢复

[root@centos01 ~]# mysql -uroot -ppwd@123 -e &#39;drop table benet.一班学生成绩;&#39;   
                      &lt;!--删除一班学生成绩表--&gt;
[root@centos01 ~]# mysql -uroot -ppwd@123 -e &#39;select * from benet.一班学生成绩;&#39;    
                 &lt;!--查看表是否删除--&gt;
ERROR 1146 (42S02) at line 1: Table &#39;benet.一班学生成绩&#39; doesn&#39;t exist
[root@centos01 ~]# mysql -uroot -ppwd@123 &lt; ./test/benet_databases.sql     
                         &lt;!--恢复完全备份--&gt;
[root@centos01 ~]# mysqlbinlog --no-defaults --start-datetime=&#39;2019-11-01 9:55:43&#39;
/root/test/mysql-bin.000006 |mysql -uroot -p      
                      &lt;!--基于时间恢复增量备份--&gt;
Enter password:        &lt;!--输入密码--&gt;
[root@centos01 ~]# mysql -uroot -ppwd@123 -e &#39;select * from benet.一班学生成绩;&#39;    
                       &lt;!--查看数据是否恢复--&gt;
+--------+--------+----------+--------+--------+--------+--------+
| 姓名   | 班级   | 学号     | 语文   | 数学   | 英语   | 理综   |
+--------+--------+----------+--------+--------+--------+--------+
| 赵六   | 一班   | 20170816 | 100    | 109    | 112    | 265    |
| 王五   | 一班   | 20170818 | 95     | 103    | 108    | 270    |
| 李四   | 一班   | 20170820 | 95     | 115    | 110    | 260    |
| 张三   | 一班   | 20170822 | 110    | 105    | 92     | 235    |
| 陈铭   | 二班   | 20170826 | 111    | 107    | 96     | 204    |
+--------+--------+----------+--------+--------+--------+--------+</code></pre>]]></content>
      <categories>
        <category>技术试验</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>SQLAlchemy--基本增删改查-PYTHON</title>
    <url>/2020/03/30/SQLAlchemy-%E5%9F%BA%E6%9C%AC%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5-PYTHON/</url>
    <content><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>SQLAlchemy是一个基于Python实现的ORM框架。该框架建立在 DB API之上，使用关系对象映射进行数据库操作，简言之便是：将类和对象转换成SQL，然后使用数据API执行SQL并获取执行结果。</p>
<a id="more"></a>
<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><pre><code>pip install sqlalchemy</code></pre><h1 id="组成部分"><a href="#组成部分" class="headerlink" title="组成部分"></a>组成部分</h1><pre><code>Engine：框架的引擎
Connection Pooling：数据库连接池
Dialect：选择连接数据库的DB API种类
Schema/Types：架构和类型
SQL Exprression Language：SQL表达式语言</code></pre><p>SQLAlchemy本身无法操作数据库，其必须以来pymsql等第三方插件，Dialect用于和数据API进行交流，根据配置文件的不同调用不同的数据库API，从而实现对数据库的操作，如：  </p>
<pre><code>MySQL-Python
    mysql+mysqldb://&lt;user&gt;:&lt;password&gt;@&lt;host&gt;[:&lt;port&gt;]/&lt;dbname&gt;

pymysql
    mysql+pymysql://&lt;username&gt;:&lt;password&gt;@&lt;host&gt;/&lt;dbname&gt;[?&lt;options&gt;]

MySQL-Connector
    mysql+mysqlconnector://&lt;user&gt;:&lt;password&gt;@&lt;host&gt;[:&lt;port&gt;]/&lt;dbname&gt;

cx_Oracle
    oracle+cx_oracle://user:pass@host:port/dbname[?key=value&amp;key=value...]

更多：http://docs.sqlalchemy.org/en/latest/dialects/index.html</code></pre><p>django中如何反向生成models</p>
<pre><code>python manage.py inspectdb &gt; app/models.py</code></pre><h1 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h1><p>SQLAlchemy只能创建表，删除表，不能在原先的表上在进行修改，如果要进行修改，可以在数据库进行修改，然后再在对应的类上进行修改。  </p>
<h1 id="执行原生SQL（不常用）"><a href="#执行原生SQL（不常用）" class="headerlink" title="执行原生SQL（不常用）"></a>执行原生SQL（不常用）</h1><pre><code>import time
import threading
import sqlalchemy
from sqlalchemy import create_engine
from sqlalchemy.engine.base import Engine
engine = create_engine(
    &quot;mysql+pymysql://root:123456@127.0.0.1:3306/test?charset=utf8&quot;,
    max_overflow=0,  # 超过连接池大小外最多创建的连接
    pool_size=5,  # 连接池大小
    pool_timeout=30,  # 池中没有线程最多等待的时间，否则报错
    pool_recycle=-1  # 多久之后对线程池中的线程进行一次连接的回收（重置）
)
def task(arg):
    conn = engine.raw_connection()
    cursor = conn.cursor()
    cursor.execute(
        &quot;select * from app01_book&quot;
    )
    result = cursor.fetchall()
    print(result)
    cursor.close()
    conn.close()
for i in range(20):
    t = threading.Thread(target=task, args=(i,))
    t.start()</code></pre><h1 id="orm使用（重点）"><a href="#orm使用（重点）" class="headerlink" title="orm使用（重点）"></a>orm使用（重点）</h1><p>连接</p>
<pre><code>from sqlalchemy import create_engine</code></pre><p>create_engine()返回一个Engine的实例，并且它表示通过数据库语法处理细节的核心接口，在这种情况下，数据库语法将会被解释称Python的类方法</p>
<pre><code>engine = create_engine(&#39;mysql+pymysql://root:123456@localhost:3306/test&#39;,echo=True)</code></pre><p>连接 echo参数为True时，会显示每条执行的sql语句</p>
<pre><code>engine = create_engine(&#39;mysql+pymysql://root:123456@localhost:3306/test&#39;)</code></pre><p>声明映像<br>通过使用Declarative方法，我们可以创建一些包含描述要被映射的实际数据库表的准则的映射类。<br>使用Declarative方法定义的映射类依据一个基类，这个基类是维系类和数据表关系的目录——我们所说的Declarative base class。在一个普通的模块入口中，应用通常只需要有一个base的实例。我们通过declarative_base()功能创建一个基类：</p>
<pre><code>from sqlalchemy.ext.declarative import declarative_base
Base = declarative_base()</code></pre><p>有了这个Base，我们可以依据这个base定义任意数量的映射类：</p>
<pre><code>class User(Base):
    __tablename__ = &#39;users&#39;  # 数据库表名称
    id = Column(Integer, primary_key=True)  # id 主键
    name = Column(String(32), index=True, nullable=False)  # name列，索引，不可为空
    # email = Column(String(32), unique=True)
    #datetime.datetime.now不能加括号，加了括号，以后永远是当前时间
    # ctime = Column(DateTime, default=datetime.datetime.now)
    # extra = Column(Text, nullable=True)
    __table_args__ = (
        # UniqueConstraint(&#39;id&#39;, &#39;name&#39;, name=&#39;uix_id_name&#39;), #联合唯一
        # Index(&#39;ix_id_name&#39;, &#39;name&#39;, &#39;email&#39;), #索引
    )</code></pre><p>注意: 用Declarative 构造的一个类至少需要一个tablename属性，一个主键行。  </p>
<h1 id="生成表"><a href="#生成表" class="headerlink" title="生成表"></a>生成表</h1><p>SQLAlchemy不能通过类似于与django的makemigerations和migerate自动生成表，需要我们自己进行表的生成</p>
<pre><code>def init_db():
    &quot;&quot;&quot;
    根据类创建数据库表
    :return:
    &quot;&quot;&quot;
    engine = create_engine(
        &quot;mysql+pymysql://root:123456@127.0.0.1:3306/aaa?charset=utf8&quot;,
        max_overflow=0,  # 超过连接池大小外最多创建的连接
        pool_size=5,  # 连接池大小
        pool_timeout=30,  # 池中没有线程最多等待的时间，否则报错
        pool_recycle=-1  # 多久之后对线程池中的线程进行一次连接的回收（重置）
    )
    Base.metadata.create_all(engine)</code></pre><h1 id="更改表字段"><a href="#更改表字段" class="headerlink" title="更改表字段"></a>更改表字段</h1><p>SQLAlchemy不支持在表创建完成后，再进行表里面的字段进行修改，增加，删除，所以如果要进行表的字段修改，有两种方法：<br>手动修改数据库，然后再在对应的类上进行字段的修改<br>删除表，然后修改字段后，再创建表</p>
<h1 id="删除表"><a href="#删除表" class="headerlink" title="删除表"></a>删除表</h1><pre><code>def drop_db():
    &quot;&quot;&quot;
    根据类删除数据库表
    :return:
    &quot;&quot;&quot;
    engine = create_engine(
        &quot;mysql+pymysql://root:123456@127.0.0.1:3306/aaa?charset=utf8&quot;,
        max_overflow=0,  # 超过连接池大小外最多创建的连接
        pool_size=5,  # 连接池大小
        pool_timeout=30,  # 池中没有线程最多等待的时间，否则报错
        pool_recycle=-1  # 多久之后对线程池中的线程进行一次连接的回收（重置）
    )
    Base.metadata.drop_all(engine)</code></pre><p>完整代码</p>
<pre><code>import datetime
from sqlalchemy import create_engine
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy import Column, Integer, String, Text, ForeignKey, DateTime, UniqueConstraint, Index
Base = declarative_base()
class Users(Base):
    __tablename__ = &#39;users&#39;  # 数据库表名称
    id = Column(Integer, primary_key=True)  # id 主键
    name = Column(String(32), index=True, nullable=False)  # name列，索引，不可为空
    age = Column(Integer, default=0)
    # email = Column(String(32), unique=True)
    #datetime.datetime.now不能加括号，加了括号，以后永远是当前时间
    # ctime = Column(DateTime, default=datetime.datetime.now)
    # extra = Column(Text, nullable=True)
    __table_args__ = (
        # UniqueConstraint(&#39;id&#39;, &#39;name&#39;, name=&#39;uix_id_name&#39;), #联合唯一
        # Index(&#39;ix_id_name&#39;, &#39;name&#39;, &#39;email&#39;), #索引
    )
def init_db():
    &quot;&quot;&quot;
    根据类创建数据库表
    :return:
    &quot;&quot;&quot;
    engine = create_engine(
        &quot;mysql+pymysql://root:123456@127.0.0.1:3306/aaa?charset=utf8&quot;,
        max_overflow=0,  # 超过连接池大小外最多创建的连接
        pool_size=5,  # 连接池大小
        pool_timeout=30,  # 池中没有线程最多等待的时间，否则报错
        pool_recycle=-1  # 多久之后对线程池中的线程进行一次连接的回收（重置）
    )
    Base.metadata.create_all(engine)
def drop_db():
    &quot;&quot;&quot;
    根据类删除数据库表
    :return:
    &quot;&quot;&quot;
    engine = create_engine(
        &quot;mysql+pymysql://root:123456@127.0.0.1:3306/aaa?charset=utf8&quot;,
        max_overflow=0,  # 超过连接池大小外最多创建的连接
        pool_size=5,  # 连接池大小
        pool_timeout=30,  # 池中没有线程最多等待的时间，否则报错
        pool_recycle=-1  # 多久之后对线程池中的线程进行一次连接的回收（重置）
    )
    Base.metadata.drop_all(engine)
if __name__ == &#39;__main__&#39;:
    # drop_db()
    init_db()</code></pre><h1 id="常用操作（CURD）"><a href="#常用操作（CURD）" class="headerlink" title="常用操作（CURD）"></a>常用操作（CURD）</h1><p>创建映射类的实例</p>
<pre><code>user1 = User(name=&#39;hades&#39;, age=18)
user2 = User(name=&#39;bonnie&#39;, age=16)</code></pre><h1 id="创建会话Session"><a href="#创建会话Session" class="headerlink" title="创建会话Session"></a>创建会话Session</h1><p>准备好和数据库会话了，ORM通过Session与数据库建立连接的</p>
<p>当应用第一次载入时，我们定义一个Session类（声明Create_engine()的同时），这个Session类为新的Session对象提供工厂服务。</p>
<pre><code>from sqlalchemy.orm import sessionmaker
Session = sessionmaker(bind=engine)</code></pre><p>这个定制的Session类会创建绑定到数据库的Session对象。如果需要和数据库建立连接，只需要实例化一个session对象</p>
<pre><code>session =Session()</code></pre><p>虽然上面的Session已经和数据库引擎Engine关联，但是还没有打开任何连接。当它第一次被使用时，就会从Engine维护的一个连接池中检索是否存在连接，如果存在便会保持连接知道我们提交所有更改并且/或者关闭session对象。</p>
<h1 id="增加add-add-all"><a href="#增加add-add-all" class="headerlink" title="增加add()/add_all()"></a>增加add()/add_all()</h1><pre><code># 增加一个
session.add(user1)
session.add(user2)</code></pre><pre><code># 增加多个,可以增加不同的映射实例
# session.add_all([user1, user2, Hosts(ip=&#39;127.0.0.1&#39;)])</code></pre><h1 id="提交commit"><a href="#提交commit" class="headerlink" title="提交commit()"></a>提交commit()</h1><p>至此，我们可以认为，新添加的这个对象实例还在等待着；user1对象现在并不代表数据库中的一行数据。直到使用flush进程，Session才会让SQL保持连接。如果查询这条数据的话，所有等待信息会被第一时间刷新，查询结果也会立即发行。</p>
<p>通过commit()可以提交所有剩余的更改到数据库。<br>注意：提交、查询都会执行所有的等待信息。<br>所有的增加，修改，删除都需要commit提交</p>
<pre><code> session.commit()</code></pre><h1 id="回滚rollback"><a href="#回滚rollback" class="headerlink" title="回滚rollback()"></a>回滚rollback()</h1><pre><code>session.rollback()</code></pre><h1 id="查询-重点"><a href="#查询-重点" class="headerlink" title="查询(重点)"></a>查询(重点)</h1><p>通过Session的query()方法创建一个查询对象。这个函数的参数数量是可变的，参数可以是任何类或者类的描述集合</p>
<p>下面是一个迭代输出User类的例子：</p>
<pre><code>查询第一个
session.query(Users).filter_by(name=&#39;lqz&#39;).first()</code></pre><h1 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h1><pre><code>session.query(User).order_by(User.id).all()
desc(): 降序，一定要加（）
session.query(User).order_by(User.id.desc()).all()
asc()：升序
session.query(User).order_by(Users.name.desc(),User.id.asc()).all()</code></pre><p>Query也支持ORM描述作为参数。任何时候，多个类的实体或者是基于列的实体表达都可以作为query()函数的参数，返回类型是元组：</p>
<pre><code>session.query(User.name,User.fullname)
session.query(User,User.name).all()</code></pre><h1 id="起别名"><a href="#起别名" class="headerlink" title="起别名"></a>起别名</h1><p>字段起别名： label()相当于row.name</p>
<pre><code>session.query(User.name.label(&quot;name_label&quot;)).all()</code></pre><p>表起别名：aliased()</p>
<pre><code>from sqlalchemy.orm import aliased
user_alias = aliased(User,name=&#39;user_alias&#39;)
session.query(user_alias,user_alias.name).all()
Query 的基本操作包括LIMIT和OFFSET，使用python数组切片和ORDERBY结合可以让操作变得很方便。</code></pre><h1 id="限制"><a href="#限制" class="headerlink" title="限制"></a>限制</h1><p>用于分页，区间<br>只查询第二条和第三条数据</p>
<pre><code>session.query(User).order_by(User.id)[1:3]</code></pre><h1 id="过滤"><a href="#过滤" class="headerlink" title="过滤"></a>过滤</h1><p>使用关键字变量过滤查询结果，filter 和filter_by都使用</p>
<pre><code>filter传的是表达式，filter_by传的是参数
session.query(User).filter(User.name==&#39;hades&#39;).all()
session.query(User).filter_by(name=&#39;bonnie&#39;).all()</code></pre><h1 id="filter与filter-by的区别："><a href="#filter与filter-by的区别：" class="headerlink" title="filter与filter_by的区别："></a>filter与filter_by的区别：</h1><pre><code>filter：可以使用&gt; &lt; 等，但是列必须是： 表.列， filter的等于号是==
filter：不支持组合查询
filter_by： 可以直接写列，不支持&lt; &gt; filter_by 等于是==
filter_by 可以支持组合查询</code></pre><h1 id="过滤方法"><a href="#过滤方法" class="headerlink" title="过滤方法"></a>过滤方法</h1><p>equals</p>
<pre><code>session.query(User).filter(User.name == &#39;ed&#39;)
not equals

session.query(User).filter(User.name != &#39;ed&#39;)
like

session.query(User).filter(User.name.like(&#39;%ed%&#39;))
in

query.filter(User.name.in_([&#39;ed&#39;,&#39;wendy&#39;,&#39;jack&#39;]))</code></pre><h1 id="子查询"><a href="#子查询" class="headerlink" title="子查询"></a>子查询</h1><pre><code>session.query(User).filter(User.name.in_(session.query(User.name).filter(User.name.like(&#39;%ed%&#39;))
not in

query.filter(~User.name.in_(&#39;ed&#39;,&#39;wendy&#39;,&#39;jack&#39;))
is null

session.query(User).filter(User.name == None) 
is not null

session.query(User).filter(User.name != None)
and

session.query(Users).filter(and_(User.name ==&#39;ed&#39;,User.fullname ==&#39;Ed Jones&#39;)) # and
session.query(Users).filter(User.name == &#39;ed&#39;,User.fullname ==&#39;Ed Jones&#39;) # and
session.query(Users).filter(User.name == &#39;ed&#39;).filter(User.fullname == &#39;Ed Jones&#39;)# and
or

query.filter(or_(User.name=&#39;ed&#39;, User.name=&#39;wendy&#39;))</code></pre><h1 id="占位符查找"><a href="#占位符查找" class="headerlink" title="占位符查找"></a>占位符查找</h1><pre><code>#:value 和:name 相当于占位符，用params传参数
session.query(Users).filter(text(&quot;id&lt;:value and name=:name&quot;)).params(value=224, name=&#39;fred&#39;).order_by(Users.id).all()</code></pre><h1 id="自定义查询sql"><a href="#自定义查询sql" class="headerlink" title="自定义查询sql"></a>自定义查询sql</h1><pre><code>session.query(Users).from_statement(text(&quot;SELECT * FROM users where name=:name&quot;)).params(name=&#39;ed&#39;).all()</code></pre><h1 id="统计计数"><a href="#统计计数" class="headerlink" title="统计计数"></a>统计计数</h1><pre><code>count = session.query(User).filter(User.name.like(&quot;%t%&quot;)).count()</code></pre><h1 id="分组"><a href="#分组" class="headerlink" title="分组"></a>分组</h1><pre><code>session.query(func.count(User.name),User.name).group_by(User.name)</code></pre><h1 id="having"><a href="#having" class="headerlink" title="having"></a>having</h1><p>having作为分组的筛选条件</p>
<pre><code>session.query(func.min(User.id), func.avg(User.id)).group_by(Users.name).having(func.min(Users.id) &gt;2).all()</code></pre><h1 id="聚合函数"><a href="#聚合函数" class="headerlink" title="聚合函数"></a>聚合函数</h1><pre><code>func.count：统计行的数量，和count作用一样
fc=session.query(func.count(User.name),User.name).group_by(User.name).all()
func.avg：求平均值
fc=session.query(func.avg(User.age),User.name).group_by(User.name).all()
func.max：求最大值
fc=session.query(func.max(User.age),User.name).group_by(User.name).all()
func.min：求最小值
fc=session.query(func.min(User.age),User.name).group_by(User.name).all()
func.sum：求和
fc=session.query(func.sum(User.age),User.name).group_by(User.name).all()</code></pre><h1 id="修改"><a href="#修改" class="headerlink" title="修改"></a>修改</h1><p>第一种：先查询出对象，然后再赋予对象字段新的值</p>
<pre><code>obj = session.query(User).filter(User.name==&#39;hades&#39;).first()
obj.age = 27
session.commit()  # 一定要提交</code></pre><p>第二种：update()方法，需要传入一个字典</p>
<pre><code>session.query(User).filter(User.name==&#39;hades&#39;).update({&#39;age&#39;:27})
session.commit()  # 一定要提交</code></pre><p>第三种：在原先的基础上增加，类似于django中的F查询</p>
<pre><code>比如：年龄加1岁
注意：后面必须配合synchronize_session
字符串：synchronize_session=False
数字类型：synchronize_session=evaluata
session.query(User).filter(User.id &gt; 0).update({User.name: User.name + &quot;099&quot;}, synchronize_session=False)
# session.query(User).filter(User.id &gt; 0).update({&quot;age&quot;: User.age + 1}, synchronize_session=&quot;evaluate&quot;)
# session.commit()
# 删除delete()
session.query(Users).filter(Users.id &gt; 4).delete()
session.commit()</code></pre>]]></content>
      <categories>
        <category>技术资讯</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>TensorFlow 神经网络教程---机器学习</title>
    <url>/2020/06/01/TensorFlow-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%95%99%E7%A8%8B-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<p>TensorFlow 是一个用于机器学习应用程序的开源库。<a id="more"></a>它是谷歌大脑的第二代系统，在取代了近源的 DistBelief 之后，被谷歌用于研究和生产应用。TensorFlow 提供了很多种语言接口，包括 Python、C++、Go、Java 和 C 等等。考虑到普遍性和易学性，本文将采用 Python 版本，并且会简单介绍下 TensorFlow 的安装和它的一些低阶 API，以及从头开始构建基于真实数据集的前馈神经网络。</p>
<p>在更为复杂的应用场景下，神经网络的训练时长往往是一种特别需要克服的因素。由于神经网络以及其他机器学习算法主要在处理矩阵乘法，因此在 GPU 上运行要比在 CPU 上快得多（当然有个别情况除外）。<br>TensorFlow 支持 CPU 和 GPU，Google 甚至还研究出了 TensorFlow 专用的云计算硬件，叫做 Tensor Processing Unit（TPU），可在训练中达到更好的性能。</p>
<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>虽然 TPU 仅在云中可用，但 TensorFlow 在本地计算机上的安装可以安装 CPU 版或者 GPU 版的。要安装GPU 版本，你的电脑必须有 NVIDIA 显卡，并且还要满足更多要求。<br>基本上，安装至少有5种不同的选项，使用：virtualenv，pip，Docker，Anaconda，以及从源代码安装。这些安装方法请参考：安装 TensorFlow。<br>最常见和最简单的安装方式是通过 virtualenv 和 pip，因此它们将在本文中进行解释。<br>如果你已经使用了 Python 一段时间，你可能知道 pip 。以下是如何在 Ubuntu 上安装：</p>
<pre><code># Install pip
sudo apt-get install python-pip python-dev   # Python 2.7  
sudo apt-get install python3-pip python3-dev # Python 3.x  
在 Ubuntu 和 Mac OSX（不支持 GPU） 机器上安装 TensorFlow：

# CPU support
pip install tensorflow      # Python 2.7  
pip3 install tensorflow     # Python 3.x

# GPU support
pip install tensorflow-gpu  # Python 2.7  
pip3 install tensorflow-gpu # Python 3.x  </code></pre><p>上述命令也适用于 Windows 系统，但仅适用于 Python 3.5.x 和 3.6.x 版本。</p>
<p>在单独的环境中安装 TensorFlow 可以通过 virtualenv 或 conda（Anaconda的一部分）来完成。同样的代码一样可以安装，不过使用前需要创建和激活虚拟环境：</p>
<pre><code>virtualenv --system-site-packages ~/tensorflow  
source ~/tensorflow/bin/activate</code></pre><p>这可以很好地把虚拟环境与系统上全局安装的软件包分离开来。</p>
<h1 id="核心API组件"><a href="#核心API组件" class="headerlink" title="核心API组件"></a>核心API组件</h1><p>TensorFlow 提供了高阶 API 和低阶 API。最低级别的一级称为 Core，它与基本组件一起使用：Tensors、Graphs 和 Sessions。<br>更高级别的API，例如 tf.estimator，用于简化工作流程和自动化，包括数据集管理、学习、评估等过程。无论如何，了解库的核心功能才能更好地利用 TensorFlow 这个利器。<br>Core API 的重点是构建一个计算图，其中包含一系列排列在节点图中的操作。每个节点可以具有多个张量（基本数据结构）作为输入并对它们执行操作以计算输出，该输出随后可以表示对多层网络中的其他节点的输入。这种类型的架构适用于机器学习应用，比如神经网络。</p>
<h1 id="张量"><a href="#张量" class="headerlink" title="张量"></a>张量</h1><p>张量是 TensorFlow 中的基本数据结构，它以任意数量的维度存储数据，类似于 NumPy 中的多维数组。张量有三种基本类型：常量，变量和占位符。<br>常量是不可变类型的张量。它们可以被视为没有输入的节点，输出它们在内部存储的单个值。<br>变量是可变类型的 tensors，其值可以在图形运行期间改变。在ML应用中，变量通常存储需要优化的参数（例如，神经网络中节点之间的权重）。在通过显式调用特殊操作运行图形之前，需要初始化变量。<br>占位符是存储来自外部源的数据的张量。它们代表了一个“承诺”，即在运行图形时将提供一个值。在机器学习应用程序中，占位符通常用于向学习模型输入数据。<br>以下几行给出了三种张量类型的示例：</p>
<pre><code>import tensorflow as tf

tf.reset_default_graph()

# Define a placeholder
a = tf.placeholder(&quot;float&quot;, name=&#39;pholdA&#39;)  
print(&quot;a:&quot;, a)

# Define a variable 
b = tf.Variable(2.0, name=&#39;varB&#39;)  
print(&quot;b:&quot;, b)

# Define a constant
c = tf.constant([1., 2., 3., 4.], name=&#39;consC&#39;)  
print(&quot;c:&quot;, c)


a: Tensor(&quot;pholdA:0&quot;, dtype=float32)  
b: &lt;tf.Variable &#39;varB:0&#39; shape=() dtype=float32_ref&gt;  
c: Tensor(&quot;consC:0&quot;, shape=(4,), dtype=float32)  </code></pre><p>请注意，此时张量不包含值，并且只有在会话中运行图形时，它们的值才可用。<br>下面我们将使用 Core API 构建一个神经网络，用于在真实数据上进行机器学习。  </p>
<h1 id="神经网络模型"><a href="#神经网络模型" class="headerlink" title="神经网络模型"></a>神经网络模型</h1><p>我们来使用 TensorFlow 的核心组件从头开始构建前馈神经网络。<br>鸢尾花数据集<br>鸢尾花数据集 由150个植物实例组成，每个植物都有4个维度（用做输入特征）及其类型（需要预测的输出值）。这些植物可能属于三种类型中的一种（ setosa，virginica 和 versicolor ）。让我们首先从TensorFlow 的网站下载数据 - 它分为训练和测试子集，每个子​​集分别包含 120 和 30 个实例。  </p>
<pre><code>import numpy as np
import pandas as pd
import tensorflow as tf
import urllib.request as request
import matplotlib.pyplot as plt

# Download dataset
IRIS_TRAIN_URL = &quot;http://download.tensorflow.org/data/iris_training.csv&quot;
IRIS_TEST_URL = &quot;http://download.tensorflow.org/data/iris_test.csv&quot;

names = [&#39;sepal-length&#39;, &#39;sepal-width&#39;, &#39;petal-length&#39;, &#39;petal-width&#39;, &#39;species&#39;]
train = pd.read_csv(IRIS_TRAIN_URL, names=names, skiprows=1)
test = pd.read_csv(IRIS_TEST_URL, names=names, skiprows=1)

# Train and test input data
Xtrain = train.drop(&quot;species&quot;, axis=1)  
Xtest = test.drop(&quot;species&quot;, axis=1)

# Encode target values into binary (&#39;one-hot&#39; style) representation
ytrain = pd.get_dummies(train.species)
ytest = pd.get_dummies(test.species)</code></pre><h1 id="模型和学习"><a href="#模型和学习" class="headerlink" title="模型和学习"></a>模型和学习</h1><p>神经网络的输入和输出层的形状将对应于数据的形状，即输入层将包含表示四个输入特征的四个神经元，而由于要给这三个物种编码，输出层将包含三个神经元。例如，’setosa’ 物种可以用向量 [1,0,0] 编码，’virginica’ 用 [0,1,0] 等编码。<br>我们为隐藏层中的神经元数量选择三个值：5、10 和 20，因此网络大小为（4-5-3），（4-10-3）和（4-20-3）。这意味着我们的第一个网络将拥有 4 个输入神经元，5 个“隐藏”神经元和 3 个输出神经元。  </p>
<h1 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h1><p><a href="https://stackabuse.com/tensorflow-neural-network-tutorial/" target="_blank" rel="noopener">https://stackabuse.com/tensorflow-neural-network-tutorial/</a></p>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark生态圈---大数据</title>
    <url>/2020/06/01/Spark%E7%94%9F%E6%80%81%E5%9C%88-%E5%A4%A7%E6%95%B0%E6%8D%AE/</url>
    <content><![CDATA[<p>Spark 生态圈是加州大学伯克利分校的 AMP 实验室打造的<a id="more"></a>，是一个力图在算法（Algorithms）、机器（Machines）、人（People）之间通过大规模集成来展现大数据应用的平台。  </p>
<p>AMP 实验室运用大数据、云计算、通信等各种资源及各种灵活的技术方案，对海量不透明的数据进行甄别并转化为有用的信息，以供人们更好地理解世界。该生态圈已经涉及机器学习、数据挖掘、数据库、信息检索、自然语言处理和语音识别等多个领域。  </p>
<p>Spark 生态圈以 Spark Core 为核心，从 HDFS、Amazon S3 和 HBase 等持久层读取数据，以 Mesos、YARN 和自身携带的 Standalone 为 Cluster Manager 调度 Job 完成 Spark 应用程序的计算，这些应用程序可以来自于不同的组件。  </p>
<p>如 Spark Shell/Spark Submit 的批处理，Spark Streaming 的实时处理应用，Spark SQL 的即席查询，MLlib 的机器学习，GraphX 的图处理和 SparkR 的数学计算等。  </p>
<h1 id="Spark-内核架构"><a href="#Spark-内核架构" class="headerlink" title="Spark 内核架构"></a>Spark 内核架构</h1><pre><code>
1）提供了有向无环图（DAG）的分布式并行计算框架，并提供 cache 机制来支持多次迭代计算或者数据共享，大大减少了迭代计算之间读取数据的开销，这对于需要进行多次迭代的数据挖掘和分析的性能有很大提升。

2）在 Spark 中引入了 RDD 的抽象，它是分布在一组结点中的只读对象集合，这些集合是弹性的，如果数据集的一部分丢失，则可以根据血缘关系对它们进行重建，保证了数据的高容错性。

3）移动计算而非移动数据，RDD 分区可以就近读取 HDFS 中的数据块到各个结点内存中进行计算。

4）使用多线程池模型来减少 Task 启动开销。

5）采用容错的、高可伸缩性的 Akka 作为通信框架。
</code></pre><h1 id="Spark-Streaming"><a href="#Spark-Streaming" class="headerlink" title="Spark Streaming"></a>Spark Streaming</h1><pre><code>Spark Streaming 是一个对实时数据流进行高通量、容错处理的流式处理系统，可以对多种数据源（如 Kafka、Flume、Twitter、Zero 和 TCP 套接字）进行类似 map、reduce 和 join 的复杂操作，并将结果保存到外部文件系统、数据库中，或应用到实时仪表盘上。

Spark Streaming 的核心思想是将流式计算分解成一系列短小的批处理作业，这里的批处理引擎是 Spark Core。也就是把 Spark Streaming 的输入数据按照设定的时间片（如 1 秒）分成一段一段的数据，每一段数据都转换成 Spark 中的 RDD，然后将 Spark Streaming 中对 DStream 的转换操作变为对 Spark 中的 RDD 的转换操作，将 RDD 经过操作变成的中间结果保存在内存中。

根据业务的需求，整个流式计算可以对中间结果进行叠加，或者将中间结果存储到外部设备。本教程会在后边对 Spark Streaming 做详细介绍。</code></pre><h1 id="Spark-SQL"><a href="#Spark-SQL" class="headerlink" title="Spark SQL"></a>Spark SQL</h1><pre><code>Spark SQL 允许开发人员直接处理 RDD，以及查询存储在 Hive、HBase 上的外部数据。Spark SQL 的一个重要特点是其能够统一处理关系表和 RDD，使得开发人员可以轻松地使用 SQL 命令进行外部查询，同时进行更复杂的数据分析。</code></pre><h1 id="Spark-MLlib"><a href="#Spark-MLlib" class="headerlink" title="Spark MLlib"></a>Spark MLlib</h1><pre><code>Spark MLlib 实现了一些常见的机器学习算法和实用程序，包括分类、回归、聚类、协同过滤、降维及底层优化，并且该算法可以进行扩充。Spark MLlib 降低了机器学习的门槛，开发人员只要具备一定的理论知识就能进行机器学习的工作。有时间的话将在后面对 Spark MLlib 做进一步介绍。</code></pre><h1 id="Spark-GraphX"><a href="#Spark-GraphX" class="headerlink" title="Spark GraphX"></a>Spark GraphX</h1><pre><code>Spark GraphX 是 Spark 中用于图并行计算的 API，可以认为是 GraphLab 和 Pregel 在 Spark 上的重写及优化。与其他分布式图计算框架相比，Spark GraphX 最大的贡献是在 Spark 之上提供了一站式数据解决方案，可以方便且高效地完成图计算的一整套流水作业。

Spark GraphX 的核心抽象是 Resilient Distributed Property Graph，即一种点和边都带属性的有向多重图。它扩展了 Spark RDD 的抽象，有 Table 和 Graph 两种视图，而只需要一份物理存储。两种视图都有自己独有的操作符，从而使得操作灵活，并提高了执行效率。

需要说明的是，无论是 Spark Streaming、Spark SQL、Spark MLlib，还是 Spark GraphX，都可以使用 Spark Core 的 API 处理问题，它们的方法几乎是通用的，处理的数据也可以共享，从而可以完成不同应用之间数据的无缝集成。</code></pre>]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Java大数据开发</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu系统安装Python</title>
    <url>/2020/05/20/Ubuntu%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85Python/</url>
    <content><![CDATA[<p>今天是2020年5月20日，在这个特殊的日子里，我祝福我爱的人爱我的人每天都有好心情···切入正题<a id="more"></a><br>近期接到一个任务在公司的Ubuntu系统下搭建Python环境，因为之前接触到的都是Linux系统所以下载软件的话时长都是YUM install 下载；结果刚一打开系统就开始yum install ；也是神奇，既不报错又不报错。最后找了好多技术网站 得到了Ubuntu系统下下载的话是使用sudo apt-get install 安装软件。 最后罗列了在Ubuntu系统下搭建Python环境的具体步骤：</p>
<h1 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h1><p>在安装之前，请使用以下命令安装Python的先决条件。</p>
<pre><code>sudo apt-get install build-essential checkinstall
sudo apt-get install libreadline-gplv2-dev libncursesw5-dev libssl-dev \
    libsqlite3-dev tk-dev libgdbm-dev libc6-dev libbz2-dev</code></pre><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>使用python官方站点的以下命令下载Python。您也可以下载最新版本代替下面指定的版本。</p>
<pre><code>cd /usr/src
sudo wget https://www.python.org/ftp/python/3.7.0/Python-3.7.0.tgz

sudo tar xzf Python-3.7.0.tgz</code></pre><h1 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h1><p>使用下面的命令集来使用altinstall在您的系统上编译python源代码。</p>
<pre><code>cd Python-3.7.0
sudo ./configure --enable-optimizations
sudo make altinstall
make altinstall用于防止替换默认的python二进制文件/ usr / bin / python。</code></pre><h1 id="检查Python版本"><a href="#检查Python版本" class="headerlink" title="检查Python版本"></a>检查Python版本</h1><pre><code>python3.7 -V</code></pre><h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p>安装python3.7出现ModuleNotFoundError: No module named ‘_ctypes’解决办法<br>解决办法：</p>
<pre><code>sudo apt-get update
sudo apt-get upgrade
sudo apt-get dist-upgrade
sudo apt-get install build-essential python-dev python-setuptools python-pip python-smbus
sudo apt-get install build-essential libncursesw5-dev libgdbm-dev libc6-dev
sudo apt-get install zlib1g-dev libsqlite3-dev tk-dev
sudo apt-get install libssl-dev openssl
sudo apt-get install libffi-dev</code></pre>]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>flask-session组件-Web框架</title>
    <url>/2020/03/30/flask-session%E7%BB%84%E4%BB%B6-Web%E6%A1%86%E6%9E%B6/</url>
    <content><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>flask-session是flask框架的session组件，<br>由于原来flask内置session使用签名cookie保存，该组件则将支持session保存到多个地方<br>如：</p>
<a id="more"></a>
<pre><code>redis
memcached
filesystem
mongodb
sqlalchmey</code></pre><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><pre><code>pip install flask-session</code></pre><h1 id="存储方式"><a href="#存储方式" class="headerlink" title="存储方式"></a>存储方式</h1><h1 id="redis"><a href="#redis" class="headerlink" title="redis"></a>redis</h1><p>第一种</p>
<pre><code>import redis
from flask import Flask, session
from flask_session import Session
app = Flask(__name__)
app.debug = True
app.secret_key = &#39;xxxx&#39;
app.config[&#39;SESSION_TYPE&#39;] = &#39;redis&#39;  # session类型为redis
app.config[&#39;SESSION_PERMANENT&#39;] = False  # 如果设置为True，则关闭浏览器session就失效。
app.config[&#39;SESSION_USE_SIGNER&#39;] = False  # 是否对发送到浏览器上session的cookie值进行加密
app.config[&#39;SESSION_KEY_PREFIX&#39;] = &#39;session:&#39;  # 保存到session中的值的前缀
app.config[&#39;SESSION_REDIS&#39;] = redis.Redis(host=&#39;127.0.0.1&#39;, port=&#39;6379&#39;, password=&#39;123123&#39;)  
# 用于连接redis的配置
Session(app)
@app.route(&#39;/index&#39;)
def index():
    session[&#39;k1&#39;] = &#39;v1&#39;
    return &#39;xx&#39;
if __name__ == &#39;__main__&#39;:
    app.run()</code></pre><p>第二种</p>
<pre><code>from flask import Flask,session
from flask_session import RedisSessionInterface
import redis
app = Flask(__name__)
conn=redis.Redis(host=&#39;127.0.0.1&#39;,port=6379)
#use_signer是否对key签名
#如果use_siginer为False,这表示不需要配置app.secret_key
app.secret_key=&quot;aksdhkajs&quot;
app.session_interface=RedisSessionInterface(conn,key_prefix=&#39;hades&#39;,
                                            use_signer=True,permanent=False)
&#39;&#39;&#39;
之前的session
seesion名字为配置文件中的名字
    存:seesion  -&gt;加密--&gt;cookie
    取:session --&gt;值  ----》解密
redis的seesion
seesion名字为配置文件中的名字
    name=self.key_prefix + session.sid, value=val 是redis里面的键
    val存到redis
seesion  --&gt;name
name加前缀---&gt;redis取
&#39;&#39;&#39;
@app.route(&#39;/&#39;)
def hello_world():
    session[&#39;name&#39;]=&#39;hades&#39;
    return &#39;Hello World!&#39;
@app.route(&quot;/index&quot;)
def index():
    print(session[&#39;name&#39;])
    return &quot;ok&quot;
if __name__ == &#39;__main__&#39;:
    app.run()</code></pre><h1 id="memcached"><a href="#memcached" class="headerlink" title="memcached"></a>memcached</h1><pre><code>from flask import Flask, session
from flask_session import Session
import memcache
app = Flask(__name__)
app.debug = True
app.secret_key = &#39;xxxx&#39;
app.config[&#39;SESSION_TYPE&#39;] = &#39;memcached&#39; # session类型为memcached
app.config[&#39;SESSION_PERMANENT&#39;] = True # 如果设置为True，则关闭浏览器session就失效。
app.config[&#39;SESSION_USE_SIGNER&#39;] = False # 是否对发送到浏览器上session的cookie值进行加密
app.config[&#39;SESSION_KEY_PREFIX&#39;] = &#39;session:&#39; # 保存到session中的值的前缀
app.config[&#39;SESSION_MEMCACHED&#39;] = memcache.Client([&#39;10.211.55.4:12000&#39;])
Session(app)
@app.route(&#39;/index&#39;)
def index():
    session[&#39;k1&#39;] = &#39;v1&#39;
    return &#39;xx&#39;
if __name__ == &#39;__main__&#39;:
    app.run()</code></pre><h1 id="filesystem"><a href="#filesystem" class="headerlink" title="filesystem"></a>filesystem</h1><pre><code>from flask import Flask, session
from flask_session import Session
app = Flask(__name__)
app.debug = True
app.secret_key = &#39;xxxx&#39;
app.config[&#39;SESSION_TYPE&#39;] = &#39;filesystem&#39;  # session类型为filesystem
app.config[
    &#39;SESSION_FILE_DIR&#39;] = &#39;/Users/wupeiqi/PycharmProjects/grocery/96.Flask新课程/组件/2.flask-session&#39;  # 文件路径
app.config[&#39;SESSION_FILE_THRESHOLD&#39;] = 500  # 存储session的个数如果大于这个值时，就要开始进行删除了
app.config[&#39;SESSION_FILE_MODE&#39;] = 384  # 文件权限类型
app.config[&#39;SESSION_PERMANENT&#39;] = True  # 如果设置为True，则关闭浏览器session就失效。
app.config[&#39;SESSION_USE_SIGNER&#39;] = False  # 是否对发送到浏览器上session的cookie值进行加密
app.config[&#39;SESSION_KEY_PREFIX&#39;] = &#39;session:&#39;  # 保存到session中的值的前缀
Session(app)
@app.route(&#39;/index&#39;)
def index():
    session[&#39;k1&#39;] = &#39;v1
    return &#39;xx&#39;
if __name__ == &#39;__main__&#39;:
    app.run()</code></pre><h1 id="mongodb"><a href="#mongodb" class="headerlink" title="mongodb"></a>mongodb</h1><pre><code>from flask import Flask, session
from flask_session import Session
import pymongo
app = Flask(__name__)
app.debug = True
app.secret_key = &#39;xxxx&#39;
app.config[&#39;SESSION_TYPE&#39;] = &#39;mongodb&#39;  # session类型为mongodb
app.config[&#39;SESSION_MONGODB&#39;] = pymongo.MongoClient()
app.config[&#39;SESSION_MONGODB_DB&#39;] = &#39;mongo的db名称（数据库名称）&#39;
app.config[&#39;SESSION_MONGODB_COLLECT&#39;] = &#39;mongo的collect名称（表名称）&#39;
app.config[&#39;SESSION_PERMANENT&#39;] = True  # 如果设置为True，则关闭浏览器session就失效。
app.config[&#39;SESSION_USE_SIGNER&#39;] = False  # 是否对发送到浏览器上session的cookie值进行加密
app.config[&#39;SESSION_KEY_PREFIX&#39;] = &#39;session:&#39;  # 保存到session中的值的前缀
Session(app)
@app.route(&#39;/index&#39;)
def index():
    session[&#39;k1&#39;] = &#39;v1&#39;
    session[&#39;k2&#39;] = &#39;v1&#39;
    return &#39;xx&#39;
if __name__ == &#39;__main__&#39;:
    app.run()</code></pre><h1 id="mongodb操作简单示例："><a href="#mongodb操作简单示例：" class="headerlink" title="mongodb操作简单示例："></a>mongodb操作简单示例：</h1><pre><code>from pymongo import MongoClient
# 创建链接
conn = MongoClient(&#39;47.93.4.198&#39;, 27017)
# 选择数据库
db = conn[&#39;db1&#39;]
# 选择表
posts = db[&#39;posts&#39;]
post_data = {
    &#39;name&#39;: &#39;alex&#39;,
    &#39;age&#39;: 18
}
# 表中插入数据
# result = posts.insert_one(post_data)
# 获取一条数据
# row = posts.find_one()
# print(row)
# # 获取多条数据
# rows = posts.find()
# for row in rows:
#     print(row)
# 删除多条数据
# rows = posts.delete_many(filter={})
# print(rows)
# 更新多条数据
# posts.update({}, {&#39;name&#39;: &#39;wupeiqi&#39;})</code></pre><h1 id="sqlalchemy"><a href="#sqlalchemy" class="headerlink" title="sqlalchemy"></a>sqlalchemy</h1><pre><code>import redis
from flask import Flask, session
from flask_session import Session as FSession
from flask_sqlalchemy import SQLAlchemy
app = Flask(__name__)
app.debug = True
app.secret_key = &#39;xxxx&#39;
# 设置数据库链接
app.config[&#39;SQLALCHEMY_DATABASE_URI&#39;] = &#39;mysql+pymysql://root:123@127.0.0.1:3306/fssa?charset=utf8&#39;
app.config[&#39;SQLALCHEMY_TRACK_MODIFICATIONS&#39;] = True
# 实例化SQLAlchemy
db = SQLAlchemy(app)
app.config[&#39;SESSION_TYPE&#39;] = &#39;sqlalchemy&#39;  # session类型为sqlalchemy
app.config[&#39;SESSION_SQLALCHEMY&#39;] = db # SQLAlchemy对象
app.config[&#39;SESSION_SQLALCHEMY_TABLE&#39;] = &#39;session&#39; # session要保存的表名称
app.config[&#39;SESSION_PERMANENT&#39;] = True  # 如果设置为True，则关闭浏览器session就失效。
app.config[&#39;SESSION_USE_SIGNER&#39;] = False  # 是否对发送到浏览器上session的cookie值进行加密
app.config[&#39;SESSION_KEY_PREFIX&#39;] = &#39;session:&#39;  # 保存到session中的值的前缀
FSession(app)
@app.route(&#39;/index&#39;)
def index():
    session[&#39;k1&#39;] = &#39;v1&#39;
    session[&#39;k2&#39;] = &#39;v1&#39;
    return &#39;xx&#39;
if __name__ == &#39;__main__&#39;:
    app.run()</code></pre><h1 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h1><p>在写好代码后，不要着急运行，需要先执行进入终端执行一条创建数据库表的命令：</p>
<pre><code>bogon:pro-flask wupeiqi$ python3
Python 3.5.1 (v3.5.1:37a07cee5969, Dec  5 2015, 21:12:44)
[GCC 4.2.1 (Apple Inc. build 5666) (dot 3)] on darwin
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
&gt;&gt;&gt; from app import db
&gt;&gt;&gt; db.create_all()</code></pre>]]></content>
      <categories>
        <category>Web 框架</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>redis----主从复制</title>
    <url>/2020/04/06/redis-%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>为了避免单点故障，我们需要将数据复制多份部署在多台不同的服务器上，即使有一台服务器出现故障其他服务器依然可以继续提供服务  <a id="more"></a><br>作用： 数据备份  扩展读性能(读写分离)</p>
<p>复制方式：全量复制 部分复制</p>
<h1 id="实现方式"><a href="#实现方式" class="headerlink" title="实现方式"></a>实现方式</h1><p>1、一主二扑 A（B、C） 一个Master两个Slave</p>
<p>2、薪火相传（去中心化） A-B-C，B既是主节点（C的主节点），又是从节点（A的从节点）</p>
<p>3、反客为主（主节点down掉后，手动操作升级从节点为主节点）</p>
<p>4、哨兵模式（后台监控主机是否故障，如果故障了根据投票数自动将从库转换为主库）</p>
<h1 id="一主多从"><a href="#一主多从" class="headerlink" title="一主多从"></a>一主多从</h1><p><img src= "/img/loading.gif" data-src="/images/redis%E9%9B%86%E7%BE%A4.png" alt="alt"></p>
<p>配置</p>
<pre><code>Master：6379端口
requirepass 123456
slave1:  6380端口
port 6380
slaveof 127.0.0.1 6379
masterauth 123456
Slave2:  6381端口
port 6381
slaveof 127.0.0.1 6379
masterauth 123456</code></pre><p>启动 开启 Master</p>
<pre><code>redis-server.exe redis.windows.conf</code></pre>]]></content>
  </entry>
  <entry>
    <title>人工智能三学派</title>
    <url>/2020/03/17/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%89%E5%AD%A6%E6%B4%BE/</url>
    <content><![CDATA[<p>人工智能：</p>
<p>让机器具备人的思维和意识。</p>
<p>人工智能三学派：</p>
<a id="more"></a>

<p>行为主义：基于控制论，构建感知-动作控制系统（控制论：平衡/行走/避障等自适应控制系统）</p>
<p>符号主义：基于算术逻辑表达式，求解问题先把问题描述为表达式，在求解表达式。（可用公式描述，实现理性思维）</p>
<p>连接主义：仿生学，模仿神经元连接关系（放脑神经元连接，实现感性思维，例如神经网络）</p>
<p>用计算机仿出神经网络的连接关系让计算机具备感性思维。</p>
<ol>
<li>准备数据（采集大量“特征/标签”数据）</li>
<li>搭建网络（搭建神经网络结构）</li>
<li>优化参数（训练网络获取最佳参数【反向传播：优化连接的权重知道模型的识别准确率达到要求，得到最优的连线权重，保存】）</li>
<li>应用网络（将网络保存为模型，输入新数据，输出分类或预测结果【前向传播：输出概率值 概率值最大的就是分类和预测的结果】）</li>
</ol>
]]></content>
      <tags>
        <tag>A.I.</tag>
      </tags>
  </entry>
  <entry>
    <title>varchar int 查询 到底什么情况下走索引？</title>
    <url>/2020/04/03/varchar-int-%E6%9F%A5%E8%AF%A2-%E5%88%B0%E5%BA%95%E4%BB%80%E4%B9%88%E6%83%85%E5%86%B5%E4%B8%8B%E8%B5%B0%E7%B4%A2%E5%BC%95%EF%BC%9F/</url>
    <content><![CDATA[<p>一个字符类型的、一个int类型的，查询的时候到底会不会走索引，其实很多工作了几年的开发人员有时也会晕，下面就用具体事例来测试一下。</p>
<a id="more"></a>
<h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h1><p>先准备2张表，以备后续测试使用。<br>两张表的差异是c_no的字段类型不同。<br>表1：创建表test1,总共3列，其中id 是主键（int）,c_no 为int型，且有索引，c_2为普通字段</p>
<pre><code>/*创建表test1 */
create table  test1(id int primary key,c_no  int ,c_2 varchar(1),key c_no(c_no));
/* 插入一些测试数据 */
insert  into test1 values(1,1,&#39;0&#39;),(2,2,&#39;1&#39;),(3,4,&#39;1&#39;),(4,6,&#39;0&#39;),(5,7,&#39;&#39;1),(6,11,&#39;2&#39;),(7,5,&#39;3&#39;),(8,100,&#39;0&#39;),(9,30,&#39;1&#39;),(10,50,&#39;0&#39;);</code></pre><p>表2： 创建表test1,总共3列，其中id 是主键（int）,c_no 为字符型，且有索引，c_2为普通字段</p>
<pre><code>/* 创建test2 */
create table  test2(id int primary key  auto_increment,c_no  varchar(11) ,c2 varchar(2),key c_no(c_no));
/* 插入一些测试数据 */
 insert  into test2 values(1,&#39;5&#39;,&#39;1&#39;),(4,&#39;100&#39;,&#39;0&#39;),(3,&#39;30&#39;,&#39;1&#39;),(10,&#39;500&#39;,&#39;0&#39;),(11,&#39;20&#39;,&#39;0&#39;),(12,&#39;20a&#39;,&#39;0&#39;),(15,&#39;020b&#39;,&#39;1&#39;);</code></pre><h1 id="等值查询测试"><a href="#等值查询测试" class="headerlink" title="等值查询测试"></a>等值查询测试</h1><p>测试test1<br>test1.c_no字段为int类型，下面分别用整型和字符串进行比较，查看是否走索引。对应的执行计划如下：</p>
<pre><code>mysql&gt; explain  select *  from test1 where c_no=&#39;100&#39;;
+----+-------------+-------+------------+------+---------------+------+---------+-------+------+----------+-------+
| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref   | rows | filtered | Extra |
+----+-------------+-------+------------+------+---------------+------+---------+-------+------+----------+-------+
|  1 | SIMPLE      | test1 | NULL       | ref  | c_no          | c_no | 5       | const |    1 |   100.00 | NULL  |
+----+-------------+-------+------------+------+---------------+------+---------+-------+------+----------+-------+
1 row in set, 1 warning (0.00 sec)
mysql&gt; explain  select *  from test1 where c_no=100;
+----+-------------+-------+------------+------+---------------+------+---------+-------+------+----------+-------+
| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref   | rows | filtered | Extra |
+----+-------------+-------+------------+------+---------------+------+---------+-------+------+----------+-------+
|  1 | SIMPLE      | test1 | NULL       | ref  | c_no          | c_no | 5       | const |    1 |   100.00 | NULL  |
+----+-------------+-------+------------+------+---------------+------+---------+-------+------+----------+-------+
1 row in set, 1 warning (0.00 sec)</code></pre><p>可见，两种方式均走索引了，且走的是c_no的索引，类型为ref为const（常量的等值查询），扫行数为1<br>也就是说当表中的字段类型为整型时，无论查询用字符串类型的数字还是int类型的数字均能走索引。其中用int类型的值查询能走索引可以容易理解，那么，字符型的为什么能走？ 其实这里的字符类型做了隐式转化，上例中就相当于</p>
<pre><code>mysql&gt; explain  select *  from test1 where c_no=CAST(&#39;100&#39; as UNSIGNED);
+----+-------------+-------+------------+------+---------------+------+---------+-------+------+----------+-------+
| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref   | rows | filtered | Extra |
+----+-------------+-------+------------+------+---------------+------+---------+-------+------+----------+-------+
|  1 | SIMPLE      | test1 | NULL       | ref  | c_no          | c_no | 5       | const |    1 |   100.00 | NULL  |
+----+-------------+-------+------------+------+---------------+------+---------+-------+------+----------+-------+
1 row in set, 1 warning (0.00 sec)</code></pre><h1 id="测试test2表"><a href="#测试test2表" class="headerlink" title="测试test2表"></a>测试test2表</h1><p>以同样的方式测试一下test2的查询情况</p>
<p>先测试正常情况下字符型与字符型比较，结果可想而知，可以走索引，如下：</p>
<pre><code>mysql&gt; explain  select *  from test2 where c_no=&#39;100&#39;;
+----+-------------+-------+------------+------+---------------+------+---------+-------+------+----------+-------+
| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref   | rows | filtered | Extra |
+----+-------------+-------+------------+------+---------------+------+---------+-------+------+----------+-------+
|  1 | SIMPLE      | test2 | NULL       | ref  | c_no          | c_no | 47      | const |    1 |   100.00 | NULL  |
+----+-------------+-------+------------+------+---------------+------+---------+-------+------+----------+-------+
1 row in set, 1 warning (0.00 sec)</code></pre><p>如果是整型再查呢？结果如下（很遗憾，不能走索引了）</p>
<pre><code>mysql&gt; explain  select *  from test2 where c_no=100;
+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------+
| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra       |
+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------+
|  1 | SIMPLE      | test2 | NULL       | ALL  | c_no          | NULL | NULL    | NULL |    7 |    14.29 | Using where |
+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------+
1 row in set, 3 warnings (0.00 sec)</code></pre><p>也就是说，表中字段为字符类型的时候，查询的值为整型时，无法走索引了。</p>
<p>那这句相当于如下情况：</p>
<pre><code>mysql&gt; explain  select *  from test2 where cast(c_no  as  unsigned)=100;
+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------+
| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra       |
+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------+
|  1 | SIMPLE      | test2 | NULL       | ALL  | NULL          | NULL | NULL    | NULL |    7 |   100.00 | Using where |
+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------+
1 row in set, 1 warning (0.00 sec)</code></pre><p>也就是c_no做了隐式转化。因为如果是100做了影视转化，那么结果应该是可以走索引，例如：</p>
<pre><code>mysql&gt; explain  select *  from test2 where c_no=cast(100 as char);
+----+-------------+-------+------------+------+---------------+------+---------+-------+------+----------+-------+
| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref   | rows | filtered | Extra |
+----+-------------+-------+------------+------+---------------+------+---------+-------+------+----------+-------+
|  1 | SIMPLE      | test2 | NULL       | ref  | c_no          | c_no | 47      | const |    1 |   100.00 | NULL  |
+----+-------------+-------+------------+------+---------------+------+---------+-------+------+----------+-------+
1 row in set, 1 warning (0.00 sec)</code></pre><p>由此，我们也应证了如果字段做了函数计算后，该列上即使有索引也无法使用（MySQL8.0之前的版本）</p>
<h1 id="进一步测试"><a href="#进一步测试" class="headerlink" title="进一步测试"></a>进一步测试</h1><p>其实针对test2表 还可以测试一点，进一步证明是c_no字段做了隐式转化，例如：</p>
<pre><code>mysql&gt; select  * from test2 where c_no=20;
+----+------+------+
| id | c_no | c2   |
+----+------+------+
| 11 | 20   | 0    |
| 12 | 20a  | 0    |
| 15 | 020b | 1    |
+----+------+------+
3 rows in set, 2 warnings (0.00 sec)</code></pre><p>另外，看到了2个警告，内容如下：</p>
<pre><code>mysql&gt; show warnings;
+---------+------+------------------------------------------+
| Level   | Code | Message                                  |
+---------+------+------------------------------------------+
| Warning | 1292 | Truncated incorrect DOUBLE value: &#39;20a&#39;  |
| Warning | 1292 | Truncated incorrect DOUBLE value: &#39;020b&#39; |
+---------+------+------------------------------------------+
2 rows in set (0.00 sec)</code></pre><h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p>更加证明了转化为数字型（预转为double）<br>通过上面的简单测试，即可发现如下结论：</p>
<pre><code>当表中的字段类型为整型时，无论查询用字符串类型的数字还是int类型的数字均能走索引；
表中字段为字符类型的时候，查询的值为整型时，无法走索引；
如果字段做了函数计算后，该列上即使有索引也无法使用（MySQL8.0之前的版本）</code></pre><p>因此开发同学在写SQL的时候要注意SQL的写法，缺少一个单引号可能导致很大的性能差异。</p>
]]></content>
      <categories>
        <category>技术试验</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>关于HTTP你了解多少？-面试</title>
    <url>/2020/04/27/%E5%85%B3%E4%BA%8EHTTP%E4%BD%A0%E4%BA%86%E8%A7%A3%E5%A4%9A%E5%B0%91%EF%BC%9F-%E9%9D%A2%E8%AF%95/</url>
    <content><![CDATA[<h1 id="HTTP-和-HTTPS-的区别"><a href="#HTTP-和-HTTPS-的区别" class="headerlink" title="HTTP 和 HTTPS 的区别"></a>HTTP 和 HTTPS 的区别</h1><p>HTTP 是一种 超文本传输协议(Hypertext Transfer Protocol)，HTTP 是一个在计算机世界里专门在两点之间传输文字、图片、音频、视频等超文本数据的约定和规范<br><img src= "/img/loading.gif" data-src="/images/640.png" alt="图"><br>HTTP 主要内容分为三部分，超文本（Hypertext）、传输（Transfer）、协议（Protocol）。</p>
<p>超文本就是不单单只是本文，它还可以传输图片、音频、视频，甚至点击文字或图片能够进行超链接的跳转。</p>
<p>上面这些概念可以统称为数据，传输就是数据需要经过一系列的物理介质从一个端系统传送到另外一个端系统的过程。通常我们把传输数据包的一方称为请求方，把接到二进制数据包的一方称为应答方。</p>
<p>而协议指的就是是网络中(包括互联网)传递、管理信息的一些规范。如同人与人之间相互交流是需要遵循一定的规矩一样，计算机之间的相互通信需要共同遵守一定的规则，这些规则就称为协议，只不过是网络协议。</p>
<p>说到 HTTP，不得不提的就是 TCP/IP 网络模型，一般是五层模型。如下图所示<br><img src= "/img/loading.gif" data-src="/images/641.png" alt="alt"><br>但是也可以分为四层，就是把链路层和物理层都表示为网络接口层<br><img src= "/img/loading.gif" data-src="/images/642.png" alt="alt"><br>还有一种就是 OSI 七层网络模型，它就是在五层协议之上加了表示层和会话层<br><img src= "/img/loading.gif" data-src="/images/643.png" alt="alt"><br>而 HTTPS 的全称是 Hypertext Transfer Protocol Secure，从名称我们可以看出 HTTPS 要比 HTTPS 多了 secure 安全性这个概念，实际上， HTTPS 并不是一个新的应用层协议，它其实就是 HTTP + TLS/SSL 协议组合而成，而安全性的保证正是 TLS/SSL 所做的工作。<br>也就是说，HTTPS 就是身披了一层 SSL 的 HTTP。<br><img src= "/img/loading.gif" data-src="/images/644.png" alt="alt"><br>那么，HTTP 和 HTTPS 的主要区别是什么呢？</p>
<p>最简单的，HTTP 在地址栏上的协议是以 http:// 开头，而 HTTPS 在地址栏上的协议是以 https:// 开头</p>
<pre><code>http://www.alexisli.cn/
https://www.alexisli.cn/</code></pre><p>HTTP 是未经安全加密的协议，它的传输过程容易被攻击者监听、数据容易被窃取、发送方和接收方容易被伪造；而 HTTPS 是安全的协议，它通过 密钥交换算法 - 签名算法 - 对称加密算法 - 摘要算法 能够解决上面这些问题。<br><img src= "/img/loading.gif" data-src="/images/645.png" alt="alt"><br>HTTP 的默认端口是 80，而 HTTPS 的默认端口是 443。  </p>
<h1 id="HTTP-Get-和-Post-区别"><a href="#HTTP-Get-和-Post-区别" class="headerlink" title="HTTP Get 和 Post 区别"></a>HTTP Get 和 Post 区别</h1><p>HTTP 中包括许多方法，Get 和 Post 是 HTTP 中最常用的两个方法，基本上使用 HTTP 方法中有 99% 都是在使用 Get 方法和 Post 方法，所以有必要我们对这两个方法有更加深刻的认识。</p>
<p>get 方法一般用于请求，比如你在浏览器地址栏输入 <a href="http://www.cxuanblog.com" target="_blank" rel="noopener">www.cxuanblog.com</a> 其实就是发送了一个 get 请求，它的主要特征是请求服务器返回资源，而 post 方法一般用于</p>
<p>表单的提交，相当于是把信息提交给服务器，等待服务器作出响应，get 相当于一个是 pull/拉的操作，而 post 相当于是一个 push/推的操作。</p>
<p>get 方法是不安全的，因为你在发送请求的过程中，你的请求参数会拼在 URL 后面，从而导致容易被攻击者窃取，对你的信息造成破坏和伪造；</p>
<pre><code>/test/demo_form.asp?name1=value1&amp;name2=value2</code></pre><p>而 post 方法是把参数放在请求体 body 中的，这对用户来说不可见。</p>
<pre><code>POST /test/demo_form.asp HTTP/1.1
Host: w3schools.com
name1=value1&amp;name2=value2</code></pre><p>get 请求的 URL 有长度限制，而 post 请求会把参数和值放在消息体中，对数据长度没有要求。</p>
<p>get 请求会被浏览器主动 cache，而 post 不会，除非手动设置。</p>
<p>get 请求在浏览器反复的 回退/前进 操作是无害的，而 post 操作会再次提交表单请求。</p>
<p>get 请求在发送过程中会产生一个 TCP 数据包；post 在发送过程中会产生两个 TCP 数据包。对于 get 方式的请求，浏览器会把 http header 和 data 一并发送出去，服务器响应 200（返回数据）；而对于 post，浏览器先发送 header，服务器响应 100 continue，浏览器再发送 data，服务器响应 200 ok（返回数据）。</p>
<p>什么是无状态协议，HTTP 是无状态协议吗，怎么解决<br>无状态协议(Stateless Protocol) 就是指浏览器对于事务的处理没有记忆能力。举个例子来说就是比如客户请求获得网页之后关闭浏览器，然后再次启动浏览器，登录该网站，但是服务器并不知道客户关闭了一次浏览器。</p>
<p>HTTP 就是一种无状态的协议，他对用户的操作没有记忆能力。可能大多数用户不相信，他可能觉得每次输入用户名和密码登陆一个网站后，下次登陆就不再重新输入用户名和密码了。这其实不是 HTTP 做的事情，起作用的是一个叫做 小甜饼(Cookie) 的机制。它能够让浏览器具有记忆能力。</p>
<pre><code>如果你的浏览器允许 cookie 的话，查看方式 chrome://settings/content/cookies</code></pre><p><img src= "/img/loading.gif" data-src="/images/646.png" alt="alt"><br>也就说明你的记忆芯片通电了…… 当你向服务端发送请求时，服务端会给你发送一个认证信息，服务器第一次接收到请求时，开辟了一块 Session 空间（创建了Session对象），同时生成一个 sessionId ，并通过响应头的 Set-Cookie：JSESSIONID=XXXXXXX 命令，向客户端发送要求设置 Cookie 的响应；客户端收到响应后，在本机客户端设置了一个 JSESSIONID=XXXXXXX 的 Cookie 信息，该 Cookie 的过期时间为浏览器会话结束；<br><img src= "/img/loading.gif" data-src="/images/647.png" alt="alt"><br>接下来客户端每次向同一个网站发送请求时，请求头都会带上该 Cookie信息（包含 sessionId ）， 然后，服务器通过读取请求头中的 Cookie 信息，获取名称为 JSESSIONID 的值，得到此次请求的 sessionId。这样，你的浏览器才具有了记忆能力。<br><img src= "/img/loading.gif" data-src="/images/648.png" alt="alt">  </p>
<p>还有一种方式是使用 JWT 机制，它也是能够让你的浏览器具有记忆能力的一种机制。与 Cookie 不同，JWT 是保存在客户端的信息，它广泛的应用于单点登录的情况。JWT 具有两个特点</p>
<p>JWT 的 Cookie 信息存储在客户端，而不是服务端内存中。也就是说，JWT 直接本地进行验证就可以，验证完毕后，这个 Token 就会在 Session 中随请求一起发送到服务器，通过这种方式，可以节省服务器资源，并且 token 可以进行多次验证。</p>
<p>JWT 支持跨域认证，Cookies 只能用在单个节点的域或者它的子域中有效。如果它们尝试通过第三个节点访问，就会被禁止。使用 JWT 可以解决这个问题，使用 JWT 能够通过多个节点进行用户认证，也就是我们常说的跨域认证。</p>
<h1 id="UDP-和-TCP-的区别"><a href="#UDP-和-TCP-的区别" class="headerlink" title="UDP 和 TCP 的区别"></a>UDP 和 TCP 的区别</h1><p>TCP 和 UDP 都位于计算机网络模型中的运输层，它们负责传输应用层产生的数据。下面我们就来聊一聊 TCP 和 UDP 分别的特征和他们的区别:</p>
<h1 id="UDP-是什么"><a href="#UDP-是什么" class="headerlink" title="UDP 是什么"></a>UDP 是什么</h1><p>UDP 的全称是 User Datagram Protocol，用户数据报协议。它不需要所谓的握手操作，从而加快了通信速度，允许网络上的其他主机在接收方同意通信之前进行数据传输。</p>
<p>数据报是与分组交换网络关联的传输单元。</p>
<p>UDP 的特点主要有</p>
<p>UDP 能够支持容忍数据包丢失的带宽密集型应用程序</p>
<p>UDP 具有低延迟的特点</p>
<p>UDP 能够发送大量的数据包</p>
<p>UDP 能够允许 DNS 查找，DNS 是建立在 UDP 之上的应用层协议。</p>
<h1 id="TCP-是什么"><a href="#TCP-是什么" class="headerlink" title="TCP 是什么"></a>TCP 是什么</h1><p>TCP 的全称是Transmission Control Protocol ，传输控制协议。它能够帮助你确定计算机连接到 Internet 以及它们之间的数据传输。通过三次握手来建立 TCP 连接，三次握手就是用来启动和确认 TCP 连接的过程。一旦连接建立后，就可以发送数据了，当数据传输完成后，会通过关闭虚拟电路来断开连接。</p>
<p>TCP 的主要特点有</p>
<p>TCP 能够确保连接的建立和数据包的发送</p>
<p>TCP 支持错误重传机制</p>
<p>TCP 支持拥塞控制，能够在网络拥堵的情况下延迟发送</p>
<p>TCP 能够提供错误校验和，甄别有害的数据包。  </p>
<h1 id="TCP-和-UDP-的不同"><a href="#TCP-和-UDP-的不同" class="headerlink" title="TCP 和 UDP 的不同"></a>TCP 和 UDP 的不同</h1><p>下面罗列了一些 TCP 和 UDP 的不同点，方便理解，方便记忆。<br><img src= "/img/loading.gif" data-src="/images/649.png" alt="alt">    </p>
<h1 id="TCP-三次握手和四次挥手"><a href="#TCP-三次握手和四次挥手" class="headerlink" title="TCP 三次握手和四次挥手"></a>TCP 三次握手和四次挥手</h1><p>TCP 三次握手和四次挥手也是面试题的热门考点，它们分别对应 TCP 的连接和释放过程。下面就来简单认识一下这两个过程</p>
<h1 id="TCP-三次握手"><a href="#TCP-三次握手" class="headerlink" title="TCP 三次握手"></a>TCP 三次握手</h1><p>在了解具体的流程前，我们需要先认识几个概念<br><img src= "/img/loading.gif" data-src="/images/650.png" alt="alt">   </p>
<p>SYN：它的全称是 Synchronize Sequence Numbers，同步序列编号。是 TCP/IP 建立连接时使用的握手信号。在客户机和服务器之间建立 TCP 连接时，首先会发送的一个信号。客户端在接受到 SYN 消息时，就会在自己的段内生成一个随机值 X。</p>
<p>SYN-ACK：服务器收到 SYN 后，打开客户端连接，发送一个 SYN-ACK 作为答复。确认号设置为比接收到的序列号多一个，即 X + 1，服务器为数据包选择的序列号是另一个随机数 Y。</p>
<p>ACK：Acknowledge character, 确认字符，表示发来的数据已确认接收无误。最后，客户端将 ACK 发送给服务器。序列号被设置为所接收的确认值即 Y + 1。<br><img src= "/img/loading.gif" data-src="/images/651.png" alt="alt">   </p>
<p>如果用现实生活来举例的话就是</p>
<p>小明 - 客户端 小红 - 服务端</p>
<p>小明给小红打电话，接通了后，小明说喂，能听到吗，这就相当于是连接建立。</p>
<p>小红给小明回应，能听到，你能听到我说的话吗，这就相当于是请求响应。</p>
<p>小明听到小红的回应后，好的，这相当于是连接确认。在这之后小明和小红就可以通话/交换信息了。  </p>
<h1 id="TCP-四次挥手"><a href="#TCP-四次挥手" class="headerlink" title="TCP 四次挥手"></a>TCP 四次挥手</h1><p>在连接终止阶段使用四次挥手，连接的每一端都会独立的终止。下面我们来描述一下这个过程。<br><img src= "/img/loading.gif" data-src="/images/652.png" alt="alt">   </p>
<p>首先，客户端应用程序决定要终止连接(这里服务端也可以选择断开连接)。这会使客户端将 FIN 发送到服务器，并进入 FIN_WAIT_1 状态。当客户端处于 FIN_WAIT_1 状态时，它会等待来自服务器的 ACK 响应。</p>
<p>然后第二步，当服务器收到 FIN 消息时，服务器会立刻向客户端发送 ACK 确认消息。</p>
<p>当客户端收到服务器发送的 ACK 响应后，客户端就进入 FIN_WAIT_2 状态，然后等待来自服务器的 FIN 消息</p>
<p>服务器发送 ACK 确认消息后，一段时间（可以进行关闭后）会发送 FIN 消息给客户端，告知客户端可以进行关闭。</p>
<p>当客户端收到从服务端发送的 FIN 消息时，客户端就会由 FIN_WAIT_2 状态变为 TIME_WAIT 状态。处于 TIME_WAIT 状态的客户端允许重新发送 ACK 到服务器为了防止信息丢失。客户端在 TIME_WAIT 状态下花费的时间取决于它的实现，在等待一段时间后，连接关闭，客户端上所有的资源（包括端口号和缓冲区数据）都被释放。  </p>
<p>还是可以用上面那个通话的例子来进行描述</p>
<p>小明对小红说，我所有的东西都说完了，我要挂电话了。</p>
<p>小红说，收到，我这边还有一些东西没说。</p>
<p>经过若干秒后，小红也说完了，小红说，我说完了，现在可以挂断了</p>
<p>小明收到消息后，又等了若干时间后，挂断了电话.</p>
<h1 id="文章参考："><a href="#文章参考：" class="headerlink" title="文章参考："></a>文章参考：</h1><p>What is a TLS handshake?</p>
<p>Recursive and Iterative DNS Queries</p>
<p>DNS递归查询与迭代查询</p>
<p>TCP三次握手和四次挥手过程</p>
<p>TCP Connection Termination</p>
<p>Transmission_Control_Protocol</p>
<p>SYN</p>
<p>TCP 3-Way Handshake (SYN, SYN-ACK,ACK)</p>
<p>TCP vs UDP: What’s the Difference?</p>
<p>计算机网络7层模型</p>
<p>HTTP常见面试题</p>
]]></content>
      <categories>
        <category>面试分享</category>
      </categories>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title>使用mysql-connector操作MySQL-PYTHON</title>
    <url>/2020/03/29/%E4%BD%BF%E7%94%A8mysql-connector%E6%93%8D%E4%BD%9CMySQL-PYTHON/</url>
    <content><![CDATA[<h1 id="本文概述"><a href="#本文概述" class="headerlink" title="本文概述"></a>本文概述</h1><p>mysql-connector 是 MySQL 官方提供的驱动器。本文用python创建和删除mysql数据库数据表，实现数据插入、数据删除，数据查询、排序更新。</p>
<p>MySQL 是最流行的关系型数据库管理系统，如果你不不熟悉 MySQL，可以阅读我们的 MySQL 教程。</p>
<p>本章节我们为大家介绍使用 mysql-connector 来连接使用 MySQL， mysql-connector 是 MySQL 官方提供的驱动器。</p>
<p>我们可以使用 pip 命令来安装 mysql-connector：</p>
<pre><code>python -m pip install mysql-connector</code></pre><p>使用以下代码测试 mysql-connector 是否安装成功：</p>
<pre><code>demo_mysql_test.py:

import mysql.connector</code></pre><p>执行以上代码，如果没有产生错误，表明安装成功。</p>
<h1 id="创建数据库连接"><a href="#创建数据库连接" class="headerlink" title="创建数据库连接"></a>创建数据库连接</h1><p>可以使用以下代码来连接数据库：</p>
<pre><code>demo_mysql_test.py:

import mysql.connector

mydb = mysql.connector.connect(
  host=&quot;localhost&quot;,       # 数据库主机地址
  user=&quot;yourusername&quot;,    # 数据库用户名
  passwd=&quot;yourpassword&quot;   # 数据库密码
)

print(mydb)</code></pre><h1 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h1><p>创建数据库使用 “CREATE DATABASE” 语句，以下创建一个名为 alexis_db 的数据库：</p>
<pre><code>demo_mysql_test.py:

import mysql.connector

mydb = mysql.connector.connect(
  host=&quot;localhost&quot;,
  user=&quot;root&quot;,
  passwd=&quot;123456&quot;
)

mycursor = mydb.cursor()

mycursor.execute(&quot;CREATE DATABASE alexis_db&quot;)</code></pre><p>创建数据库前我们也可以使用 “SHOW DATABASES” 语句来查看数据库是否存在：</p>
<pre><code>demo_mysql_test.py:
输出所有数据库列表：

import mysql.connector

mydb = mysql.connector.connect(
  host=&quot;localhost&quot;,
  user=&quot;root&quot;,
  passwd=&quot;123456&quot;
)

mycursor = mydb.cursor()

mycursor.execute(&quot;SHOW DATABASES&quot;)

for x in mycursor:
  print(x)</code></pre><p>或者我们可以直接连接数据库，如果数据库不存在，会输出错误信息：</p>
<pre><code>demo_mysql_test.py:

import mysql.connector

mydb = mysql.connector.connect(
  host=&quot;localhost&quot;,
  user=&quot;root&quot;,
  passwd=&quot;123456&quot;,
  database=&quot;alexis_db&quot;
)</code></pre><h1 id="创建数据表"><a href="#创建数据表" class="headerlink" title="创建数据表"></a>创建数据表</h1><p>创建数据表使用 “CREATE TABLE” 语句，创建数据表前，需要确保数据库已存在，以下创建一个名为 sites 的数据表：</p>
<pre><code>demo_mysql_test.py:

import mysql.connector

mydb = mysql.connector.connect(
  host=&quot;localhost&quot;,
  user=&quot;root&quot;,
  passwd=&quot;123456&quot;,
  database=&quot;alexis_db&quot;
)
mycursor = mydb.cursor()

mycursor.execute(&quot;CREATE TABLE sites (name VARCHAR(255), url VARCHAR(255))&quot;)</code></pre><p>执行成功后，我们可以看到数据库创建的数据表 sites，字段为 name 和 url。</p>
<p>我们也可以使用 “SHOW TABLES” 语句来查看数据表是否已存在：</p>
<pre><code>demo_mysql_test.py:

import mysql.connector

mydb = mysql.connector.connect(
  host=&quot;localhost&quot;,
  user=&quot;root&quot;,
  passwd=&quot;123456&quot;,
  database=&quot;alexis_db&quot;
)
mycursor = mydb.cursor()

mycursor.execute(&quot;SHOW TABLES&quot;)

for x in mycursor:
  print(x)</code></pre><h1 id="主键设置"><a href="#主键设置" class="headerlink" title="主键设置"></a>主键设置</h1><p>创建表的时候我们一般都会设置一个主键（PRIMARY KEY），我们可以使用 “INT AUTO_INCREMENT PRIMARY KEY” 语句来创建一个主键，主键起始值为 1，逐步递增。</p>
<p>如果我们的表已经创建，我们需要使用 ALTER TABLE 来给表添加主键：</p>
<pre><code>demo_mysql_test.py:
给 sites 表添加主键。

import mysql.connector

mydb = mysql.connector.connect(
  host=&quot;localhost&quot;,
  user=&quot;root&quot;,
  passwd=&quot;123456&quot;,
  database=&quot;alexis_db&quot;
)
mycursor = mydb.cursor()

mycursor.execute(&quot;ALTER TABLE sites ADD COLUMN id INT AUTO_INCREMENT PRIMARY KEY&quot;)</code></pre><p>如果你还未创建 sites 表，可以直接使用以下代码创建。</p>
<pre><code>demo_mysql_test.py:
给表创建主键。

import mysql.connector

mydb = mysql.connector.connect(
  host=&quot;localhost&quot;,
  user=&quot;root&quot;,
  passwd=&quot;123456&quot;,
  database=&quot;alexis_db&quot;
)
mycursor = mydb.cursor()

mycursor.execute(&quot;CREATE TABLE sites (id INT AUTO_INCREMENT PRIMARY KEY, name VARCHAR(255), url VARCHAR(255))&quot;)</code></pre><h1 id="插入数据"><a href="#插入数据" class="headerlink" title="插入数据"></a>插入数据</h1><p>插入数据使用 “INSERT INTO” 语句：</p>
<pre><code>demo_mysql_test.py:
向 sites 表插入一条记录。

import mysql.connector

mydb = mysql.connector.connect(
  host=&quot;localhost&quot;,
  user=&quot;root&quot;,
  passwd=&quot;123456&quot;,
  database=&quot;alexis_db&quot;
)
mycursor = mydb.cursor()

sql = &quot;INSERT INTO sites (name, url) VALUES (%s, %s)&quot;
val = (&quot;alexis&quot;, &quot;https://alexisli.cn/&quot;)
mycursor.execute(sql, val)

mydb.commit()    # 数据表内容有更新，必须使用到该语句

print(mycursor.rowcount, &quot;记录插入成功。&quot;)</code></pre><p>执行代码，输出结果为：</p>
<pre><code>1 记录插入成功</code></pre><h1 id="批量插入-executemany-方法"><a href="#批量插入-executemany-方法" class="headerlink" title="批量插入 executemany() 方法"></a>批量插入 executemany() 方法</h1><p>批量插入使用 executemany() 方法，该方法的第二个参数是一个元组列表，包含了我们要插入的数据：</p>
<pre><code>demo_mysql_test.py:

import mysql.connector

mydb = mysql.connector.connect(
  host=&quot;localhost&quot;,
  user=&quot;root&quot;,
  passwd=&quot;123456&quot;,
  database=&quot;alexis_db&quot;
)
mycursor = mydb.cursor()

sql = &quot;INSERT INTO sites (name, url) VALUES (%s, %s)&quot;
val = [
  (&#39;Google&#39;, &#39;https://www.google.com&#39;),
  (&#39;Github&#39;, &#39;https://www.github.com&#39;),
  (&#39;Taobao&#39;, &#39;https://www.taobao.com&#39;),
  (&#39;stackoverflow&#39;, &#39;https://www.stackoverflow.com/&#39;)
]

mycursor.executemany(sql, val)

mydb.commit()    # 数据表内容有更新，必须使用到该语句

print(mycursor.rowcount, &quot;记录插入成功。&quot;)</code></pre><p>执行代码，输出结果为：</p>
<pre><code>4 记录插入成功。</code></pre><p>如果我们想在数据记录插入后，获取该记录的 ID ，可以使用以下代码：</p>
<pre><code>demo_mysql_test.py:

import mysql.connector

mydb = mysql.connector.connect(
  host=&quot;localhost&quot;,
  user=&quot;root&quot;,
  passwd=&quot;123456&quot;,
  database=&quot;alexis_db&quot;
)
mycursor = mydb.cursor()

sql = &quot;INSERT INTO sites (name, url) VALUES (%s, %s)&quot;
val = (&quot;Zhihu&quot;, &quot;https://www.zhihu.com&quot;)
mycursor.execute(sql, val)

mydb.commit()

print(&quot;1 条记录已插入, ID:&quot;, mycursor.lastrowid)</code></pre><p>执行代码，输出结果为：</p>
<pre><code>1 条记录已插入, ID: 6</code></pre><h1 id="查询数据"><a href="#查询数据" class="headerlink" title="查询数据"></a>查询数据</h1><p>查询数据使用 SELECT 语句：</p>
<pre><code>demo_mysql_test.py:

import mysql.connector

mydb = mysql.connector.connect(
  host=&quot;localhost&quot;,
  user=&quot;root&quot;,
  passwd=&quot;123456&quot;,
  database=&quot;alexis_db&quot;
)
mycursor = mydb.cursor()

mycursor.execute(&quot;SELECT * FROM sites&quot;)

myresult = mycursor.fetchall()     # fetchall() 获取所有记录

for x in myresult:
  print(x)</code></pre><p>执行代码，输出结果为：</p>
<pre><code>(1, &#39;alexis&#39;, &#39;https://alexisli.cn/&#39;)
(2, &#39;Google&#39;, &#39;https://www.google.com&#39;)
(3, &#39;Github&#39;, &#39;https://www.github.com&#39;)
(4, &#39;Taobao&#39;, &#39;https://www.taobao.com&#39;)
(5, &#39;stackoverflow&#39;, &#39;https://www.stackoverflow.com/&#39;)
(6, &#39;Zhihu&#39;, &#39;https://www.zhihu.com&#39;)</code></pre><p>也可以读取指定的字段数据：</p>
<pre><code>demo_mysql_test.py:

import mysql.connector

mydb = mysql.connector.connect(
  host=&quot;localhost&quot;,
  user=&quot;root&quot;,
  passwd=&quot;123456&quot;,
  database=&quot;alexis_db&quot;
)
mycursor = mydb.cursor()

mycursor.execute(&quot;SELECT name, url FROM sites&quot;)

myresult = mycursor.fetchall()

for x in myresult:
  print(x)</code></pre><p>执行代码，输出结果为：</p>
<pre><code>(&#39;alexis&#39;, &#39;https://alexisli.cn/&#39;)
(&#39;Google&#39;, &#39;https://www.google.com&#39;)
(&#39;Github&#39;, &#39;https://www.github.com&#39;)
(&#39;Taobao&#39;, &#39;https://www.taobao.com&#39;)
(&#39;stackoverflow&#39;, &#39;https://www.stackoverflow.com/&#39;)
(&#39;Zhihu&#39;, &#39;https://www.zhihu.com&#39;)</code></pre><h1 id="fetchone-方法"><a href="#fetchone-方法" class="headerlink" title="fetchone() 方法"></a>fetchone() 方法</h1><p>如果我们只想读取一条数据，可以使用 fetchone() 方法：</p>
<pre><code>demo_mysql_test.py:

import mysql.connector

mydb = mysql.connector.connect(
  host=&quot;localhost&quot;,
  user=&quot;root&quot;,
  passwd=&quot;123456&quot;,
  database=&quot;alexis_db&quot;
)
mycursor = mydb.cursor()

mycursor.execute(&quot;SELECT * FROM sites&quot;)

myresult = mycursor.fetchone()

print(myresult)</code></pre><p>执行代码，输出结果为：</p>
<pre><code>(1, &#39;alexis&#39;, &#39;https://alexisli.cn/&#39;)</code></pre><h1 id="where-条件语句"><a href="#where-条件语句" class="headerlink" title="where 条件语句"></a>where 条件语句</h1><p>如果我们要读取指定条件的数据，可以使用 where 语句：</p>
<pre><code>demo_mysql_test.py
读取 name 字段为 ai8py 的记录：

import mysql.connector

mydb = mysql.connector.connect(
  host=&quot;localhost&quot;,
  user=&quot;root&quot;,
  passwd=&quot;123456&quot;,
  database=&quot;alexis_db&quot;
)
mycursor = mydb.cursor()

sql = &quot;SELECT * FROM sites WHERE name =&#39;alexis&#39;&quot;

mycursor.execute(sql)

myresult = mycursor.fetchall()

for x in myresult:
  print(x)

执行代码，输出结果为：

(1, &#39;alexis&#39;, &#39;https://alexisli.cn/&#39;)
也可以使用通配符 %：</code></pre><pre><code>demo_mysql_test.py

import mysql.connector

mydb = mysql.connector.connect(
  host=&quot;localhost&quot;,
  user=&quot;root&quot;,
  passwd=&quot;123456&quot;,
  database=&quot;alexis_db&quot;
)
mycursor = mydb.cursor()

sql = &quot;SELECT * FROM sites WHERE url LIKE &#39;%oo%&#39;&quot;

mycursor.execute(sql)

myresult = mycursor.fetchall()

for x in myresult:
  print(x)

执行代码，输出结果为：

(1, &#39;alexis&#39;, &#39;https://alexisli.cn/&#39;)
(2, &#39;Google&#39;, &#39;https://www.google.com&#39;)</code></pre><p>为了防止数据库查询发生 SQL 注入的攻击，我们可以使用 %s 占位符来转义查询的条件：</p>
<pre><code>demo_mysql_test.py

import mysql.connector

mydb = mysql.connector.connect(
  host=&quot;localhost&quot;,
  user=&quot;root&quot;,
  passwd=&quot;123456&quot;,
  database=&quot;alexis_db&quot;
)
mycursor = mydb.cursor()

sql = &quot;SELECT * FROM sites WHERE name = %s&quot;
na = (&quot;alexis&quot;, )

mycursor.execute(sql, na)

myresult = mycursor.fetchall()

for x in myresult:
  print(x)</code></pre><h1 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h1><p>查询结果排序可以使用 ORDER BY 语句，默认的排序方式为升序，关键字为 ASC，如果要设置降序排序，可以设置关键字 DESC。</p>
<pre><code>demo_mysql_test.py
按 name 字段字母的升序排序：

import mysql.connector

mydb = mysql.connector.connect(
  host=&quot;localhost&quot;,
  user=&quot;root&quot;,
  passwd=&quot;123456&quot;,
  database=&quot;alexis_db&quot;
)
mycursor = mydb.cursor()

sql = &quot;SELECT * FROM sites ORDER BY name&quot;

mycursor.execute(sql)

myresult = mycursor.fetchall()

for x in myresult:
  print(x)</code></pre><p>执行代码，输出结果为：</p>
<pre><code>(3, &#39;Github&#39;, &#39;https://www.github.com&#39;)
(2, &#39;Google&#39;, &#39;https://www.google.com&#39;)
(1, &#39;alexis&#39;, &#39;https://www.alexisli.cn&#39;)
(5, &#39;stackoverflow&#39;, &#39;https://www.stackoverflow.com/&#39;)
(4, &#39;Taobao&#39;, &#39;https://www.taobao.com&#39;)
(6, &#39;Zhihu&#39;, &#39;https://www.zhihu.com&#39;)</code></pre><h1 id="降序排序实例："><a href="#降序排序实例：" class="headerlink" title="降序排序实例："></a>降序排序实例：</h1><pre><code>demo_mysql_test.py
按 name 字段字母的降序排序：

import mysql.connector

mydb = mysql.connector.connect(
  host=&quot;localhost&quot;,
  user=&quot;root&quot;,
  passwd=&quot;123456&quot;,
  database=&quot;alexis_db&quot;
)
mycursor = mydb.cursor()

sql = &quot;SELECT * FROM sites ORDER BY name DESC&quot;

mycursor.execute(sql)

myresult = mycursor.fetchall()

for x in myresult:
  print(x)</code></pre><p>执行代码，输出结果为：</p>
<pre><code>(6, &#39;Zhihu&#39;, &#39;https://www.zhihu.com&#39;)
(4, &#39;Taobao&#39;, &#39;https://www.taobao.com&#39;)
(5, &#39;stackoverflow&#39;, &#39;https://www.stackoverflow.com/&#39;)
(1, &#39;alexis&#39;, &#39;https://www.alexisli.cn&#39;)
(2, &#39;Google&#39;, &#39;https://www.google.com&#39;)
(3, &#39;Github&#39;, &#39;https://www.github.com&#39;)</code></pre><h1 id="Limit"><a href="#Limit" class="headerlink" title="Limit"></a>Limit</h1><p>如果我们要设置查询的数据量，可以通过 “LIMIT” 语句来指定</p>
<pre><code>demo_mysql_test.py
读取前 3 条记录：

import mysql.connector

mydb = mysql.connector.connect(
  host=&quot;localhost&quot;,
  user=&quot;root&quot;,
  passwd=&quot;123456&quot;,
  database=&quot;alexis_db&quot;
)
mycursor = mydb.cursor()

mycursor.execute(&quot;SELECT * FROM sites LIMIT 3&quot;)

myresult = mycursor.fetchall()

for x in myresult:
  print(x)</code></pre><p>执行代码，输出结果为：</p>
<pre><code>(1, &#39;alexis&#39;, &#39;https://www.alexisli.cn&#39;)
(2, &#39;Google&#39;, &#39;https://www.google.com&#39;)
(3, &#39;Github&#39;, &#39;https://www.github.com&#39;)</code></pre><p>也可以指定起始位置，使用的关键字是 OFFSET：</p>
<pre><code>demo_mysql_test.py
从第二条开始读取前 3 条记录：

import mysql.connector

mydb = mysql.connector.connect(
  host=&quot;localhost&quot;,
  user=&quot;root&quot;,
  passwd=&quot;123456&quot;,
  database=&quot;alexis_db&quot;
)
mycursor = mydb.cursor()

mycursor.execute(&quot;SELECT * FROM sites LIMIT 3 OFFSET 1&quot;)  # 0 为 第一条，1 为第二条，以此类推

myresult = mycursor.fetchall()

for x in myresult:
  print(x)</code></pre><p>执行代码，输出结果为：</p>
<pre><code>(2, &#39;Google&#39;, &#39;https://www.google.com&#39;)
(3, &#39;Github&#39;, &#39;https://www.github.com&#39;)
(4, &#39;Taobao&#39;, &#39;https://www.taobao.com&#39;)</code></pre><h1 id="删除记录"><a href="#删除记录" class="headerlink" title="删除记录"></a>删除记录</h1><p>删除记录使用 “DELETE FROM” 语句：</p>
<pre><code>demo_mysql_test.py
删除 name 为 stackoverflow 的记录：

import mysql.connector

mydb = mysql.connector.connect(
  host=&quot;localhost&quot;,
  user=&quot;root&quot;,
  passwd=&quot;123456&quot;,
  database=&quot;alexis_db&quot;
)
mycursor = mydb.cursor()

sql = &quot;DELETE FROM sites WHERE name = &#39;stackoverflow&#39;&quot;

mycursor.execute(sql)

mydb.commit()

print(mycursor.rowcount, &quot; 条记录删除&quot;)</code></pre><p>执行代码，输出结果为：</p>
<p>1  条记录删除<br>注意：要慎重使用删除语句，删除语句要确保指定了 WHERE 条件语句，否则会导致整表数据被删除。</p>
<p>为了防止数据库查询发生 SQL 注入的攻击，我们可以使用 %s 占位符来转义删除语句的条件：</p>
<pre><code>demo_mysql_test.py

import mysql.connector

mydb = mysql.connector.connect(
  host=&quot;localhost&quot;,
  user=&quot;root&quot;,
  passwd=&quot;123456&quot;,
  database=&quot;alexis_db&quot;
)
mycursor = mydb.cursor()

sql = &quot;DELETE FROM sites WHERE name = %s&quot;
na = (&quot;stackoverflow&quot;, )

mycursor.execute(sql, na)

mydb.commit()

print(mycursor.rowcount, &quot; 条记录删除&quot;)</code></pre><p>执行代码，输出结果为：</p>
<p>1  条记录删除</p>
<h1 id="更新表数据"><a href="#更新表数据" class="headerlink" title="更新表数据"></a>更新表数据</h1><p>数据表更新使用 “UPDATE” 语句：</p>
<pre><code>demo_mysql_test.py
将 name 为 Zhihu 的字段数据改为 ZH：

import mysql.connector

mydb = mysql.connector.connect(
  host=&quot;localhost&quot;,
  user=&quot;root&quot;,
  passwd=&quot;123456&quot;,
  database=&quot;alexis_db&quot;
)
mycursor = mydb.cursor()

sql = &quot;UPDATE sites SET name = &#39;ZH&#39; WHERE name = &#39;Zhihu&#39;&quot;

mycursor.execute(sql)

mydb.commit()

print(mycursor.rowcount, &quot; 条记录被修改&quot;)</code></pre><p>执行代码，输出结果为：</p>
<pre><code>1  条记录被修改</code></pre><p>注意：UPDATE 语句要确保指定了 WHERE 条件语句，否则会导致整表数据被更新。</p>
<p>为了防止数据库查询发生 SQL 注入的攻击，我们可以使用 %s 占位符来转义更新语句的条件：</p>
<pre><code>demo_mysql_test.py

import mysql.connector

mydb = mysql.connector.connect(
  host=&quot;localhost&quot;,
  user=&quot;root&quot;,
  passwd=&quot;123456&quot;,
  database=&quot;alexis_db&quot;
)
mycursor = mydb.cursor()

sql = &quot;UPDATE sites SET name = %s WHERE name = %s&quot;
val = (&quot;Zhihu&quot;, &quot;ZH&quot;)

mycursor.execute(sql, val)

mydb.commit()

print(mycursor.rowcount, &quot; 条记录被修改&quot;)</code></pre><p>执行代码，输出结果为：</p>
<pre><code>1  条记录被修改</code></pre><h1 id="删除表"><a href="#删除表" class="headerlink" title="删除表"></a>删除表</h1><p>删除表使用 “DROP TABLE” 语句， IF EXISTS 关键字是用于判断表是否存在，只有在存在的情况才删除：</p>
<pre><code>demo_mysql_test.py

import mysql.connector

mydb = mysql.connector.connect(
  host=&quot;localhost&quot;,
  user=&quot;root&quot;,
  passwd=&quot;123456&quot;,
  database=&quot;alexis_db&quot;
)
mycursor = mydb.cursor()

sql = &quot;DROP TABLE IF EXISTS sites&quot;  # 删除数据表 sites

mycursor.execute(sql)</code></pre>]]></content>
      <categories>
        <category>技术资讯</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>垃圾回收gc</title>
    <url>/2020/03/18/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6gc/</url>
    <content><![CDATA[<hr>
<p>python的垃圾收回机制不想c和c++是开发者自己管理维护内存的，python的垃圾回收是系统自己处理的，所以作为普通的开发者，我们不需要关注垃圾回收部分的内容，如果想要深层次理解python请继续看下文。</p>
<a id="more"></a>

<p><strong>python垃圾回收机制</strong><br>Python的GC模块主要运用了引用计数来跟踪和回收垃圾。在引用计数的基础上，还可以通过“标记－清除”解决容器对象可能产生的循环引用的问题。通过分代回收以空间换取时间进一步提高垃圾回收的效率。</p>
<h2 id="引用计数"><a href="#引用计数" class="headerlink" title="引用计数"></a>引用计数</h2><p><strong>原理：</strong>当一个对象的引用被创建或者复制时，对象的引用计数加1；当一个对象的引用被销毁时，对象的引用计数减1，当对象的引用计数减少为0时，就意味着对象已经再没有被使用了，可以将其内存释放掉。</p>
<p><strong>优点：</strong>引用计数有一个很大的优点，即实时性，任何内存，一旦没有指向它的引用，就会被立即回收，而其他的垃圾收集技术必须在某种特殊条件下才能进行无效内存的回收。</p>
<p><strong>缺点：</strong>但是它也有弱点，引用计数机制所带来的维护引用计数的额外操作与Python运行中所进行的内存分配和释放，引用赋值的次数是成正比的，这显然比其它那些垃圾收集技术所带来的额外操作只是与待回收的内存数量有关的效率要低。同时，引用技术还存在另外一个很大的问题－循环引用，因为对象之间相互引用，每个对象的引用都不会为0，所以这些对象所占用的内存始终都不会被释放掉。</p>
<h2 id="标记－清除"><a href="#标记－清除" class="headerlink" title="标记－清除"></a>标记－清除</h2><p>标记－清除只关注那些可能会产生循环引用的对象，显然，像是PyIntObject、PyStringObject这些不可变对象是不可能产生循环引用的，因为它们内部不可能持有其它对象的引用。Python中的循环引用总是发生在container对象之间，也就是能够在内部持有其它对象的对象，比如list、dict、class等等。这也使得该方法带来的开销只依赖于container对象的的数量。</p>
<p><strong>原理：</strong></p>
<ol>
<li>寻找跟对象（root object）的集合作为垃圾检测动作的起点，跟对象也就是一些全局引用和函数栈中的引用，这些引用所指向的对象是不可被删除的；</li>
<li>从root object集合出发，沿着root object集合中的每一个引用，如果能够到达某个对象，则说明这个对象是可达的，那么就不会被删除，这个过程就是垃圾检测阶段；</li>
<li>当检测阶段结束以后，所有的对象就分成可达和不可达两部分，所有的可达对象都进行保留，其它的不可达对象所占用的内存将会被回收，这就是垃圾回收阶段。（底层采用的是链表将这些集合的对象连接在一起）；</li>
</ol>
<p><strong>缺点：</strong>标记和清除的过程效率不高。</p>
<h2 id="分代回收"><a href="#分代回收" class="headerlink" title="分代回收"></a>分代回收</h2><p><strong>原理：</strong>将系统中的所有内存块根据其存活时间划分为不同的集合，每一个集合就成为一个“代”，Python默认定义了三代对象集合，垃圾收集的频率随着“代”的存活时间的增大而减小。也就是说，活得越长的对象，就越不可能是垃圾，就应该减少对它的垃圾收集频率。那么如何来衡量这个存活时间：通常是利用几次垃圾收集动作来衡量，如果一个对象经过的垃圾收集次数越多，可以得出：该对象存活时间就越长。</p>
]]></content>
      <categories>
        <category>基础常识</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>内置模块---PYTHON</title>
    <url>/2020/03/18/%E5%86%85%E7%BD%AE%E6%A8%A1%E5%9D%97-PYTHON/</url>
    <content><![CDATA[<p>常用内置模块列表：</p>
<ul>
<li>os</li>
<li>sys</li>
<li>json</li>
</ul>
<a id="more"></a>

<h1 id="os模块"><a href="#os模块" class="headerlink" title="os模块"></a>os模块</h1><p>os.getcwd() #获取当前程序目录</p>
<p>os.listdir(‘dirname’) #列出指定目录下的所有文件和子目录，包括隐藏文件，并以列表方式打印</p>
<p>os.remove() #删除一个文件</p>
<p>os.rename(“oldname”,”newname”) #重命名文件/目录</p>
<p>os.path.isfile(path) #如果path是一个存在的文件，返回True，否则返回False</p>
<p>os.path.exists(path) #如果path存在，返回True；如果path不存在，返回False</p>
<p>os.path.getatime(path) #返回path所指向的文件或者目录的最后存取时间</p>
<p>os.path.getmtime(path) #返回path所指向的文件或者目录的最后修改时间</p>
<h1 id="sys模块"><a href="#sys模块" class="headerlink" title="sys模块"></a>sys模块</h1><p>sys.exit(n) #退出程序，正常退出时exit(0)</p>
<p>sys.version  #获取Python解释程序的版本信息</p>
<p>sys.maxint #最大的Int值</p>
<p>sys.platform #返回操作系统平台名称</p>
<h1 id="json模块"><a href="#json模块" class="headerlink" title="json模块"></a>json模块</h1><p>json模块用于字符串 和 python数据类型间进行转换</p>
<p>json模块提供了四个功能：dumps、dump、loads、load</p>
<p>dumps、dump #把对象转换成str</p>
<p>loads、load #把str转换成json</p>
]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>处理企业级电商业务中的秒杀系统方案-PYTHON</title>
    <url>/2020/04/26/%E5%A4%84%E7%90%86%E4%BC%81%E4%B8%9A%E7%BA%A7%E7%94%B5%E5%95%86%E4%B8%9A%E5%8A%A1%E4%B8%AD%E7%9A%84%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%A1%88-PYTHON/</url>
    <content><![CDATA[<p>现在电商产业的多种多样，从最早的阿里巴巴、淘宝到现在的京东等等数不胜数，你还记得的京东的秒杀功能吗？我是这样理解的<a id="more"></a></p>
<h1 id="秒杀——抢订单环节一般会带来2个问题："><a href="#秒杀——抢订单环节一般会带来2个问题：" class="headerlink" title="秒杀——抢订单环节一般会带来2个问题："></a>秒杀——抢订单环节一般会带来2个问题：</h1><pre><code>1.高并发：大量用户同一时间抢购，网站瞬时访问量剧增，导致服务器压力大
2.超卖: 成功下订单买到商品的人数，超过数据库最大库存数量</code></pre><h1 id="遇到这种技术难题技术情况有什么解决方案："><a href="#遇到这种技术难题技术情况有什么解决方案：" class="headerlink" title="遇到这种技术难题技术情况有什么解决方案："></a>遇到这种技术难题技术情况有什么解决方案：</h1><pre><code>架构层面：
秒杀架构设计原则：
尽量将请求拦截在系统上游,读多写少的常用多使用缓存

扩容:
就是加机器

系统隔离：
为了避免短时间内的大访问量对现有网站业务造成的冲击，可以将秒杀系统独立部署。系统隔离更多是运行时的隔离，可以通过分组部署的方式和另外99%分开。秒杀还申请了单独的域名，目的也是让请求落到不同的集群中。即使秒杀系统崩溃了，也不会对网站造成影响。

数据隔离：
将即将被秒杀的热数据维护到redis。秒杀所调用的数据大部分都是热数据，比如会启用单独cache集群或MySQL数据库来放热点数据，目前也是不想0.01%的数据影响另外99.99%。

减库存操作：
一种是拍下减库存 另外一种是付款减库存；目前采用的“拍下减库存”的方式，拍下就是一瞬间的事，对用户体验会好些。

产品层面：
1.控制秒杀商品页面抢购按钮的可用/禁用。
购买按钮只有在秒杀开始的时候才能点亮，在此之前是灰色的，显示活动未开始。

2.增加了秒杀答题，基于时间分片削峰
秒杀答题一个很重要的目的是为了防止秒杀器。还有一个重要的功能，就是把峰值的下单请求给拉长了，从以前的1s之内延长到2~10s左右，请求峰值基于时间分片了，这个时间的分片对服务端处理并发非常重要，会减轻很大压力，另外由于请求的先后，靠后的请求自然也没有库存了，也根本到不了最后的下单步骤，所以真正的并发写就非常有限了。其实这种设计思路目前也非常普遍，如支付宝的“咻一咻”已及微信的摇一摇。

3.秒杀页面设计简化：
秒杀场景业务需求与一般购物不同，用户更在意的是能够抢到商品而不是用户体验。所以秒杀商品页面应尽可能简单并且拍下后地址等个人信息应该使用默认信息，减轻秒杀进行时系统负载，若有更改可以在秒杀结束后进行更改。

3.前端层面
静态化以及页面缓存
将页面能够静态的部分都静态化，并将静态页面缓存于CDN，以及反向代理服务器，可能还要临时租借服务器。
利用 页面静态化、数据静态化，反向代理 等方法可以避免 带宽和sql压力 ，但是随之而来一个问题，页面抢单按钮也不会刷新了，可以把 js 文件单独放在js服务器上，由另外一台服务器写 定时任务 来控制js 推送。 另外还有一个问题，js文件会被大部分浏览器缓存，我们可以使用xxx.js?v=随机数 的方式来避免js被缓存。

限流（反作弊）
1.针对同一个用户id来实现，前端js控制一个客户端几秒之内只能发送同一个请求，后端校验同一个uid在几秒之内返回同一个页面

2.针对同一个ip来实现，进行ip检测，同一个ip几秒之内不发送请求或者只返回同一个页面

3.针对多用户多ip来实现，依靠数据分析

4.为了避免用户直接访问下单页面URL，需要将改URL动态化，即使秒杀系统的开发者也无法在秒杀开始前访问下单页面的URL。办法是在下单页面URL加入由服务器端生成的随机数作为参数，在秒杀开始的时候才能得到。

后端层面：
1.加入缓存redis：
因为秒杀是典型的读多写少的场景，适合操作内存而非操作硬盘；缓存工具redis本身的操作是保证原子性的，所以可以保证请求了redis的写的操作的线程安全性。

2.加入消息队列，利用队列进行削峰：
将用户请求放置于一个或多个队列中，队列中元素总和等于该商品库存总和，未进入队列的请求均失败。利用多线程轮询分别从一个或多个队列中取出用户请求。操作redis进行减库存操作，成功减库存之后返回成功，并将用户信息与商品信息存入另一个队列当中，进行生成订单的操作。利用两个队列异步处理业务减轻秒杀高峰时期服务器负载。

3.程序计数器：
队列与缓存为了保证请求redis的次数不超过总的库存量，利用一个程序计数器来这一点。程序计数器用JUC包下原子类可以实现。

4.分布式锁
分布式情况下可以利用分布式锁来解决任务每次只能由一次服务来执行且不能重复执行。
分布式锁的实现：zk、redis
分布式锁的优化：先考虑是否可以去锁，然后考虑尽可能多用乐观锁，少用悲观锁。这里有一个问题，乐观锁如果每一次都会有并发冲突的话性能反而不如悲观锁，那么难道真的多用乐观锁性能会比悲观锁高吗？选举考虑ha，比如心跳检测。

分布式去锁 方案
利用集群并发加入队列，选举队列处理服务单点执行，这样可以保证并发实现和加锁一样的并发量但不会影响性能。
</code></pre>]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>多线程-PYTHON</title>
    <url>/2020/03/20/%E5%A4%9A%E7%BA%BF%E7%A8%8B-PYTHON/</url>
    <content><![CDATA[<p>Python 多线程Threading<br>任何进程默认就会启动一个线程，我们把该线程称为主线程，主线程又可以启动新的线程，Python的threading模块有个current_thread()函数，它永远返回当前线程的实例。主线程实例的名字叫MainThread，子线程的名字在创建时指定，我们用LoopThread命名子线程。</p>
<a id="more"></a>
<p>多线程类似于同时执行多个不同程序，多线程运行有如下优点：</p>
<p>使用线程可以把占据长时间的程序中的任务放到后台去处理。<br>用户界面可以更加吸引人，比如用户点击了一个按钮去触发某些事件的处理，可以弹出一个进度条来显示处理的进度<br>程序的运行速度可能加快<br>在一些等待的任务实现上如用户输入、文件读写和网络收发数据等，线程就比较有用了。在这种情况下我们可以释放一些珍贵的资源如内存占用等等。<br>线程在执行过程中与进程还是有区别的。每个独立的线程有一个程序运行的入口、顺序执行序列和程序的出口。但是线程不能够独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制。</p>
<p>每个线程都有他自己的一组CPU寄存器，称为线程的上下文，该上下文反映了线程上次运行该线程的CPU寄存器的状态。</p>
<p>指令指针和堆栈指针寄存器是线程上下文中两个最重要的寄存器，线程总是在进程得到上下文中运行的，这些地址都用于标志拥有线程的进程地址空间中的内存。</p>
<p>线程可以被抢占（中断）。<br>在其他线程正在运行时，线程可以暂时搁置（也称为睡眠） — 这就是线程的退让。<br>线程可以分为:</p>
<p>内核线程：由操作系统内核创建和撤销。<br>用户线程：不需要内核支持而在用户程序中实现的线程。<br>Python3 线程中常用的两个模块为：</p>
<p>_thread<br>threading(推荐使用)<br>thread 模块已被废弃。用户可以使用 threading 模块代替。所以，在 Python3 中不能再使用”thread” 模块。为了兼容性，Python3 将 thread 重命名为 “_thread”。</p>
<h1 id="开始学习Python线程"><a href="#开始学习Python线程" class="headerlink" title="开始学习Python线程"></a>开始学习Python线程</h1><p>Python中使用线程有两种方式：函数或者用类来包装线程对象。</p>
<p>函数式：调用 _thread 模块中的start_new_thread()函数来产生新线程。语法如下:</p>
<p>_thread.start_new_thread ( function, args[, kwargs] )</p>
<h1 id="参数说明"><a href="#参数说明" class="headerlink" title="参数说明:"></a>参数说明:</h1><p>function – 线程函数。<br>args – 传递给线程函数的参数,他必须是个tuple类型。<br>kwargs – 可选参数。<br>实例：</p>
<pre><code>#!/usr/bin/python3
import _thread
import time
# 为线程定义一个函数
def print_time( threadName, delay):
   count = 0
   while count &lt; 5:
      time.sleep(delay)
      count += 1
      print (&quot;%s: %s&quot; % ( threadName, time.ctime(time.time()) ))
# 创建两个线程 
try:
   _thread.start_new_thread( print_time, (&quot;Thread-1&quot;, 2, ) )
   _thread.start_new_thread( print_time, (&quot;Thread-2&quot;, 4, ) )
except:
   print (&quot;Error: 无法启动线程&quot;)
while 1:
   pass

执行以上程序输出结果如下：

Thread-1: Wed Apr  6 11:36:31 2016
Thread-1: Wed Apr  6 11:36:33 2016
Thread-2: Wed Apr  6 11:36:33 2016
Thread-1: Wed Apr  6 11:36:35 2016
Thread-1: Wed Apr  6 11:36:37 2016
Thread-2: Wed Apr  6 11:36:37 2016
Thread-1: Wed Apr  6 11:36:39 2016
Thread-2: Wed Apr  6 11:36:41 2016
Thread-2: Wed Apr  6 11:36:45 2016
Thread-2: Wed Apr  6 11:36:49 2016
执行以上程后可以按下 ctrl-c to 退出。</code></pre><h1 id="线程模块"><a href="#线程模块" class="headerlink" title="线程模块"></a>线程模块</h1><p>Python3 通过两个标准库 _thread 和 threading 提供对线程的支持。</p>
<p>_thread 提供了低级别的、原始的线程以及一个简单的锁，它相比于 threading 模块的功能还是比较有限的。</p>
<p>threading 模块除了包含 _thread 模块中的所有方法外，还提供的其他方法：</p>
<p>threading.currentThread(): 返回当前的线程变量。<br>threading.enumerate(): 返回一个包含正在运行的线程的list。正在运行指线程启动后、结束前，不包括启动前和终止后的线程。<br>threading.activeCount(): 返回正在运行的线程数量，与len(threading.enumerate())有相同的结果。<br>除了使用方法外，线程模块同样提供了Thread类来处理线程，Thread类提供了以下方法:</p>
<p>run(): 用以表示线程活动的方法。<br>start():启动线程活动。<br>join([time]): 等待至线程中止。这阻塞调用线程直至线程的join() 方法被调用中止-正常退出或者抛出未处理的异常-或者是可选的超时发生。<br>isAlive(): 返回线程是否活动的。<br>getName(): 返回线程名。<br>setName(): 设置线程名。</p>
<h1 id="使用-threading-模块创建线程"><a href="#使用-threading-模块创建线程" class="headerlink" title="使用 threading 模块创建线程"></a>使用 threading 模块创建线程</h1><p>我们可以通过直接从 threading.Thread 继承创建一个新的子类，并实例化后调用 start() 方法启动新线程，即它调用了线程的 run() 方法：</p>
<pre><code>#!/usr/bin/python3
import threading
import time
exitFlag = 0
class myThread (threading.Thread):
    def __init__(self, threadID, name, counter):
        threading.Thread.__init__(self)
        self.threadID = threadID
        self.name = name
        self.counter = counter
    def run(self):
        print (&quot;开始线程：&quot; + self.name)
        print_time(self.name, self.counter, 5)
        print (&quot;退出线程：&quot; + self.name)
def print_time(threadName, delay, counter):
    while counter:
        if exitFlag:
            threadName.exit()
        time.sleep(delay)
        print (&quot;%s: %s&quot; % (threadName, time.ctime(time.time())))
        counter -= 1
# 创建新线程
thread1 = myThread(1, &quot;Thread-1&quot;, 1)
thread2 = myThread(2, &quot;Thread-2&quot;, 2)
# 开启新线程
thread1.start()
thread2.start()
thread1.join()
thread2.join()
print (&quot;退出主线程&quot;)
以上程序执行结果如下；

开始线程：Thread-1
开始线程：Thread-2
Thread-1: Wed Apr  6 11:46:46 2016
Thread-1: Wed Apr  6 11:46:47 2016
Thread-2: Wed Apr  6 11:46:47 2016
Thread-1: Wed Apr  6 11:46:48 2016
Thread-1: Wed Apr  6 11:46:49 2016
Thread-2: Wed Apr  6 11:46:49 2016
Thread-1: Wed Apr  6 11:46:50 2016
退出线程：Thread-1
Thread-2: Wed Apr  6 11:46:51 2016
Thread-2: Wed Apr  6 11:46:53 2016
Thread-2: Wed Apr  6 11:46:55 2016
退出线程：Thread-2
退出主线程</code></pre><h1 id="线程同步"><a href="#线程同步" class="headerlink" title="线程同步"></a>线程同步</h1><p>如果多个线程共同对某个数据修改，则可能出现不可预料的结果，为了保证数据的正确性，需要对多个线程进行同步。</p>
<p>使用 Thread 对象的 Lock 和 Rlock 可以实现简单的线程同步，这两个对象都有 acquire 方法和 release 方法，对于那些需要每次只允许一个线程操作的数据，可以将其操作放到 acquire 和 release 方法之间。如下：</p>
<p>多线程的优势在于可以同时运行多个任务（至少感觉起来是这样）。但是当线程需要共享数据时，可能存在数据不同步的问题。</p>
<p>考虑这样一种情况：一个列表里所有元素都是0，线程”set”从后向前把所有元素改成1，而线程”print”负责从前往后读取列表并打印。</p>
<p>那么，可能线程”set”开始改的时候，线程”print”便来打印列表了，输出就成了一半0一半1，这就是数据的不同步。为了避免这种情况，引入了锁的概念。</p>
<p>锁有两种状态——锁定和未锁定。每当一个线程比如”set”要访问共享数据时，必须先获得锁定；如果已经有别的线程比如”print”获得锁定了，那么就让线程”set”暂停，也就是同步阻塞；等到线程”print”访问完毕，释放锁以后，再让线程”set”继续。</p>
<p>经过这样的处理，打印列表时要么全部输出0，要么全部输出1，不会再出现一半0一半1的尴尬场面。</p>
<p>实例：</p>
<pre><code>#!/usr/bin/python3
import threading
import time
class myThread (threading.Thread):
    def __init__(self, threadID, name, counter):
        threading.Thread.__init__(self)
        self.threadID = threadID
        self.name = name
        self.counter = counter
    def run(self):
        print (&quot;开启线程： &quot; + self.name)
        # 获取锁，用于线程同步
        threadLock.acquire()
        print_time(self.name, self.counter, 3)
        # 释放锁，开启下一个线程
        threadLock.release()
def print_time(threadName, delay, counter):
    while counter:
        time.sleep(delay)
        print (&quot;%s: %s&quot; % (threadName, time.ctime(time.time())))
        counter -= 1
threadLock = threading.Lock()
threads = []
# 创建新线程
thread1 = myThread(1, &quot;Thread-1&quot;, 1)
thread2 = myThread(2, &quot;Thread-2&quot;, 2)
# 开启新线程
thread1.start()
thread2.start()
# 添加线程到线程列表
threads.append(thread1)
threads.append(thread2)
# 等待所有线程完成
for t in threads:
    t.join()
print (&quot;退出主线程&quot;)
执行以上程序，输出结果为：

开启线程： Thread-1
开启线程： Thread-2
Thread-1: Wed Apr  6 11:52:57 2016
Thread-1: Wed Apr  6 11:52:58 2016
Thread-1: Wed Apr  6 11:52:59 2016
Thread-2: Wed Apr  6 11:53:01 2016
Thread-2: Wed Apr  6 11:53:03 2016
Thread-2: Wed Apr  6 11:53:05 2016
退出主线程</code></pre><h1 id="线程优先级队列（-Queue）"><a href="#线程优先级队列（-Queue）" class="headerlink" title="线程优先级队列（ Queue）"></a>线程优先级队列（ Queue）</h1><p>Python 的 Queue 模块中提供了同步的、线程安全的队列类，包括FIFO（先入先出)队列Queue，LIFO（后入先出）队列LifoQueue，和优先级队列 PriorityQueue。</p>
<p>这些队列都实现了锁原语，能够在多线程中直接使用，可以使用队列来实现线程间的同步。</p>
<p>Queue 模块中的常用方法:</p>
<pre><code>Queue.qsize() 返回队列的大小
Queue.empty() 如果队列为空，返回True,反之False
Queue.full() 如果队列满了，返回True,反之False
Queue.full 与 maxsize 大小对应
Queue.get([block[, timeout]])获取队列，timeout等待时间
Queue.get_nowait() 相当Queue.get(False)
Queue.put(item) 写入队列，timeout等待时间
Queue.put_nowait(item) 相当Queue.put(item, False)
Queue.task_done() 在完成一项工作之后，Queue.task_done()函数向任务已经完成的队列发送一个信号
Queue.join() 实际上意味着等到队列为空，再执行别的操作</code></pre><p>实例:</p>
<pre><code>#!/usr/bin/python3
import queue
import threading
import time
exitFlag = 0
class myThread (threading.Thread):
    def __init__(self, threadID, name, q):
        threading.Thread.__init__(self)
        self.threadID = threadID
        self.name = name
        self.q = q
    def run(self):
        print (&quot;开启线程：&quot; + self.name)
        process_data(self.name, self.q)
        print (&quot;退出线程：&quot; + self.name)
def process_data(threadName, q):
    while not exitFlag:
        queueLock.acquire()
        if not workQueue.empty():
            data = q.get()
            queueLock.release()
            print (&quot;%s processing %s&quot; % (threadName, data))
        else:
            queueLock.release()
        time.sleep(1)
threadList = [&quot;Thread-1&quot;, &quot;Thread-2&quot;, &quot;Thread-3&quot;]
nameList = [&quot;One&quot;, &quot;Two&quot;, &quot;Three&quot;, &quot;Four&quot;, &quot;Five&quot;]
queueLock = threading.Lock()
workQueue = queue.Queue(10)
threads = []
threadID = 1
# 创建新线程
for tName in threadList:
    thread = myThread(threadID, tName, workQueue)
    thread.start()
    threads.append(thread)
    threadID += 1
# 填充队列
queueLock.acquire()
for word in nameList:
    workQueue.put(word)
queueLock.release()
# 等待队列清空
while not workQueue.empty():
    pass
# 通知线程是时候退出
exitFlag = 1
# 等待所有线程完成
for t in threads:
    t.join()
print (&quot;退出主线程&quot;)
以上程序执行结果：

开启线程：Thread-1
开启线程：Thread-2
开启线程：Thread-3
Thread-3 processing One
Thread-1 processing Two
Thread-2 processing Three
Thread-3 processing Four
Thread-1 processing Five
退出线程：Thread-3
退出线程：Thread-2
退出线程：Thread-1
退出主线程</code></pre>]]></content>
      <categories>
        <category>基础进阶</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>安装常用工具包-LINUX</title>
    <url>/2020/03/19/%E5%AE%89%E8%A3%85%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%E5%8C%85-LINUX/</url>
    <content><![CDATA[<p>全部操作都在root用户下执行</p>
<a id="more"></a>
<h1 id="安装编译相关工具"><a href="#安装编译相关工具" class="headerlink" title="安装编译相关工具"></a>安装编译相关工具</h1><p>yum -y groupinstall “Development tools”<br>yum -y install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gdbm-devel db4-devel libpcap-devel xz-devel<br>yum install libffi-devel -y<br>2.下载安装包解压<br>wget <a href="https://www.python.org/ftp/python/3.7.0/Python-3.7.0.tar.xz" target="_blank" rel="noopener">https://www.python.org/ftp/python/3.7.0/Python-3.7.0.tar.xz</a><br>tar -xvJf  Python-3.7.0.tar.xz<br>3.编译安装<br>mkdir /usr/local/python3 #创建编译安装目录<br>cd Python-3.7.0<br>./configure –prefix=/usr/local/python3<br>make &amp;&amp; make install<br>4.创建软连接<br>ln -s /usr/local/python3/bin/python3 /usr/local/bin/python3<br>ln -s /usr/local/python3/bin/pip3 /usr/local/bin/pip3<br>5.验证是否成功<br>python3 -V<br>pip3 -V</p>
<h1 id="添加Nginx的源"><a href="#添加Nginx的源" class="headerlink" title="添加Nginx的源"></a>添加Nginx的源</h1><p>rpm -Uvh <a href="http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpm" target="_blank" rel="noopener">http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpm</a></p>
<h1 id="安装Nginx"><a href="#安装Nginx" class="headerlink" title="安装Nginx"></a>安装Nginx</h1><p>yum install -y nginx<br>安装成功后，配置文件目录为/etc/nginx</p>
<h1 id="启动Nginx"><a href="#启动Nginx" class="headerlink" title="启动Nginx"></a>启动Nginx</h1><p>systemctl start nginx.service #启动Nginx<br>systemctl enable nginx.service #设置开机自启</p>
<h1 id="yum安装redis"><a href="#yum安装redis" class="headerlink" title="yum安装redis"></a>yum安装redis</h1><p>yum install -y epel-release<br>yum install -y redis</p>
<h1 id="启动redis"><a href="#启动redis" class="headerlink" title="启动redis"></a>启动redis</h1><p>service redis start #启动redis<br>service redis status #查看redis状态</p>
<hr>
<p>ps -ef | grep redis #查看redis进程<br>service redis stop #停止redis</p>
<h1 id="设置开机自启"><a href="#设置开机自启" class="headerlink" title="设置开机自启"></a>设置开机自启</h1><p>chkconfig redis on</p>
<h1 id="修改redis配置"><a href="#修改redis配置" class="headerlink" title="修改redis配置"></a>修改redis配置</h1><p>vim /etc/redis.conf<br>修改如下内容:</p>
<p>port 6379 #启动端口<br>requirepass 111111 #访问密码<br>重启redis</p>
<p>service redis restart<br>登录redis<br>注: 127.0.0.1:6379&gt;为redis数据库前缀</p>
<p>redis-cli #登录redis<br>127.0.0.1:6379&gt; auth 111111 #认证登录<br>127.0.0.1:6379&gt; keys * #查看当前的key</p>
<h1 id="下载安装mysql-yum-源"><a href="#下载安装mysql-yum-源" class="headerlink" title="下载安装mysql yum 源"></a>下载安装mysql yum 源</h1><p>wget -i -c <a href="http://dev.mysql.com/get/mysql57-community-release-el7-10.noarch.rpm" target="_blank" rel="noopener">http://dev.mysql.com/get/mysql57-community-release-el7-10.noarch.rpm</a><br>yum install -y mysql57-community-release-el7-10.noarch.rpm<br>安装mysql并启动<br>yum install -y mysql-community-server #安装mysql<br>systemctl start  mysqld.service #启动<br>systemctl status mysqld.service #查看运行状态<br>登录mysql<br>grep “password” /var/log/mysqld.log #查看mysql生成的密码<br>mysql -uroot -p #以root用户登录mysql<br>修改root密码<br>注: mysql&gt; 为提示符；新密码需符合：包含字母大小写、特殊符和数字，且位数大于4</p>
<p>mysql&gt; ALTER USER ‘root’@’localhost’ IDENTIFIED BY ‘new password’;<br> 授权root用户远程访问<br>mysql&gt; use mysql;<br>mysql&gt; grant all privileges  on <em>.</em> to root@’%’ identified by “password”;<br>mysql&gt; flush privileges;</p>
<h1 id="下载sqlite安装包"><a href="#下载sqlite安装包" class="headerlink" title="下载sqlite安装包"></a>下载sqlite安装包</h1><p>cd /opt<br>wget <a href="http://www.sqlite.org/2015/sqlite-autoconf-3081101.tar.gz" target="_blank" rel="noopener">http://www.sqlite.org/2015/sqlite-autoconf-3081101.tar.gz</a> #下载安装包<br>tar zxvf sqlite-autoconf-3081101.tar.gz  #进行解压<br>3.编译安装<br>cd sqlite-autoconf-3081101/<br>./configure<br>make &amp;&amp; make install<br>yum install sqlite-devel<br>4.链接sqlite3<br>cd #回到用户目录<br>sqlite3 #链接sqlite3</p>
<p>5.退出sqlite3<br>sqlite3链接成功后，执行如下：</p>
<p>sqlite&gt; .quit #退出sqlite3</p>
]]></content>
      <categories>
        <category>基础-Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>小程序开发快速入门（一）</title>
    <url>/2020/03/31/%E5%B0%8F%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>微信小程序的技术栈和 Web 开发类似，页面展示使用微信自定制的类似 HTML 和 CSS 的标记语言，互动与数据存取使用 JavaScript。<a id="more"></a>从 Web 开发转向微信小程序开发非常容易。如果没有 WEB 基础，需要对 HTML 和 CSS 有基本认识，学会写 JavaScript 代码。</p>
<p>另外要独立制作小程序，除了掌握小程序开发技术，最好还会使用一种原型设计工具，以便于呈现、打磨自己的想法。  </p>
<h1 id="账号申请-开发者工具"><a href="#账号申请-开发者工具" class="headerlink" title="账号申请 开发者工具"></a>账号申请 开发者工具</h1><p>账号申请地址：<a href="https://mp.weixin.qq.com/" target="_blank" rel="noopener" title="注册">注册</a><br>开发者工具地址：<a href="https://developers.weixin.qq.com/miniprogram/dev/devtools/download.html" target="_blank" rel="noopener" title="IDE">开发工具</a><br>具体申请过程不赘述了，开发者工具首次使用的时候需要用微信认证，并且项目要绑定到申请的小程序账号，在创建项目的时候按照提示填写相关内容即可。（APPID 在小程序账号里可以找到）  </p>
]]></content>
      <categories>
        <category>微信小程序教程</category>
      </categories>
      <tags>
        <tag>小程序</tag>
      </tags>
  </entry>
  <entry>
    <title>大数据采集、清洗、处理：使用MapReduce进行离线数据分析---大数据</title>
    <url>/2020/06/01/%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E3%80%81%E6%B8%85%E6%B4%97%E3%80%81%E5%A4%84%E7%90%86%EF%BC%9A%E4%BD%BF%E7%94%A8MapReduce%E8%BF%9B%E8%A1%8C%E7%A6%BB%E7%BA%BF%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E5%A4%A7%E6%95%B0%E6%8D%AE/</url>
    <content><![CDATA[<p>在互联网应用中，不管是哪一种处理方式，其基本的数据来源都是日志数据<a id="more"></a>，例如对于web应用来说，则可能是用户的访问日志、用户的点击日志等。<br>如果对于数据的分析结果在时间上有比较严格的要求，则可以采用在线处理的方式来对数据进行分析，如使用Spark、Storm等进行处理。比较贴切的一个例子是天猫双十一的成交额，在其展板上，我们看到交易额是实时动态进行更新的，对于这种情况，则需要采用在线处理。<br>当然，如果只是希望得到数据的分析结果，对处理的时间要求不严格，就可以采用离线处理的方式，比如我们可以先将日志数据采集到HDFS中，之后再进一步使用MapReduce、Hive等来对数据进行分析，这也是可行的。<br>这份文档主要分享对某个电商网站产生的用户访问日志（access.log）进行离线处理与分析的过程，基于MapReduce的处理方式，最后会统计出某一天不同省份访问该网站的uv与pv。</p>
<h1 id="大数据处理的常用方法"><a href="#大数据处理的常用方法" class="headerlink" title="大数据处理的常用方法"></a>大数据处理的常用方法</h1><p>大数据处理目前比较流行的是两种方法，一种是离线处理，一种是在线处理。</p>
<h1 id="生产场景与需求"><a href="#生产场景与需求" class="headerlink" title="生产场景与需求"></a>生产场景与需求</h1><p>在我们的场景中，Web应用的部署是如下的架构：<br>即比较典型的Nginx负载均衡+KeepAlive高可用集群架构，在每台Web服务器上，都会产生用户的访问日志，业务需求方给出的日志格式如下：  </p>
<pre><code>1001    211.167.248.22  eecf0780-2578-4d77-a8d6-e2225e8b9169    40604   1       GET /top HTTP/1.0       408     null      null    1523188122767
1003    222.68.207.11   eecf0780-2578-4d77-a8d6-e2225e8b9169    20202   1       GET /tologin HTTP/1.1   504     null      Mozilla/5.0 (Windows; U; Windows NT 5.1)Gecko/20070309 Firefox/2.0.0.3  1523188123267
1001    61.53.137.50    c3966af9-8a43-4bda-b58c-c11525ca367b    0       1       GET /update/pass HTTP/1.0       302       null    null    1523188123768
1000    221.195.40.145  1aa3b538-2f55-4cd7-9f46-6364fdd1e487    0       0       GET /user/add HTTP/1.1  200     null      Mozilla/4.0 (compatible; MSIE 7.0; Windows NT5.2)       1523188124269
1000    121.11.87.171   8b0ea90a-77a5-4034-99ed-403c800263dd    20202   1       GET /top HTTP/1.0       408     null      Mozilla/5.0 (Windows; U; Windows NT 5.1)Gecko/20070803 Firefox/1.5.0.12 1523188120263</code></pre><p>其每个字段的说明如下：  </p>
<pre><code>appid ip mid userid login_type request status http_referer user_agent time
其中：
appid包括：web:1000,android:1001,ios:1002,ipad:1003
mid:唯一的id此id第一次会种在浏览器的cookie里。如果存在则不再种。作为浏览器唯一标示。移动端或者pad直接取机器码。
login_type：登录状态，0未登录、1：登录用户
request：类似于此种 &quot;GET /userList HTTP/1.1&quot;
status：请求的状态主要有：200 ok、404 not found、408 Request Timeout、500 Internal Server Error、504 Gateway Timeout等
http_referer：请求该url的上一个url地址。
user_agent：浏览器的信息，例如：&quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36&quot;
time：时间的long格式：1451451433818。</code></pre><p>根据给定的时间范围内的日志数据，现在业务方有如下需求：<br>统计出每个省每日访问的PV、UV。  </p>
<h1 id="数据采集：获取原生数据"><a href="#数据采集：获取原生数据" class="headerlink" title="数据采集：获取原生数据"></a>数据采集：获取原生数据</h1><p>对于用户访问日志的采集，使用的是Flume，并且会将采集的数据保存到HDFS中，其架构思路如下：  </p>
<pre><code>不同的Web Server上都会部署一个Agent用于该Server上日志数据的采集，之后，不同Web Server的Flume Agent采集的日志数据会下沉到另外一个被称为Flume Consolidation Agent（聚合Agent）的Flume Agent上，该Flume Agent的数据落地方式为输出到HDFS。</code></pre><p>在我们的HDFS中，可以查看到其采集的日志：<br><img src= "/img/loading.gif" data-src="/images/hadoop.png"></p>
<p>后面我们的工作正是要基于Flume采集到HDFS中的数据做离线处理与分析。</p>
<h1 id="数据清洗："><a href="#数据清洗：" class="headerlink" title="数据清洗："></a>数据清洗：</h1><p>将不规整数据转化为规整数据</p>
<h1 id="数据清洗目的"><a href="#数据清洗目的" class="headerlink" title="数据清洗目的"></a>数据清洗目的</h1><p>刚刚采集到HDFS中的原生数据，我们也称为不规整数据，即目前来说，该数据的格式还无法满足我们对数据处理的基本要求，需要对其进行预处理，转化为我们后面工作所需要的较为规整的数据，所以这里的数据清洗，其实指的就是对数据进行基本的预处理，以方便我们后面的统计分析，所以这一步并不是必须的，需要根据不同的业务需求来进行取舍，只是在我们的场景中需要对数据进行一定的处理。</p>
<h1 id="数据清洗方案"><a href="#数据清洗方案" class="headerlink" title="数据清洗方案"></a>数据清洗方案</h1><p>原来的日志数据格式是如下的：</p>
<pre><code>appid ip mid userid login_type request status http_referer user_agent time
其中：
appid包括：web:1000,android:1001,ios:1002,ipad:1003
mid:唯一的id此id第一次会种在浏览器的cookie里。如果存在则不再种。作为浏览器唯一标示。移动端或者pad直接取机器码。
login_type：登录状态，0未登录、1：登录用户
request：类似于此种 &quot;GET /userList HTTP/1.1&quot;
status：请求的状态主要有：200 ok、404 not found、408 Request Timeout、500 Internal Server Error、504 Gateway Timeout等
http_referer：请求该url的上一个url地址。
user_agent：浏览器的信息，例如：&quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36&quot;
time：时间的long格式：1451451433818。</code></pre><p>但是如果需要按照省份来统计uv、pv，其所包含的信息还不够，我们需要对这些数据做一定的预处理，比如需要，对于其中包含的IP信息，我们需要将其对应的IP信息解析出来；为了方便我们的其它统计，我们也可以将其request信息解析为method、 request_url、 http_version等，所以按照上面的分析，我们希望预处理之后的日志数据包含如下的数据字段：  </p>
<pre><code>appid;  
ip;
//通过ip来衍生出来的字段 province和city
province;
city;

mid;      
userId;    
loginType; 
request; 
//通过request 衍生出来的字段 method request_url http_version
method;
requestUrl;
httpVersion;

status;          
httpReferer; 
userAgent;   
//通过userAgent衍生出来的字段，即用户的浏览器信息
browser;

time;</code></pre><p>即在原来的基础上，我们增加了其它新的字段，如province、city等。  </p>
<p>我们采用MapReduce来对数据进行预处理，预处理之后的结果，我们也是保存到HDFS中，即采用如下的架构：<br><img src= "/img/loading.gif" data-src="/images/hadoop5.png"></p>
<h1 id="数据清洗过程："><a href="#数据清洗过程：" class="headerlink" title="数据清洗过程："></a>数据清洗过程：</h1><p>MapReduce程序编写<br>数据清洗的过程主要是编写MapReduce程序，而MapReduce程序的编写又分为写Mapper、Reducer、Job三个基本的过程。但是在我们这个案例中，要达到数据清洗的目的，实际上只需要Mapper就可以了，并不需要Reducer，原因很简单，我们只是预处理数据，在Mapper中就已经可以对数据进行处理了，其输出的数据并不需要进一步经过Redcuer来进行汇总处理。  </p>
<p>所以下面就直接编写Mapper和Job的程序代码:<br>AccessLogCleanMapper</p>
<pre><code>package cn.xpleaf.dataClean.mr.mapper;

import cn.xpleaf.dataClean.mr.writable.AccessLogWritable;
import cn.xpleaf.dataClean.utils.JedisUtil;
import cn.xpleaf.dataClean.utils.UserAgent;
import cn.xpleaf.dataClean.utils.UserAgentUtil;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.log4j.Logger;
import redis.clients.jedis.Jedis;

import java.io.IOException;
import java.text.DateFormat;
import java.text.SimpleDateFormat;
import java.util.Date;

/**
 * access日志清洗的主要mapper实现类
 * 原始数据结构：
 * appid ip mid userid login_tpe request status http_referer user_agent time ---&gt; 10列内容
 * 清洗之后的结果：
 * appid ip province city mid userid login_type request method request_url http_version status http_referer user_agent browser yyyy-MM-dd HH:mm:ss
 */
public class AccessLogCleanMapper extends Mapper&lt;LongWritable, Text, NullWritable, Text&gt; {

    private Logger logger;
    private String[] fields;

    private String appid;      //数据来源 web:1000,android:1001,ios:1002,ipad:1003
    private String ip;
    //通过ip来衍生出来的字段 province和city
    private String province;
    private String city;

    private String mid;      //mid:唯一的id此id第一次会种在浏览器的cookie里。如果存在则不再种。作为浏览器唯一标示。移动端或者pad直接取机器码。
    private String userId;     //用户id
    private String loginType; //登录状态，0未登录、1：登录用户
    private String request; //类似于此种 &quot;GET userList HTTP/1.1&quot;
    //通过request 衍生出来的字段 method request_url http_version
    private String method;
    private String requestUrl;
    private String httpVersion;

    private String status;          //请求的状态主要有：200 ok、/404 not found、408 Request Timeout、500 Internal Server Error、504 Gateway Timeout等
    private String httpReferer; //请求该url的上一个url地址。
    private String userAgent;   //浏览器的信息，例如：&quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36&quot;
    //通过userAgent来获取对应的浏览器
    private String browser;

    //private long time; //action对应的时间戳
    private String time;//action对应的格式化时间yyyy-MM-dd HH:mm:ss

    private DateFormat df;
    private Jedis jedis;

    @Override
    protected void setup(Context context) throws IOException, InterruptedException {
        logger = Logger.getLogger(AccessLogCleanMapper.class);
        df = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);
        jedis = JedisUtil.getJedis();
    }

    /**
     * appid ip mid userid login_tpe request status http_referer user_agent time ---&gt; 10列内容
     * ||
     * ||
     * appid ip province city mid userid login_type request method request_url http_version status http_referer user_agent browser yyyy-MM-dd HH:mm:ss
     */
    @Override
    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
        fields = value.toString().split(&quot;\t&quot;);
        if (fields == null || fields.length != 10) { // 有异常数据
            return;
        }
        // 因为所有的字段没有进行特殊操作，只是文本的输出，所以没有必要设置特定类型，全部设置为字符串即可，
        // 这样在做下面的操作时就可以省去类型的转换，但是如果对数据的合法性有严格的验证的话，则要保持类型的一致
        appid = fields[0];
        ip = fields[1];
        // 解析IP
        if (ip != null) {
            String ipInfo = jedis.hget(&quot;ip_info&quot;, ip);
            province = ipInfo.split(&quot;\t&quot;)[0];
            city = ipInfo.split(&quot;\t&quot;)[1];
        }

        mid = fields[2];
        userId = fields[3];
        loginType = fields[4];
        request = fields[5];
        method = request.split(&quot; &quot;)[0];
        requestUrl = request.split(&quot; &quot;)[1];
        httpVersion = request.split(&quot; &quot;)[2];

        status = fields[6];
        httpReferer = fields[7];
        userAgent = fields[8];
        if (userAgent != null) {
            UserAgent uAgent = UserAgentUtil.getUserAgent(userAgent);
            if (uAgent != null) {
                browser = uAgent.getBrowserType();
            }
        }
        try { // 转换有可能出现异常
            time = df.format(new Date(Long.parseLong(fields[9])));
        } catch (NumberFormatException e) {
            logger.error(e.getMessage());
        }
        AccessLogWritable access = new AccessLogWritable(appid, ip, province, city, mid,
                userId, loginType, request, method, requestUrl,
                httpVersion, status, httpReferer, this.userAgent, browser, time);
        context.write(NullWritable.get(), new Text(access.toString()));
    }

    @Override
    protected void cleanup(Context context) throws IOException, InterruptedException {
        // 资源释放
        logger = null;
        df = null;
        JedisUtil.returnJedis(jedis);
    }
}</code></pre><p>AccessLogCleanJob  </p>
<pre><code>package cn.xpleaf.dataClean.mr.job;

import cn.xpleaf.dataClean.mr.mapper.AccessLogCleanMapper;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;

/**
 * 清洗用户access日志信息
 * 主要的驱动程序
 *      主要用作组织mapper和reducer的运行
 *
 * 输入参数：
 * hdfs://ns1/input/data-clean/access/2018/04/08 hdfs://ns1/output/data-clean/access
 * 即inputPath和outputPath
 * 目前outputPath统一到hdfs://ns1/output/data-clean/access
 * 而inputPath则不确定，因为我们的日志采集是按天来生成一个目录的
 * 所以上面的inputPath只是清洗2018-04-08这一天的
 */
public class AccessLogCleanJob {
    public static void main(String[] args) throws Exception {

        if(args == null || args.length &lt; 2) {
            System.err.println(&quot;Parameter Errors! Usage &lt;inputPath...&gt; &lt;outputPath&gt;&quot;);
            System.exit(-1);
        }

        Path outputPath = new Path(args[args.length - 1]);

        Configuration conf = new Configuration();
        String jobName = AccessLogCleanJob.class.getSimpleName();
        Job job = Job.getInstance(conf, jobName);
        job.setJarByClass(AccessLogCleanJob.class);

        // 设置mr的输入参数
        for( int i = 0; i &lt; args.length - 1; i++) {
            FileInputFormat.addInputPath(job, new Path(args[i]));
        }
        job.setInputFormatClass(TextInputFormat.class);
        job.setMapperClass(AccessLogCleanMapper.class);
        job.setMapOutputKeyClass(NullWritable.class);
        job.setMapOutputValueClass(Text.class);
        // 设置mr的输出参数
        outputPath.getFileSystem(conf).delete(outputPath, true);    // 避免job在运行的时候出现输出目录已经存在的异常
        FileOutputFormat.setOutputPath(job, outputPath);
        job.setOutputFormatClass(TextOutputFormat.class);

        job.setOutputKeyClass(NullWritable.class);
        job.setOutputValueClass(Text.class);
        job.setNumReduceTasks(0);   // map only操作，没有reducer

        job.waitForCompletion(true);
    }
}</code></pre><h1 id="执行MapReduce程序"><a href="#执行MapReduce程序" class="headerlink" title="执行MapReduce程序"></a>执行MapReduce程序</h1><p>将上面的mr程序打包后上传到我们的Hadoop环境中，这里，对2018-04-08这一天产生的日志数据进行清洗，执行如下命令：  </p>
<pre><code>yarn jar data-extract-clean-analysis-1.0-SNAPSHOT-jar-with-dependencies.jar\
cn.xpleaf.dataClean.mr.job.AccessLogCleanJob \
hdfs://ns1/input/data-clean/access/2018/04/08 \
hdfs://ns1/output/data-clean/access</code></pre><p>观察结果，可以看到MapReduce Job执行成功！</p>
<pre><code>......
18/04/08 20:54:21 INFO mapreduce.Job: Running job: job_1523133033819_0009
18/04/08 20:54:28 INFO mapreduce.Job: Job job_1523133033819_0009 running in uber mode : false
18/04/08 20:54:28 INFO mapreduce.Job:  map 0% reduce 0%
18/04/08 20:54:35 INFO mapreduce.Job:  map 50% reduce 0%
18/04/08 20:54:40 INFO mapreduce.Job:  map 76% reduce 0%
18/04/08 20:54:43 INFO mapreduce.Job:  map 92% reduce 0%
18/04/08 20:54:45 INFO mapreduce.Job:  map 100% reduce 0%
18/04/08 20:54:46 INFO mapreduce.Job: Job job_1523133033819_0009 completed successfully
18/04/08 20:54:46 INFO mapreduce.Job: Counters: 31
......</code></pre><h1 id="数据清洗结果"><a href="#数据清洗结果" class="headerlink" title="数据清洗结果"></a>数据清洗结果</h1><p>上面的MapReduce程序执行成功后，可以看到在HDFS中生成的数据输出目录：<br><img src= "/img/loading.gif" data-src="/images/hadoop3.png"><br>我们可以下载其中一个结果数据文件，并用Notepadd++打开查看其数据信息：<br><img src= "/img/loading.gif" data-src="/images/hadoop4.png"></p>
<h1 id="数据处理："><a href="#数据处理：" class="headerlink" title="数据处理："></a>数据处理：</h1><p>对规整数据进行统计分析<br>经过数据清洗之后，就得到了我们做数据的分析统计所需要的比较规整的数据，下面就可以进行数据的统计分析了，即按照业务需求，统计出某一天中每个省份的PV和UV。  </p>
<p>我们依然是需要编写MapReduce程序，并且将数据保存到HDFS中，其架构跟前面的数据清洗是一样的：<br><img src= "/img/loading.gif" data-src="/images/hadoop5.png"></p>
<h1 id="数据处理思路："><a href="#数据处理思路：" class="headerlink" title="数据处理思路："></a>数据处理思路：</h1><p>如何编写MapReduce程序<br>现在我们已经得到了规整的数据，关于在于如何编写我们的MapReduce程序。  </p>
<p>因为要统计的是每个省对应的pv和uv，pv就是点击量，uv是独立访客量，需要将省相同的数据拉取到一起，拉取到一块的这些数据每一条记录就代表了一次点击（pv + 1），这里面有同一个用户产生的数据（通过mid来唯一地标识是同一个浏览器，用mid进行去重，得到的就是uv）。  </p>
<p>而拉取数据，可以使用Mapper来完成，对数据的统计（pv、uv的计算）则可以通过Reducer来完成，即Mapper的各个参数可以为如下： </p>
<pre><code>Mapper&lt;LongWritable, Text, Text(Province), Text(mid)&gt;</code></pre><p>而Reducer的各个参数可以为如下：</p>
<pre><code>Reducer&lt;Text(Province), Text(mid), Text(Province), Text(pv + uv)&gt;</code></pre><p>数据处理过程：MapReduce程序编写<br>根据前面的分析，来编写我们的MapReduce程序。<br>ProvincePVAndUVMapper</p>
<pre><code>package cn.xpleaf.dataClean.mr.mapper;

import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

import java.io.IOException;

/**
 * Mapper&lt;LongWritable, Text, Text(Province), Text(mid)&gt;
 * Reducer&lt;Text(Province), Text(mid), Text(Province), Text(pv + uv)&gt;
 */
public class ProvincePVAndUVMapper extends Mapper&lt;LongWritable, Text, Text, Text&gt; {
    @Override
    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
        String line = value.toString();
        String[] fields = line.split(&quot;\t&quot;);
        if(fields == null || fields.length != 16) {
            return;
        }
        String province = fields[2];
        String mid = fields[4];
        context.write(new Text(province), new Text(mid));
    }
}</code></pre><p>ProvincePVAndUVReducer</p>
<pre><code>package cn.xpleaf.dataClean.mr.reducer;

import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

import java.io.IOException;
import java.util.HashSet;
import java.util.Set;

/**
 * 统计该标准化数据，产生结果
 * 省    pv      uv
 * 这里面有同一个用户产生的数|据（通过mid来唯一地标识是同一个浏览器，用mid进行去重，得到的就是uv）
 * Mapper&lt;LongWritable, Text, Text(Province), Text(mid)&gt;
 * Reducer&lt;Text(Province), Text(mid), Text(Province), Text(pv + uv)&gt;
 */
public class ProvincePVAndUVReducer extends Reducer&lt;Text, Text, Text, Text&gt; {

    private Set&lt;String&gt; uvSet = new HashSet&lt;&gt;();

    @Override
    protected void reduce(Text key, Iterable&lt;Text&gt; values, Context context) throws IOException, InterruptedException {
        long pv = 0;
        uvSet.clear();
        for(Text mid : values) {
            pv++;
            uvSet.add(mid.toString());
        }
        long uv = uvSet.size();
        String pvAndUv = pv + &quot;\t&quot; + uv;
        context.write(key, new Text(pvAndUv));
    }
}</code></pre><p>ProvincePVAndUVJob</p>
<pre><code>package cn.xpleaf.dataClean.mr.job;

import cn.xpleaf.dataClean.mr.mapper.ProvincePVAndUVMapper;
import cn.xpleaf.dataClean.mr.reducer.ProvincePVAndUVReducer;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;

/**
 * 统计每个省的pv和uv值
 * 输入：经过clean之后的access日志
 *      appid ip province city mid userid login_type request method request_url http_version status http_referer user_agent browser yyyy-MM-dd HH:mm:ss
 * 统计该标准化数据，产生结果
 * 省    pv      uv
 *
 * 分析：因为要统计的是每个省对应的pv和uv
 *      pv就是点击量，uv是独立访客量
 *      需要将省相同的数据拉取到一起，拉取到一块的这些数据每一条记录就代表了一次点击（pv + 1）
 *      这里面有同一个用户产生的数据（通过mid来唯一地标识是同一个浏览器，用mid进行去重，得到的就是uv）
 *      Mapper&lt;LongWritable, Text, Text(Province), Text(mid)&gt;
 *      Reducer&lt;Text(Province), Text(mid), Text(Province), Text(pv + uv)&gt;
 *
 *  输入参数：
 *  hdfs://ns1/output/data-clean/access hdfs://ns1/output/pv-uv
 */
public class ProvincePVAndUVJob {
    public static void main(String[] args) throws Exception {

        if (args == null || args.length &lt; 2) {
            System.err.println(&quot;Parameter Errors! Usage &lt;inputPath...&gt; &lt;outputPath&gt;&quot;);
            System.exit(-1);
        }

        Path outputPath = new Path(args[args.length - 1]);

        Configuration conf = new Configuration();
        String jobName = ProvincePVAndUVJob.class.getSimpleName();
        Job job = Job.getInstance(conf, jobName);
        job.setJarByClass(ProvincePVAndUVJob.class);

        // 设置mr的输入参数
        for (int i = 0; i &lt; args.length - 1; i++) {
            FileInputFormat.addInputPath(job, new Path(args[i]));
        }
        job.setInputFormatClass(TextInputFormat.class);
        job.setMapperClass(ProvincePVAndUVMapper.class);
        job.setMapOutputKeyClass(Text.class);
        job.setMapOutputValueClass(Text.class);
        // 设置mr的输出参数
        outputPath.getFileSystem(conf).delete(outputPath, true);    // 避免job在运行的时候出现输出目录已经存在的异常
        FileOutputFormat.setOutputPath(job, outputPath);
        job.setOutputFormatClass(TextOutputFormat.class);
        job.setReducerClass(ProvincePVAndUVReducer.class);
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(Text.class);
        job.setNumReduceTasks(1);

        job.waitForCompletion(true);
    }
}</code></pre><h1 id="执行MapReduce程序-1"><a href="#执行MapReduce程序-1" class="headerlink" title="执行MapReduce程序"></a>执行MapReduce程序</h1><p>将上面的mr程序打包后上传到我们的Hadoop环境中，这里，对前面预处理之后的数据进行统计分析，执行如下命令：</p>
<pre><code>yarn jar data-extract-clean-analysis-1.0-SNAPSHOT-jar-with-dependencies.jar \
cn.xpleaf.dataClean.mr.job.ProvincePVAndUVJob \
hdfs://ns1/output/data-clean/access \
hdfs://ns1/output/pv-uv</code></pre><p>观察运行结果、可以看到MapReduce Job执行成功！</p>
<pre><code>......
18/04/08 22:22:42 INFO mapreduce.Job: Running job: job_1523133033819_0010
18/04/08 22:22:49 INFO mapreduce.Job: Job job_1523133033819_0010 running in uber mode : false
18/04/08 22:22:49 INFO mapreduce.Job:  map 0% reduce 0%
18/04/08 22:22:55 INFO mapreduce.Job:  map 50% reduce 0%
18/04/08 22:22:57 INFO mapreduce.Job:  map 100% reduce 0%
18/04/08 22:23:03 INFO mapreduce.Job:  map 100% reduce 100%
18/04/08 22:23:03 INFO mapreduce.Job: Job job_1523133033819_0010 completed successfully
18/04/08 22:23:03 INFO mapreduce.Job: Counters: 49
......</code></pre><h1 id="数据处理结果"><a href="#数据处理结果" class="headerlink" title="数据处理结果"></a>数据处理结果</h1><p>上面的MapReduce程序执行成功后，可以看到在HDFS中生成的数据输出目录：<br><img src= "/img/loading.gif" data-src="/images/hadoop6.png"><br>我们可以下载其结果数据文件，并用Notepadd++打开查看其数据信息：<br><img src= "/img/loading.gif" data-src="/images/hadoop7.png"><br>至此，就完成了一个完整的数据采集、清洗、处理的完整离线数据分析案例。</p>
<p>相关的代码留言邮箱我Email你，有兴趣可以参考一下</p>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Java大数据开发</tag>
      </tags>
  </entry>
  <entry>
    <title>定时任务-LINUX</title>
    <url>/2020/03/19/%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1-LINUX/</url>
    <content><![CDATA[<h4 id="定时任务分为两种模式"><a href="#定时任务分为两种模式" class="headerlink" title="定时任务分为两种模式"></a>定时任务分为两种模式</h4><p> 1.系统级别的定时任务：临时文件清理、系统信息采集、日志文件切割<br> 2.用户级别的定时任务：定时向互联网同步时间、定时备份系统配置文件、定时备份数据库的数据 </p>
<a id="more"></a>
<h4 id="定时任务-标准规范"><a href="#定时任务-标准规范" class="headerlink" title="定时任务 标准规范"></a>定时任务 标准规范</h4><pre><code class="shell">[root@oldboy ~]# vim /etc/crontab
SHELL=/bin/bash        执行命令的解释器
PATH=/sbin:/bin:/usr/sbin:/usr/bin       环境变量
MAILTO=root           邮件发给谁

# For details see man 4 crontabs

# Example of job definition:
# .---------------- minute (0 - 59)     分钟
# |  .------------- hour (0 - 23)     小时
# |  |  .---------- day of month (1 - 31)     日期
# |  |  |  .------- month (1 - 12) OR jan,feb,mar,apr ...        月份
# |  |  |  |  .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat  星期
# |  |  |  |  |
# *  *  *  *  * user-name  command to be executed

 *  表示任意的(分、时、日、月、周)时间都执行
 -  表示一个时间范围段, 如5-7点
 ,  表示分隔时段, 如6,0,4表示周六、日、四
 /1 表示每隔n单位时间, 如*/10 每10分钟</code></pre>
<h4 id="常用的一些定时任务段"><a href="#常用的一些定时任务段" class="headerlink" title="常用的一些定时任务段"></a>常用的一些定时任务段</h4><pre><code class="shell">00 02 * * * ls      #每天的凌晨2点整执行
00 02 1 * * ls      #每月的1日的凌晨2点整执行
00 02 14 2 * ls     #每年的2月14日凌晨2点执行
00 02 * * 7 ls      #每周天的凌晨2点整执行
00 02 * 6 5 ls      #每年的6月周五凌晨2点执行
00 02 14 * 7 ls     #每月14日或每周日的凌晨2点都执行
00 02 14 2 7 ls     #每年的2月14日或每年2月的周天的凌晨2点执行   
*/10  02 * * * ls   #每天凌晨2点，每隔10分钟执行一次
* * * * *  ls       #每分钟都执行
00 00 14 2 *  ls    #每年2月14日的凌晨执行命令 
*/5 * * * *  ls     #每隔5分钟执行一次
00 02 * 1,5,8 * ls  #每年的1月5月8月凌晨2点执行
00 02 1-8 * *  ls    #每月1号到8号凌晨2点执行
0 21 * * * ls       #每天晚上21:00执行
45 4 1,10,22 * * ls #每月1、10、22日的4:45执行
45 4 1-10 * * l     #每月1到10日的4:45执行
3,15 8-11 */2 * * ls #每隔两天的上午8点到11点的第3和第15分钟执行
0 23-7/1 * * * ls   #晚上11点到早上7点之间，每隔一小时执行
15 21 * * 1-5 ls    #周一到周五每天晚上21:15执行</code></pre>
]]></content>
      <categories>
        <category>基础进阶-Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>小程序开发快速入门（二）</title>
    <url>/2020/03/31/%E5%B0%8F%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
    <content><![CDATA[<h1 id="创建项目"><a href="#创建项目" class="headerlink" title="创建项目"></a>创建项目</h1><p>在微信开发者工具中创建一个小程序项目，根据自己需要选择云开发，云开发是微信提供的后台功能，<a id="more"></a>譬如云数据库、云存储、云函数等，创建小程序项目的时候需要输入 appid，appid 在小程序后台的设置中可以找到  </p>
<h1 id="小程序项目结构"><a href="#小程序项目结构" class="headerlink" title="小程序项目结构"></a>小程序项目结构</h1><pre><code>├── README.md
├── cloudfunctions
│   ├── login
│   └── openapi
├── miniprogram
│   ├── app.js
│   ├── app.json
│   ├── app.wxss
│   ├── images
│   ├── pages
│   ├── sitemap.json
│   └── style
└── project.config.json</code></pre><p>cloudfunctions：小程序的云开发代码（非必须），需要部署到云端；</p>
<p>miniprogram：小程序的页面文件以及交互逻辑代码；</p>
<p>project.config.json：项目的配置文件，是微信开发者工具使用的配置文件，可以使用的配置项见<a href="https://developers.weixin.qq.com/miniprogram/dev/devtools/projectconfig.html" target="_blank" rel="noopener" title="项目配置文件">项目配置</a>  </p>
<h1 id="部署云函数"><a href="#部署云函数" class="headerlink" title="部署云函数"></a>部署云函数</h1><p>第一次使用云开发功能的时候，创建项目时会提示你开通云开发功能，按提示开通即可。在 cloudfunctions 目录中实现了几个云函数，这些云函数是 node.js 项目。  </p>
<p align="center">
    <img src= "/img/loading.gif" data-src="/images/小程序.png" alt="Sample" width="1015" height="599">
</p>
在云函数目录上点击鼠标右键->选择上传并部署，然后预览中的小程序就可以调用云函数。如果调用没有部署的云函数，会提示云函数未部署。

<p>云开发功能不是必须的，后台服务完全可以在自己的服务器上部署。云开发是腾讯提供的函数功能，另外还有云存储、云数据库等，使用云开发能够简化后端服务开发，减少维护工作。  </p>
<h1 id="预览小程序"><a href="#预览小程序" class="headerlink" title="预览小程序"></a>预览小程序</h1><p>微信开发者界面左侧就是小程序的预览界面，另外在工具栏中选择预览或者真机调试会弹出二维码，用微信扫描二维码就可以在手机上预览小程序。</p>
<p>工具栏中还有很多其它开发工具，譬如版本管理、清缓存等。  </p>
<h1 id="小程序配置文件"><a href="#小程序配置文件" class="headerlink" title="小程序配置文件"></a>小程序配置文件</h1><p>app.json 是小程序的全局配置，包括了小程序的所有页面、界面表现、超时设置、底部 tab 等。 所有可用配置项以及配置项的含义可以在<a href="https://developers.weixin.qq.com/miniprogram/dev/reference/configuration/app.html" target="_blank" rel="noopener" 标题"">微信小程序全局配置</a>中找到。其中：</p>
<pre><code>pages 是小程序的所有页面的路径，每个页面都必须要在这里注册；
window 定义小程序所有页面顶部的背景颜色、文字颜色等；
tabBar 小程序的底部 tab 栏；
networkTimeout 网络超时；
debug 是否开启 debug 模式；
functionPages 是否启用插件模式；
subpackage 分包结构配置；
workers worker 代码；
requireBackgroundModes 后台使用的功能；
plugins 启用的插件；
preloadRule 分包预下载规则；
resizable iPad 的屏幕旋转支持；
navigateToMiniProgramAppIdList 需要跳转的小程序列表；
usingComponents 全局自定义组建；
permission 小程序接口权限；
sitemapLocation sitemap.json 的位置。</code></pre><p>itemap.json 是小程序收录配置，在 sitemap.json 中设置小程序页面是否可以被微信索引，没有该文件默认所有页面都允许被索引，下面是一个允许所有页面被索引的 sitemap.json 文件：  </p>
<pre><code>{
  &quot;rules&quot;: [{
  &quot;action&quot;: &quot;allow&quot;,
  &quot;page&quot;: &quot;*&quot;
  }]
}</code></pre><h1 id="小程序页面文件"><a href="#小程序页面文件" class="headerlink" title="小程序页面文件"></a>小程序页面文件</h1><p>每个小程序页面主要包括 wxml、wxss、js、json 四个文件，另外可以包含一些图片的页面素材文件：</p>
<pre><code>wxml 页面文件是小程序页面结构的基础；
wxss 文件是独立的样式表；
js 文件是页面交互逻辑的实现；
json 文件是页面的配置文件。</code></pre><p align="center">
    <img src= "/img/loading.gif" data-src="/images/xiao1.png" alt="Sample" width="294" height="141">
</p>

<h1 id="页面文件的内容格式和语法-正在编辑……"><a href="#页面文件的内容格式和语法-正在编辑……" class="headerlink" title="页面文件的内容格式和语法 正在编辑……."></a>页面文件的内容格式和语法 正在编辑…….</h1>]]></content>
      <categories>
        <category>微信小程序教程</category>
      </categories>
      <tags>
        <tag>小程序</tag>
      </tags>
  </entry>
  <entry>
    <title>文件操作-PYTHON</title>
    <url>/2020/03/19/%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C-PYTHON/</url>
    <content><![CDATA[<h2 id="读取文件"><a href="#读取文件" class="headerlink" title="读取文件"></a>读取文件</h2><p>读取文件使用python内置方法open()打开文件，使用.read()读取全部内容，示例如下：</p>
<a id="more"></a>
<pre><code>path = &quot;c:\py.txt&quot;
fi = open(path, &quot;r&quot;)
print(fi.read())
fi.close()</code></pre><p><strong>with语法</strong></p>
<p>with是python2.5引入的自动释放资源的语法模式，确保使用过程中不管是否发生了异常，都会释放资源.<br>使用with读取文件，是不需要自己手动close的，示例如下：</p>
<pre><code>with open(path) as fi:
    print(fi.read())</code></pre><p><strong>逐行读取文件</strong><br>.read()是读取文件的全部内容，使用.readlines()，示例如下：</p>
<pre><code>with open(path, &quot;r&quot;) as fi:
    lines = fi.readlines()
print(len(lines))</code></pre><p><strong>open方法的模式</strong></p>
<p>上面的示例可以看出来，open(目录,操作模式)的时候必须指定操作模式，open的操作模式：</p>
<blockquote>
<p>读取模式：’r’(默认模式) | 写入模式：’w’ | 附加模式：’a’.</p>
</blockquote>
<p>python模式是读取，所以”r”可以省略，示例如下：</p>
<pre><code>path = &quot;c:\py.txt&quot;
fi = open(path)
print(fi.read())
fi.close()</code></pre><h2 id="文件写入"><a href="#文件写入" class="headerlink" title="文件写入"></a>文件写入</h2><p>文件写入分为两种方式，一种是覆盖(w)，另一种是追加(a)。</p>
<p>文件覆盖的写入，代码如下：</p>
<pre><code>with open(path, &quot;w&quot;) as fi:
    fi.write(&quot;第一行\n第二行\n第三行&quot;)</code></pre><p>文件的追加，代码如下：</p>
<pre><code>with open(path, &quot;a&quot;) as fi:
    fi.write(&quot;\n第1行\n第2行\n第3行&quot;)</code></pre><blockquote>
<p>注意：文件写入，如果文件不存在会重建，不会报错。</p>
</blockquote>
<h2 id="更多文件操作"><a href="#更多文件操作" class="headerlink" title="更多文件操作"></a>更多文件操作</h2><p>os.getcwd()：获取当前运行目录</p>
<p>os.listdir(path)：获取指定目录下的列表</p>
<p>os.path.exists(path)：检查是否存在文件或文件夹</p>
<p>os.mkdir(path)：创建文件夹，已经存在文件会报错</p>
<p>os.remove(path)：删除文件夹，只能删除文件夹</p>
<p>os.rename(old, new)：文件重命名</p>
<p>示例如下：</p>
<pre><code>import os

# 获取当前程序运行目录
print(os.getcwd())

# 获取指定目录下的列表
print(os.listdir(&quot;E:\\server&quot;))

# 检查是否存在文件或文件夹
print(os.path.exists(&quot;E:\\test\\a.txt&quot;))

# 创建文件夹，已经存在文件会报错
os.mkdir(&quot;E:\\test1&quot;)

# 删除文件夹，只能删除文件夹
os.remove(&quot;E:\\test1&quot;)

# 文件重命名
os.rename(&quot;E:\\test\\a.txt&quot;, &quot;E:\\test\\b.txt&quot;)
</code></pre>]]></content>
      <categories>
        <category>基础常识</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>必须要懂的八大神经网络架构---机器学习</title>
    <url>/2020/05/30/%E5%BF%85%E9%A1%BB%E8%A6%81%E6%87%82%E7%9A%84%E5%85%AB%E5%A4%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<p>机器学习你知道多少？</p>
<a id="more"></a>
<h1 id="为什么需要机器学习？"><a href="#为什么需要机器学习？" class="headerlink" title="为什么需要机器学习？"></a>为什么需要机器学习？</h1><pre><code>有些任务直接编码较为复杂，我们不能处理所有的细微之处和简单编码，因此，机器学习很有必要。相反，我们向机器学习算法提供大量数据，让算法不断探索数据并构建模型来解决问题。比如：在新的杂乱照明场景内，从新的角度识别三维物体；编写一个计算信用卡交易诈骗概率的程序。
机器学习方法如下：它没有为每个特定的任务编写相应的程序，而是收集大量事例，为给定输入指定正确输出。算法利用这些事例产生程序。该程序与手写程序不同，可能包含数百万的数据量，也适用于新事例以及训练过的数据。若数据改变，程序在新数据上训练且被更新。大量的计算比支付手写程序要便宜的多。
</code></pre><pre><code>机器学习的应用如下：

模式识别：识别实际场景的面部或表情、语言识别。
识别异常：信用卡交易顺序异常，核电厂传感器读数模式异常。
预测：未来股价或货币汇率，个人观影喜好。
</code></pre><h1 id="什么是神经网络？神经网络"><a href="#什么是神经网络？神经网络" class="headerlink" title="什么是神经网络？神经网络"></a>什么是神经网络？神经网络</h1><pre><code>神经网络是一种通用机器学习模型，是一套特定的算法集，在机器学习领域掀起了一场变革，本身就是普通函数的逼近，可以应用到任何机器学习输入到输出的复杂映射问题。一般来说，神经网络架构可分为3类：
前馈神经网络：是最常见的类型，第一层为输入，最后一层为输出。如果有多个隐藏层，则称为“深度”神经网络。它能够计算出一系列事件间相似转变的变化，每层神经元的活动是下一层的非线性函数。
循环神经网络：各节点之间构成循环图，可以按照箭头的方向回到初始点。循环神经网络具有复杂的动态，难以训练，它模拟连续数据，相当于每个时间片段具有一个隐藏层的深度网络，除了在每个时间片段上使用相同的权重，也有输入。网络可以记住隐藏状态的信息，但是很难用这点来训练网络。
对称连接网络：和循环神经网络一样，但单元间的连接是对称的（即在两个方向的连接权重相同），它比循环神经网络更容易分析，但是功能受限。没有隐藏单元的对称连接的网络被称为“Hopfiels网络”，有隐藏单元的对称连接的网络则被称为“波兹曼机器”。
</code></pre><h1 id="感知机（Perceptron）"><a href="#感知机（Perceptron）" class="headerlink" title="感知机（Perceptron）"></a>感知机（Perceptron）</h1><pre><code>作为第一代神经网络，感知机是只有一个神经元的计算模型。首先将原始输入矢量转化为特征矢量，再用手写程序定义特征，然后学习如何对每个特征加权得到一个标量，如果标量值高于某一阈值，则认为输入矢量是目标类的一个积极样例。标准的感知机结构是前馈模型，即输入传送到节点，处理后产生输出结果：从底部输入，顶部输出，如下图所示。但也有其局限性：一旦确定了手写编码特征，在学习上就受到了较大限制。这对感知器来说是毁灭性的，尽管转换类似于翻译，但是模式识别的重点是识别模式。如果这些转换形成了一个组，学习的感知器部分不能学会识别，所以需要使用多个特征单元识别子模式的转换。
没有隐藏单元的网络在输入输出映射建模上也有很大局限性。增加线性单元层也解决不了，因为线性叠加依然是线性的，固定的非线性输出也不能建立这种映射。因此需要建立多层自适应的非线性隐藏单元。</code></pre><h1 id="卷积神经网络（Convolutional-Neural-Network）"><a href="#卷积神经网络（Convolutional-Neural-Network）" class="headerlink" title="卷积神经网络（Convolutional Neural Network）"></a>卷积神经网络（Convolutional Neural Network）</h1><pre><code>一直以来，机器学习研究广泛集中在对象检测上，但仍有诸多因素使其难以识别

识别对象：

对象分割、遮挡问题；
照明影响像素强度；
物体以各种不同的形式展现；
相同功能的对象具有不同的物理形状；
视觉不同带来的变化；
维度跳跃问题。

复制特征方法是当前CNN用于目标检测的主要方法，大规模的复制不同位置上相同的特征检测图，大大减少了要学习的自由参数数量。它使用不同的特征类型，每种类型都有自己的复制检测图，也允许以各种方式表示每个图像块
CNN可用于手写数字识别到3D对象识别等，但从彩色图像中识别对象比手写数字识别要复杂，它的类别、像素是数字的100倍（1000 vs 100，256*256彩色vs28*28灰度）。
2012年的ILSVRC-2012竞赛中的ImageNet提供一个包含120万张高分辨率训练图像的数据集。测试图像没有标注，参赛者需要识别图像中对象的类型。获胜者 Alex Krizhevsky开发了一个深度卷积神经网络，除了一些最大池化层，架构还有7个隐藏层，前面都是卷积层，最后2层是全局连接。激活函数在每个隐藏层都是线性单元，比逻辑单元速度更快，还使用竞争性规范标准抑制隐藏活动，有助于强度变化。硬件上，在两个Nvidia GTX 580 GPU（超过1000个快速内核）上使用一个高效卷积网络实现，非常适合矩阵乘法，具有很高的内存带宽。
</code></pre><h1 id="循环神经网络（-Recurrent-Neural-Network）"><a href="#循环神经网络（-Recurrent-Neural-Network）" class="headerlink" title="循环神经网络（ Recurrent Neural Network）"></a>循环神经网络（ Recurrent Neural Network）</h1><pre><code>循环神经网络（RNN）有两个强大的属性可以计算任何计算机计算出来的东西：（1）允许存储大量有效信息的分布式隐藏状态（2）用复杂的方式允许更新隐藏状态的非线性动态。RNN强大的计算能力和梯度消失（或爆炸）使其很难训练。通过多层反向传播时，若权重很小，则梯度呈指数缩小；若权重很大，则梯度呈指数增长。典型的前馈神经网络的一些隐藏层可以应对指数效应，另一方面，在长序列RNN中，梯度容易消失（或爆照），即使有好的初始权重，也很难检测出当前依赖于多个时间输入的目标输出因此很难处理远程依赖性。</code></pre><pre><code>学习RNN的方法如下：

长短期记忆：用具有长期记忆值的小模块制作RNN。
Hessian Free Optimization：使用优化器处理梯度消失问题。
回声状态网络：初始化输入→隐藏和隐藏→隐藏和输出→隐藏链接，使隐藏状态有一个巨大的弱耦合振荡器储备，可以选择性的由输入驱动。
用动量初始化：和回声状态网络一样，再用动量学习所有连接。
</code></pre><h1 id="长短期记忆网络（Long-Short-Term-Memory-Network）"><a href="#长短期记忆网络（Long-Short-Term-Memory-Network）" class="headerlink" title="长短期记忆网络（Long/Short Term Memory Network）"></a>长短期记忆网络（Long/Short Term Memory Network）</h1><pre><code>Hochreiter &amp; Schmidhuber（1997年）构建了长短期记忆网络，解决了获取RNN长时间记忆问题，使用乘法逻辑线性单元设计存储单元，只要保持“写入”门打开，信息就会写入并保持在单元中，也可以打开“读取”门从中获取数据。
RNN可以阅读行书，笔尖的输入坐标为（x,y,p），p代表笔是向上还是向下，输出则为一个字符序列，使用一系列小图像作为输入而不是笔坐标。Graves &amp; Schmidhuber（2009年）称带有LSTM的RNN是阅读行书的最佳系统。
</code></pre><h1 id="霍普菲尔德网络（Hopfield-Networks）"><a href="#霍普菲尔德网络（Hopfield-Networks）" class="headerlink" title="霍普菲尔德网络（Hopfield Networks）"></a>霍普菲尔德网络（Hopfield Networks）</h1><pre><code>非线性循环网络有很多种表现方式，较难分析：能达到稳定、震荡或馄饨状态这三种表现形式。Hopfield网络是由有循环连接的二进制阈值单元组成。1982年，约翰·霍普菲尔德发现，如果连接对称，则存在一个全局能量函数，整个网络的每个二进制“结构”都有能量，而二进制阈值决策规则使网络为能量函数设置一个最小值。使用这种计算类型最简单的方法是将记忆作为神经网络的能量最小值。使用能量最小值表示记忆给出了一个内容可寻内存，可通过了解局部内容来访问整个项目。
每记忆一次配置，都希望能产生一个能量最小值。但若有两个最小值就会限制Hopfield网络容量。伊丽莎白·加德纳发现有一个更好的存储规则，它使用了所有的权重。而不是试图一次存储多个矢量，她通过训练集进行多次循环，并用感知器收敛程序训练每个单元，使该矢量的所有其它单元具有正确的状态。

</code></pre><h1 id="玻尔兹曼机（Boltzmann-Machine-Network）"><a href="#玻尔兹曼机（Boltzmann-Machine-Network）" class="headerlink" title="玻尔兹曼机（Boltzmann Machine Network）"></a>玻尔兹曼机（Boltzmann Machine Network）</h1><pre><code>玻尔兹曼机是一种随机循环神经网络，可以被看作是Hopfield网络的随机生成产物，是最先学习内部representations的神经网络之一。该算法旨在最大限度地提高机器在训练集中分配给二进制矢量的概率的乘积，相当于最大化其分配给训练矢量的对数概率之和，方法如下
（1）网络没有外部输入时，使网络在不同时间分布稳定；
（2）每次对可见矢量采样。
2012年，Salakhutdinov和Hinton为玻尔兹曼机写了有效的小批量学习程序。2014年将模型更新，称之为受限玻尔兹曼机。
</code></pre><h1 id="深度信念网络（Deep-Belief-Network）"><a href="#深度信念网络（Deep-Belief-Network）" class="headerlink" title="深度信念网络（Deep Belief Network）"></a>深度信念网络（Deep Belief Network）</h1><pre><code>反向传播，是人工神经网络计算处理一批数据后每个神经元的误差分布的标准方法，但是也存在一些问题。首先要标注训练数据，但几乎所有数据都没有标注；其次，学习时间不足，这意味着隐藏层数较多的网络较慢；第三，可能会使局部陷入最不利局面。因此，对于深度网络来说这远远不够。 
无监督学习方法克服了反向传播的限制，使用梯度方法调整权重有助于保持架构的效率和简单性，还可以将它用于对感官输入结构建模。特别的是，它调整权重，将产生感官输入的生成模型概率最大化。信念网络是由随机变量组成的有向非循环图，可推断未观测变量的状态，还可以调整变量间的交互，使网络更可能产生训练数据。
早期图形模型是专家定义图像结构和条件概率，这些图形是稀疏连接的，他们专注于做正确的推论，而不是学习。但对于神经网络来说，学习是重点，其目的不在于可解释性或稀疏连接性使推断变得更容易。
</code></pre><h1 id="深度自动编码器（Deep-Auto-encoders）"><a href="#深度自动编码器（Deep-Auto-encoders）" class="headerlink" title="深度自动编码器（Deep Auto-encoders）"></a>深度自动编码器（Deep Auto-encoders）</h1><pre><code>该架构提供了两种映射方式，好像是一个做非线性降维非常好的方法，它在训练事例的数量上是线性的（或更好的），而最终编码模型相当紧凑和快速。然而，使用反向传播优化深度自动编码器很困难，若初始权重较小，反向传播梯度会消失。我们使用无监督逐层预训练或像回声状态网络一样认真的初始化权重。
对于预训练任务有三种不同类型的浅自动编码器：
（1）RBM作为自动编码器；
（2）去噪自动编码器；
（3）压缩自动编码器。
对于没有大量标注的数据集，预训练有助于后续的判别式学习。即便是深度神经网络，对于大量的标注数据集，无监督训练对权重初始化并不是必要的，预训练是初始化深度网络权重的第一个好方法，现在也有其它方法。但如果扩大网络，需要再次做预训练。</code></pre><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>传统的编程方法是我们告诉计算机做什么，将大问题分解成很多小而精确的且计算机可以轻松执行的任务。神经网络则不需要告诉计算机如何解决问题，而是从观测到的数据中学习，找到解决问题的办法。</p>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>时间模块-PYTHON</title>
    <url>/2020/03/19/%E6%97%B6%E9%97%B4%E6%A8%A1%E5%9D%97-PYTHON/</url>
    <content><![CDATA[<p>python中使用时间需要导入time模块，使用time.time()方法获取当前时间戳，示例如下：</p>
<a id="more"></a>
<pre><code># 导入time模块
import time

print(time.time())
# 输出：1523584077.842348
</code></pre><h2 id="格式化时间"><a href="#格式化时间" class="headerlink" title="格式化时间"></a>格式化时间</h2><p>格式化时间，使用time中的strftime()，示例如下：</p>
<pre><code># 导入time模块
import time

print(time.time())
# 输出：1523584077.842348

print(time.localtime(time.time()))
# 输出：time.struct_time(tm_year=2018, tm_mon=4, tm_mday=13, tm_hour=9, tm_min=50, tm_sec=12, tm_wday=4, tm_yday=103, tm_isdst=0)

# 时间格式化
print(time.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;, time.localtime(time.time())))
# 输出：2018-04-13 09:52:10</code></pre><p><strong>程序计时器</strong></p>
<p>使用场景：有时候我们需要计算程序的运行时长，使用以下代码：</p>
<pre><code>import datetime
import time

#开始计时
startTime = datetime.datetime.now()

time.sleep(1)

#结束计时
endTime = datetime.datetime.now()
print(endTime - startTime)
#输出：0:00:01.000791</code></pre><h2 id="格式化符号说明"><a href="#格式化符号说明" class="headerlink" title="格式化符号说明"></a>格式化符号说明</h2><p>%y 两位数的年份表示（00-99）</p>
<p>%Y 四位数的年份表示（000-9999）</p>
<p>%m 月份（01-12）</p>
<p>%d 月内中的一天（0-31）</p>
<p>%H 24小时制小时数（0-23）</p>
<p>%I 12小时制小时数（01-12）</p>
<p>%M 分钟数（00=59）</p>
<p>%S 秒（00-59）</p>
<p>%a 本地简化星期名称</p>
<p>%A 本地完整星期名称</p>
<p>%b 本地简化的月份名称</p>
<p>%B 本地完整的月份名称</p>
<p>%c 本地相应的日期表示和时间表示</p>
<p>%j 年内的一天（001-366）</p>
<p>%p 本地A.M.或P.M.的等价符</p>
<p>%U 一年中的星期数（00-53）星期天为星期的开始</p>
<p>%w 星期（0-6），星期天为星期的开始</p>
<p>%W 一年中的星期数（00-53）星期一为星期的开始</p>
<p>%x 本地相应的日期表示</p>
<p>%X 本地相应的时间表示</p>
<p>%Z 当前时区的名称</p>
<p>%% %号本身</p>
]]></content>
      <categories>
        <category>基础常识</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>条件循环和判断-PYTHON</title>
    <url>/2020/03/19/%E6%9D%A1%E4%BB%B6%E5%BE%AA%E7%8E%AF%E5%92%8C%E5%88%A4%E6%96%AD-PYTHON/</url>
    <content><![CDATA[<p>条件判断的重要值是True和False，注意首字母大写，示例如下：</p>
<a id="more"></a>
<pre><code>if True:
    print(&quot;真&quot;)
else:
    print(&quot;假&quot;)
# 输出：真</code></pre><h1 id="非真判断"><a href="#非真判断" class="headerlink" title="非真判断"></a>非真判断</h1><p>非真判断使用not关键字，示例如下：</p>
<pre><code>if not True:
    print(&quot;True&quot;)
else:
    print(&quot;False&quot;)
# 输出：False</code></pre><h1 id="多情况判断"><a href="#多情况判断" class="headerlink" title="多情况判断"></a>多情况判断</h1><p>多情况判断使用if/elif/else，示例如下：</p>
<pre><code>age = 18
if age &lt; 16:
    print(&quot;青少年&quot;)
elif age &lt; 18:
    print(&quot;青年&quot;)
elif age &lt; 60:
    print(&quot;成人&quot;)
else:
    print(&quot;老年&quot;)
# 输出：成人</code></pre><p>python用空格缩进代表代码块，所以要主要代码缩进.</p>
<h1 id="满足多条件"><a href="#满足多条件" class="headerlink" title="满足多条件"></a>满足多条件</h1><p>使用and关键字，示例如下：</p>
<pre><code>age = 18
name = &quot;laowang&quot;
if age == 18 and name == &quot;laowang&quot;:
    print(&quot;良好少年&quot;)
else:
    print(&quot;不良少年&quot;)
# 输出：良好少年</code></pre><h1 id="至少满足一种条件"><a href="#至少满足一种条件" class="headerlink" title="至少满足一种条件"></a>至少满足一种条件</h1><p>使用or关键字，示例如下：</p>
<pre><code>age = 18
name = &quot;laowang&quot;
if age == 18 or name == &quot;xiaoli&quot;:
    print(&quot;良好少年&quot;)
else:
    print(&quot;不良少年&quot;)
# 输出：良好少年</code></pre><p><strong>False值</strong><br>python中0、空字符串、空列表、空元祖值、空字典都为false.</p>
<h2 id="循环"><a href="#循环" class="headerlink" title="循环"></a>循环</h2><p><strong>for循环</strong><br>基础示例如下：</p>
<pre><code>list = [&quot;focus&quot;, &quot;mouse&quot;, &quot;click&quot;]
for item in list:
    print(item)
# 输出：focus
# 输出：mouse
# 输出：click</code></pre><h1 id="break跳出循环"><a href="#break跳出循环" class="headerlink" title="break跳出循环"></a>break跳出循环</h1><pre><code>list = [&quot;focus&quot;, &quot;mouse&quot;, &quot;click&quot;]
for item in list:
    if item == &quot;mouse&quot;:
        break
    print(item)
# 输出：focus</code></pre><h1 id="continue跳过该次循环"><a href="#continue跳过该次循环" class="headerlink" title="continue跳过该次循环"></a>continue跳过该次循环</h1><pre><code>list = [&quot;focus&quot;, &quot;mouse&quot;, &quot;click&quot;]
for item in list:
    if item == &quot;mouse&quot;:
        continue
    print(item)
# 输出：focus
# 输出：click</code></pre><h1 id="使用enumerate获取下标"><a href="#使用enumerate获取下标" class="headerlink" title="使用enumerate获取下标"></a>使用enumerate获取下标</h1><pre><code>list = [&quot;focus&quot;, &quot;mouse&quot;, &quot;click&quot;]
for index, item in enumerate(list):
    print(&quot;index:{} item:{}&quot;.format(index, item))
# 输出如下：
# index:0 item:focus
# index:1 item:mouse
# index:2 item:click</code></pre><h1 id="while循环"><a href="#while循环" class="headerlink" title="while循环"></a>while循环</h1><p>基础示例如下：</p>
<pre><code>num = 1
while num &lt; 3:
    print(num)
    num = num+1
# 输出：1
# 输出：2</code></pre><p>在while中break和continue同样有效，和上文for循环作用相同，请参考上文。</p>
]]></content>
      <categories>
        <category>基础常识</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>标准库-PYTHON</title>
    <url>/2020/03/20/%E6%A0%87%E5%87%86%E5%BA%93-PYTHON/</url>
    <content><![CDATA[<p>Python 标准库示例说明<br>Python拥有一个强大的标准库。Python语言的核心只包含数字、字符串、列表、字典、文件等常见类型和函数，而由Python标准库提供了系统管理、网络通信、文本处理、数据库接口、图形系统、XML处理等额外的功能。</p>
<a id="more"></a>

<h1 id="操作系统接口"><a href="#操作系统接口" class="headerlink" title="操作系统接口"></a>操作系统接口</h1><p>os模块提供了不少与操作系统相关联的函数。</p>
<pre><code>&gt;&gt;&gt; import os
&gt;&gt;&gt; os.getcwd()      # 返回当前的工作目录
&#39;C:\\Python34&#39;
&gt;&gt;&gt; os.chdir(&#39;/server/accesslogs&#39;)   # 修改当前的工作目录
&gt;&gt;&gt; os.system(&#39;mkdir today&#39;)   # 执行系统命令 mkdir 
0</code></pre><p>建议使用 “import os” 风格而非 “from os import *”。这样可以保证随操作系统不同而有所变化的 os.open() 不会覆盖内置函数 open()。</p>
<p>在使用 os 这样的大型模块时内置的 dir() 和 help() 函数非常有用:</p>
<pre><code>&gt;&gt;&gt; import os
&gt;&gt;&gt; dir(os)</code></pre><returns a list of all module functions>
>>> help(os)
<returns an extensive manual page created from the module's docstrings>
针对日常的文件和目录管理任务，:mod:shutil 模块提供了一个易于使用的高级接口:
```
>>> import shutil
>>> shutil.copyfile('data.db', 'archive.db')
>>> shutil.move('/build/executables', 'installdir')

<h1 id="文件通配符"><a href="#文件通配符" class="headerlink" title="文件通配符"></a>文件通配符</h1><p>glob模块提供了一个函数用于从目录通配符搜索中生成文件列表:</p>
<pre><code>&gt;&gt;&gt; import glob
&gt;&gt;&gt; glob.glob(&#39;*.py&#39;)
[&#39;primes.py&#39;, &#39;random.py&#39;, &#39;quote.py&#39;]
命令行参数
通用工具脚本经常调用命令行参数。这些命令行参数以链表形式存储于 sys 模块的 argv 变量。例如在命令行中执行 “python demo.py one two three” 后可以得到以下输出结果:

&gt;&gt;&gt; import sys
&gt;&gt;&gt; print(sys.argv)
[&#39;demo.py&#39;, &#39;one&#39;, &#39;two&#39;, &#39;three&#39;]
错误输出重定向和程序终止
sys 还有 stdin，stdout 和 stderr 属性，即使在 stdout 被重定向时，后者也可以用于显示警告和错误信息。

&gt;&gt;&gt; sys.stderr.write(&#39;Warning, log file not found starting a new one\n&#39;)
Warning, log file not found starting a new one
大多脚本的定向终止都使用 “sys.exit()”。</code></pre><h1 id="字符串正则匹配"><a href="#字符串正则匹配" class="headerlink" title="字符串正则匹配"></a>字符串正则匹配</h1><p>re模块为高级字符串处理提供了正则表达式工具。对于复杂的匹配和处理，正则表达式提供了简洁、优化的解决方案:</p>
<pre><code>&gt;&gt;&gt; import re
&gt;&gt;&gt; re.findall(r&#39;\bf[a-z]*&#39;, &#39;which foot or hand fell fastest&#39;)
[&#39;foot&#39;, &#39;fell&#39;, &#39;fastest&#39;]
&gt;&gt;&gt; re.sub(r&#39;(\b[a-z]+) \1&#39;, r&#39;\1&#39;, &#39;cat in the the hat&#39;)
&#39;cat in the hat&#39;
如果只需要简单的功能，应该首先考虑字符串方法，因为它们非常简单，易于阅读和调试:

&gt;&gt;&gt; &#39;tea for too&#39;.replace(&#39;too&#39;, &#39;two&#39;)
&#39;tea for two&#39;</code></pre><h1 id="数学"><a href="#数学" class="headerlink" title="数学"></a>数学</h1><p>math模块为浮点运算提供了对底层C函数库的访问:</p>
<pre><code>&gt;&gt;&gt; import math
&gt;&gt;&gt; math.cos(math.pi / 4)
0.70710678118654757
&gt;&gt;&gt; math.log(1024, 2)
10.0
random提供了生成随机数的工具。

&gt;&gt;&gt; import random
&gt;&gt;&gt; random.choice([&#39;apple&#39;, &#39;pear&#39;, &#39;banana&#39;])
&#39;apple&#39;
&gt;&gt;&gt; random.sample(range(100), 10)   # sampling without replacement
[30, 83, 16, 4, 8, 81, 41, 50, 18, 33]
&gt;&gt;&gt; random.random()    # random float
0.17970987693706186
&gt;&gt;&gt; random.randrange(6)    # random integer chosen from range(6)</code></pre><h1 id="访问-互联网"><a href="#访问-互联网" class="headerlink" title="访问 互联网"></a>访问 互联网</h1><p>有几个模块用于访问互联网以及处理网络通信协议。其中最简单的两个是用于处理从 urls 接收的数据的 urllib.request 以及用于发送电子邮件的 smtplib:</p>
<pre><code>&gt;&gt;&gt; from urllib.request import urlopen
&gt;&gt;&gt; for line in urlopen(&#39;http://tycho.usno.navy.mil/cgi-bin/timer.pl&#39;):
...     line = line.decode(&#39;utf-8&#39;)  # Decoding the binary data to text.
...     if &#39;EST&#39; in line or &#39;EDT&#39; in line:  # look for Eastern Time
...         print(line)
&lt;BR&gt;Nov. 25, 09:43:32 PM EST
&gt;&gt;&gt; import smtplib
&gt;&gt;&gt; server = smtplib.SMTP(&#39;localhost&#39;)
&gt;&gt;&gt; server.sendmail(&#39;soothsayer@example.org&#39;, &#39;jcaesar@example.org&#39;,
... &quot;&quot;&quot;To: jcaesar@example.org
... From: soothsayer@example.org
...
... Beware the Ides of March.
... &quot;&quot;&quot;)
&gt;&gt;&gt; server.quit()</code></pre><p>注意第二个例子需要本地有一个在运行的邮件服务器。</p>
<pre><code>#处理get请求，不传data，则为get请求
import urllib
from urllib.request import urlopen
from urllib.parse import urlencode
url=&#39;http://www.ai8py.com/login&#39;
data={&quot;username&quot;:&quot;admin&quot;,&quot;password&quot;:123456}
req_data=urlencode(data)#将字典类型的请求数据转变为url编码
res=urlopen(url+&#39;?&#39;+req_data)#通过urlopen方法访问拼接好的url
res=res.read().decode()#read()方法是读取返回数据内容，decode是转换返回数据的bytes格式为str
print(res)
#处理post请求,如果传了data，则为post请求
import urllib
from urllib.request import Request
from urllib.parse import urlencode
url=&#39;http://www.ai8py.com/login&#39;
data={&quot;username&quot;:&quot;admin&quot;,&quot;password&quot;:123456}
data=urlencode(data)#将字典类型的请求数据转变为url编码
data=data.encode(&#39;ascii&#39;)#将url编码类型的请求数据转变为bytes类型
req_data=Request(url,data)#将url和请求数据处理为一个Request对象，供urlopen调用
with urlopen(req_data) as res:
    res=res.read().decode()#read()方法是读取返回数据内容，decode是转换返回数据的bytes格式为str
print(res)</code></pre><h1 id="日期和时间"><a href="#日期和时间" class="headerlink" title="日期和时间"></a>日期和时间</h1><p>datetime模块为日期和时间处理同时提供了简单和复杂的方法。</p>
<p>支持日期和时间算法的同时，实现的重点放在更有效的处理和格式化输出。</p>
<p>该模块还支持时区处理:</p>
<pre><code>&gt;&gt;&gt; # dates are easily constructed and formatted
&gt;&gt;&gt; from datetime import date
&gt;&gt;&gt; now = date.today()
&gt;&gt;&gt; now
datetime.date(2003, 12, 2)
&gt;&gt;&gt; now.strftime(&quot;%m-%d-%y. %d %b %Y is a %A on the %d day of %B.&quot;)
&#39;12-02-03. 02 Dec 2003 is a Tuesday on the 02 day of December.&#39;
&gt;&gt;&gt; # dates support calendar arithmetic
&gt;&gt;&gt; birthday = date(1964, 7, 31)
&gt;&gt;&gt; age = now - birthday
&gt;&gt;&gt; age.days
14368</code></pre><p>常用时间处理方法</p>
<p>今天 today = datetime.date.today()<br>昨天 yesterday = today - datetime.timedelta(days=1)<br>上个月 last_month = today.month - 1 if today.month - 1 else 12<br>当前时间戳 time_stamp = time.time()<br>时间戳转datetime datetime.datetime.fromtimestamp(time_stamp)<br>datetime转时间戳 int(time.mktime(today.timetuple()))<br>datetime转字符串 today_str = today.strftime(“%Y-%m-%d”)<br>字符串转datetime today = datetime.datetime.strptime(today_str, “%Y-%m-%d”)<br>补时差 today + datetime.timedelta(hours=8)</p>
<h1 id="数据压缩"><a href="#数据压缩" class="headerlink" title="数据压缩"></a>数据压缩</h1><p>以下模块直接支持通用的数据打包和压缩格式：zlib，gzip，bz2，zipfile，以及 tarfile。</p>
<pre><code>&gt;&gt;&gt; import zlib
&gt;&gt;&gt; s = b&#39;witch which has which witches wrist watch&#39;
&gt;&gt;&gt; len(s)
41
&gt;&gt;&gt; t = zlib.compress(s)
&gt;&gt;&gt; len(t)
37
&gt;&gt;&gt; zlib.decompress(t)
b&#39;witch which has which witches wrist watch&#39;
&gt;&gt;&gt; zlib.crc32(s)
226805979</code></pre><h1 id="性能度量"><a href="#性能度量" class="headerlink" title="性能度量"></a>性能度量</h1><p>有些用户对了解解决同一问题的不同方法之间的性能差异很感兴趣。Python 提供了一个度量工具，为这些问题提供了直接答案。</p>
<p>例如，使用元组封装和拆封来交换元素看起来要比使用传统的方法要诱人的多,timeit 证明了现代的方法更快一些。</p>
<pre><code>&gt;&gt;&gt; from timeit import Timer
&gt;&gt;&gt; Timer(&#39;t=a; a=b; b=t&#39;, &#39;a=1; b=2&#39;).timeit()
0.57535828626024577
&gt;&gt;&gt; Timer(&#39;a,b = b,a&#39;, &#39;a=1; b=2&#39;).timeit()
0.54962537085770791
相对于 timeit 的细粒度，:mod:profile 和 pstats 模块提供了针对更大代码块的时间度量工具。</code></pre><h1 id="测试模块"><a href="#测试模块" class="headerlink" title="测试模块"></a>测试模块</h1><p>开发高质量软件的方法之一是为每一个函数开发测试代码，并且在开发过程中经常进行测试</p>
<p>doctest模块提供了一个工具，扫描模块并根据程序中内嵌的文档字符串执行测试。</p>
<p>测试构造如同简单的将它的输出结果剪切并粘贴到文档字符串中。</p>
<p>通过用户提供的例子，它强化了文档，允许 doctest 模块确认代码的结果是否与文档一致:</p>
<pre><code>def average(values):
    &quot;&quot;&quot;Computes the arithmetic mean of a list of numbers.
    &gt;&gt;&gt; print(average([20, 30, 70]))
    40.0
    &quot;&quot;&quot;
    return sum(values) / len(values)
import doctest
doctest.testmod()   # 自动验证嵌入测试
unittest模块不像 doctest模块那么容易使用，不过它可以在一个独立的文件里提供一个更全面的测试集:

import unittest
class TestStatisticalFunctions(unittest.TestCase):
    def test_average(self):
        self.assertEqual(average([20, 30, 70]), 40.0)
        self.assertEqual(round(average([1, 5, 7]), 1), 4.3)
        self.assertRaises(ZeroDivisionError, average, [])
        self.assertRaises(TypeError, average, 20, 30, 70)
unittest.main() # Calling from the command line invokes all tests</code></pre></returns></returns>]]></content>
      <categories>
        <category>基础常识</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>路线轨迹的3D动画展示</title>
    <url>/2020/04/05/%E8%B7%AF%E7%BA%BF%E8%BD%A8%E8%BF%B9%E7%9A%843D%E5%8A%A8%E7%94%BB%E5%B1%95%E7%A4%BA/</url>
    <content><![CDATA[<p>今天换换脑子，来一些可视化的小技巧。</p>
<a id="more"></a>
<p>百度地图很强大，也为开发者提供很好的开发接口。今天教大家一个3D地图上路线轨迹可视化的小功能。</p>
<h1 id="第一步"><a href="#第一步" class="headerlink" title="第一步"></a>第一步</h1><p>申请 ak, 很简单，10秒搞定。</p>
<p>ak 申请链接，根据提示3步搞定。<a href="http://lbsyun.baidu.com/index.php?title=jspopularGL/guide/getkey" target="_blank" rel="noopener" title="申请">申请</a>  </p>
<h1 id="第二步"><a href="#第二步" class="headerlink" title="第二步"></a>第二步</h1><p>有了 ak 后，复制下面的 hellomap.html 文件到 templates 文件夹里</p>
<pre><code>&lt;!DOCTYPE html&gt;
&lt;html&gt;

&lt;head&gt;
    &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=utf-8&quot; /&gt;
    &lt;meta name=&quot;viewport&quot; content=&quot;initial-scale=1.0, user-scalable=no&quot; /&gt;
    &lt;style type=&quot;text/css&quot;&gt;
    body, html,#allmap {width: 100%;height: 100%;overflow: hidden;margin:0;font-family:&quot;微软雅黑&quot;;}
    &lt;/style&gt;
    &lt;script type=&quot;text/javascript&quot; src=&quot;//api.map.baidu.com/api?type=webgl&amp;v=1.0&amp;ak=BDHrafkP23kFkI8MPbGUWS1bREzCCAdI&quot;&gt;&lt;/script&gt;
    &lt;script type=&quot;text/javascript&quot; src=&quot;//api.map.baidu.com/library/TrackAnimation/src/TrackAnimation_min.js&quot;&gt;&lt;/script&gt;

    &lt;title&gt;绘制轨迹&lt;/title&gt;
&lt;/head&gt;

&lt;body&gt;
    &lt;div id=&quot;allmap&quot;&gt;&lt;/div&gt;
&lt;/body&gt;
&lt;/html&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
    // GL版命名空间为BMapGL
    // 按住鼠标右键，修改倾斜角和角度
    var bmap = new BMapGL.Map(&quot;allmap&quot;);    // 创建Map实例
    bmap.centerAndZoom(new BMapGL.Point(116.297611, 40.047363), 17);  // 初始化地图,设置中心点坐标和地图级别
    bmap.enableScrollWheelZoom(true);     // 开启鼠标滚轮缩放
    bmap.setTilt(50);      // 设置地图初始倾斜角

    var path = [{
        &#39;lng&#39;: 116.297611,
        &#39;lat&#39;: 40.047363
    }, {
        &#39;lng&#39;: 116.302839,
        &#39;lat&#39;: 40.048219
    }, {
        &#39;lng&#39;: 116.308301,
        &#39;lat&#39;: 40.050566
    }, {
        &#39;lng&#39;: 116.305732,
        &#39;lat&#39;: 40.054957
    }, {
        &#39;lng&#39;: 116.304754,
        &#39;lat&#39;: 40.057953
    }, {
        &#39;lng&#39;: 116.306487,
        &#39;lat&#39;: 40.058312
    }, {
        &#39;lng&#39;: 116.307223,
        &#39;lat&#39;: 40.056379
    }];

    var point = [];
    for (var i = 0; i &lt; path.length; i++) {
        var poi = new BMapGL.Point(path[i].lng, path[i].lat);
        point.push(poi);
        var marker = new BMapGL.Marker(poi); //创建标注
        bmap.addOverlay(marker); //将标注添加到地图中
    }


    var pl = new BMapGL.Polyline(point,{strokeColor:&quot;blue&quot;, strokeWeight:6, strokeOpacity:0.5});

    var trackAni = new BMapGLLib.TrackAnimation(bmap, pl, {
        overallView: true, // 动画完成后自动调整视野到总览
        tilt: 30,          // 轨迹播放的角度，默认为55
        duration: 20000,   // 动画持续时长，默认为10000，单位ms
        delay: 3000        // 动画开始的延迟，默认0，单位ms
    });

    trackAni.start();
&lt;/script&gt;</code></pre><h1 id="第三步"><a href="#第三步" class="headerlink" title="第三步"></a>第三步</h1><p>使用 Flask 部署，几行代码：</p>
<pre><code>from flask import Flask
from flask import render_template

App = Flask(__name__)


@App.route(&#39;/&#39;)
def index():
    return render_template(&#39;hellomap.html&#39;)


if __name__ == &quot;__main__&quot;:
    App.run(debug=True)</code></pre><p><video src="http://mpvideo.qpic.cn/0bf2v4aauaaa2aaeoxeiobpfbl6dbkxqacqa.f10002.mp4?dis_k=054040f951d8517e6e974943ea75bbd2&dis_t=1586055635" controls="controls" width="500" height="300">您的浏览器不支持播放该视频！</video></p>
]]></content>
      <categories>
        <category>技术探讨</category>
      </categories>
      <tags>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title>让Python搞定MySQL数据库-PYTHON</title>
    <url>/2020/03/28/%E8%AE%A9Python%E6%90%9E%E5%AE%9AMySQL%E6%95%B0%E6%8D%AE%E5%BA%93-PYTHON/</url>
    <content><![CDATA[<p>MySQL是常用的数据库之一，也是面试必备技能之一。</p>
<a id="more"></a>
<p>本篇文章通过一次实战（Python &amp; SQL 语句结合使用 —-搞定MySQL数据库）</p>
<h1 id="实战开始"><a href="#实战开始" class="headerlink" title="实战开始"></a>实战开始</h1><p>在github上下载fifa18球员数据，将这些信息存入到mysql。<br>①数据下载地址：<br><a href="https://github.com/amanthedorkknight/fifa18-all-player-statistics" target="_blank" rel="noopener">https://github.com/amanthedorkknight/fifa18-all-player-statistics</a><br>②选择：Complete-&gt;basicplayerdata.csv</p>
<h1 id="数据从CSV导入MySQL"><a href="#数据从CSV导入MySQL" class="headerlink" title="数据从CSV导入MySQL"></a>数据从CSV导入MySQL</h1><p>1）创建对应库与表  </p>
<pre><code>#创建公司数据库，编码格式utf-8
CREATE DATABASE fifa18_db DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci;
#选择数据库：
use fifa18_db;
#创建球员表：id,名称，海报地址，俱乐部，年龄，薪资等，与csv文件对应
create table player(id int Primary key auto_increment, 
player_id int, name char(64), age int, poster char(64),

                    flag char(64), overall int, potential int, club char(64) default &#39;&#39;, club_Logo char(64), 
                   value char(16), wage char(16), special int) default charset =utf8;</code></pre><p>2）CSV读取文件<br>数据集中某些球员字段为空，插入时候需要补充默认值，使用DictReader读取。  </p>
<pre><code>path = &#39;/home/linux/workdir/data/basicplayerdata.csv&#39;
#字段名称
field = [&#39;&#39;,&#39;ID&#39;,&#39;Name&#39;,&#39;Age&#39;,&#39;Photo&#39;,&#39;Nationality&#39;,&#39;Flag&#39;,&#39;Overall&#39;,&#39;Potential&#39;,&#39;Club&#39;,&#39;Club Logo&#39;,&#39;Value&#39;,&#39;Wage&#39;,&#39;Special&#39;]
f = open(path)
fcsv = csv.DictReader(f, fieldnames = field)
#第一行去掉
line = next(fcsv)
#第一行有效数据
line = next(fcsv)
print(line)</code></pre><p>RESULT</p>
<pre><code>OrderedDict([(&#39;&#39;, &#39;0&#39;), (&#39;ID&#39;, &#39;158023&#39;), (&#39;Name&#39;, &#39;L. Messi&#39;), (&#39;Age&#39;, &#39;30&#39;), 
(&#39;Photo&#39;, &#39;https://cdn.sofifa.org/players/4/18/158023.png&#39;), (&#39;Nationality&#39;, &#39;Argentina&#39;), 
(&#39;Flag&#39;, &#39;https://cdn.sofifa.org/flags/52.png&#39;), 
(&#39;Overall&#39;, &#39;94&#39;), (&#39;Potential&#39;, &#39;94&#39;), (&#39;Club&#39;, &#39;FC Barcelona&#39;), 
(&#39;Club Logo&#39;, &#39;https://cdn.sofifa.org/teams/2/18/light/241.png&#39;), 
(&#39;Value&#39;, &#39;€118.5M&#39;), (&#39;Wage&#39;, &#39;€565K&#39;), (&#39;Special&#39;, &#39;2161&#39;)])</code></pre><p>3）读取一行并整理数据格式<br>CSV读取字段与数据库对应起来，且不要CSV文件种的第一列，整理数据格式为字典，key为数据库列名，value为CSV对应内容，代码实现。</p>
<pre><code>sqlfield = [&#39;player_id&#39;,&#39;name&#39;,&#39;age&#39;,&#39;poster&#39;,&#39;nationality&#39;,&#39;flag&#39;,&#39;overall&#39;,&#39;potential&#39;,&#39;club&#39;,&#39;club_logo&#39;,&#39;value&#39;,&#39;wage&#39;,&#39;special&#39;]
csvfield = [&#39;ID&#39;,&#39;Name&#39;,&#39;Age&#39;,&#39;Photo&#39;,&#39;Nationality&#39;,&#39;Flag&#39;,&#39;Overall&#39;,&#39;Potential&#39;,&#39;Club&#39;,&#39;Club Logo&#39;,&#39;Value&#39;,&#39;Wage&#39;,&#39;Special&#39;]
#转成字典：
keysinfo = dict(zip(sqlfield, csvfield))
#填充数据：
data = {}
for sfield, cfield in keysinfo.items():
    ele = line.get(cfield, &#39;&#39;)
    data.setdefault(sfield, ele)
print(data)</code></pre><p>RESULT</p>
<pre><code>{&#39;player_id&#39;: &#39;158023&#39;, &#39;name&#39;: &#39;L. Messi&#39;, &#39;age&#39;: &#39;30&#39;, &#39;poster&#39;: &#39;https://cdn.sofifa.org/players/4/18/158023.png&#39;, 
&#39;nationality&#39;: &#39;Argentina&#39;, &#39;flag&#39;: &#39;https://cdn.sofifa.org/flags/52.png&#39;, 
&#39;overall&#39;: &#39;94&#39;, &#39;potential&#39;: &#39;94&#39;, &#39;club&#39;: &#39;FC Barcelona&#39;, 
&#39;club_logo&#39;: &#39;https://cdn.sofifa.org/teams/2/18/light/241.png&#39;, 
&#39;value&#39;: &#39;€118.5M&#39;, &#39;wage&#39;: &#39;€565K&#39;, &#39;special&#39;: &#39;2161&#39;}</code></pre><p>4）拼接sql语句<br>插入一条数据：获取插入字段与对应数据，拼接成sql语句。  </p>
<pre><code>tablename = &#39;player&#39;
keys = data.keys()
fields = &#39;,&#39;.join(keys)
vals = &#39;,&#39;.join([&quot;&#39;%s&#39;&quot;% val for val in data.values()])
sql = f&quot;INSERT INTO {tablename}({fields}) VALUES({vals})&quot;
print(sql)</code></pre><p>RESULT</p>
<pre><code>INSERT INTO player(player_id,name,age,poster,nationality,flag,overall,potential,club,club_logo,value,wage,special) 
VALUES(&#39;158023&#39;,&#39;L. Messi&#39;,&#39;30&#39;,&#39;https://cdn.sofifa.org/players/4/18/158023.png&#39;,&#39;Argentina&#39;,&#39;https://cdn.sofifa.org/flags/52.png&#39;,&#39;94&#39;,&#39;94&#39;,&#39;FC Barcelona&#39;,&#39;https://cdn.sofifa.org/teams/2/18/light/241.png&#39;,&#39;€118.5M&#39;,&#39;€565K&#39;,&#39;2161&#39;)</code></pre><p>5）连接数据库，并插入数据  </p>
<pre><code>
#编码格式：utf-8
db = pymysql.connect(&quot;localhost&quot;,&quot;root&quot;,&quot;abc123&quot;,&quot;fifa18_db&quot;, charset=&#39;utf8&#39;)
#获取游标
cursor = db.cursor()
cursor.execute(sql)
#提交数据
db.commit()
#断开连接
cursor.close()
db.close()</code></pre><p>查看player中信息，插入成功。</p>
<p align="left">
    <img src= "/img/loading.gif" data-src="/images/SQL C.png" alt="Sample" width="791" height="220">
</p>  

<p>基本功能都已经实现，对代码进行整理，根据功能定义类及方法。  </p>
<pre><code>import csv    
import pymysql  
class LoadDataFromCsvToMysql:
    def __init__(self, csvpath, csvfield, mysqlfield, table, sqlconfig):
        #初始化参数
        pass
    def connectSql(self):
        #连接数据库，获取游标
        pass
    def disconnectSql(self):
        #断开数据库，获取游标
        pass
    def processSql(self, sql):
        #处理sql语句
        pass
    def loadCsv(self):
        #打开csv文件，返回csv对象
        pass
    def closeCsv(self):
        #关闭csv文件
        pass
    def gensql(self, linedata):
        #生成sql语句
        pass
    def process(self):
        #对外接口，打开文件并写数据库
        pass</code></pre><p>类定义完成之后，我们可以将功能明确的方法实现。  </p>
<pre><code>import csv
import pymysql
class LoadDataFromCsvToMysql:
    def __init__(self, csvpath, csvfield, mysqlfield, table, sqlconfig):
        #初始化参数
        self.dbconfig = sqlconfig
        self.inpath = csvpath
        self.sqlfield =  mysqlfield
        self.csvfield = csvfield
        self.fieldmap = dict(zip(mysqlfield, csvfield[1:]))
        self.tablename = table
    def connectSql(self):
        self.db = pymysql.connect(**self.dbconfig, charset=&#39;utf8&#39;)
        self.cursor = self.db.cursor()
    def disconnectSql(self):
        self.cursor.close()
        self.db.close()
    def processSql(self, sql):
        ret = self.cursor.execute(sql)
        self.db.commit()
        return ret
    def loadCsv(self):
        #打开csv文件
        self.f = open(path)
        fcsv = csv.DictReader(self.f, fieldnames = self.csvfield)
        next(fcsv)
        return fcsv
    def closeCsv(self):
        self.f.close()
    def gensql(self, linedata):
        pass
    def process(self):
        #测试数据库与csv文件打开关闭
        self.connectSql()
        print(&#39;connect sql...&#39;)
        fcsv = self.loadCsv()
        self.disconnectSql()
        self.closeCsv()
        print(&#39;disconnect sql&#39;)        path = &#39;/home/linux/workdir/data/basicplayerdata.csv&#39;
sqlfield= [&#39;player_id&#39;,&#39;name&#39;,&#39;age&#39;,&#39;poster&#39;,&#39;nationality&#39;,&#39;flag&#39;,&#39;overall&#39;,&#39;potential&#39;,&#39;club&#39;,&#39;club_logo&#39;,&#39;value&#39;,&#39;wage&#39;,&#39;special&#39;]
csvfield = [&#39;&#39;,&#39;ID&#39;,&#39;Name&#39;,&#39;Age&#39;,&#39;Photo&#39;,&#39;Nationality&#39;,&#39;Flag&#39;,&#39;Overall&#39;,&#39;Potential&#39;,&#39;Club&#39;,&#39;Club Logo&#39;,&#39;Value&#39;,&#39;Wage&#39;,&#39;Special&#39;]
dbconfig = {&#39;host&#39;:&#39;localhost&#39;,&#39;port&#39;:3306,&#39;user&#39;:&#39;root&#39;,&#39;passwd&#39;:&#39;abc123&#39;,&#39;db&#39;:&#39;fifa18_db&#39;}
obj = LoadDataFromCsvToMysql(path, csvfield, sqlfield,  &#39;player&#39;, dbconfig)
obj.process()

输出：

connect sql...
load csvfile
disconnect sql
</code></pre><p>6）完善process与gensql<br>process方法  </p>
<pre><code>def process(self):
        #测试数据库与csv文件打开关闭
        self.connectSql()
        print(&#39;connect sql...&#39;)
        fcsv = self.loadCsv()
        for line in fcsv:
            sql = self.gensql(line)
            print(sql)
            n = self.processSql(sql)
        self.disconnectSql()
        self.closeCsv()
        print(&#39;disconnect sql&#39;)</code></pre><p>gensql方法 将前面实现添加到此方法中  </p>
<pre><code>def gensql(self, linedata):
        #产生sql语句
        data = {}
        for sfield, cfield in self.fieldmap.items():
            ele = linedata.get(cfield, &#39;&#39;)
            data.setdefault(sfield, ele)
        tablename = self.tablename
        keys = data.keys()
        fields = &#39;,&#39;.join(keys)
        vals = &#39;,&#39;.join([&quot;&#39;%s&#39;&quot;% val for val in data.values()])
        sql = f&quot;INSERT INTO {tablename}({fields}) VALUES({vals})&quot;
        return sql</code></pre><p>测试前将player表中内容删除，然后使用代码先插入一条，并查看结果；如果测试没有问题，可以插入所有数据。实际运行出现问题：sql语句错误 ，字符串拼接错误  </p>
<pre><code>&quot;(&#39;158023&#39;,&#39;L. Messi&#39;,&#39;30&#39;,&#39;https://cdn.sofifa.org/players/4/18/158023.png&#39;,..)&quot;</code></pre><p>双引号+单引号，但是文件中，某些字符串带单引号，所以出现字段错误。<br>修改sql拼接方法：</p>
<pre><code>    def gensql(self, linedata):
        #产生sql语句
        data = {}
        for sfield, cfield in self.fieldmap.items():
            ele = linedata.get(cfield, &#39;&#39;)
            data.setdefault(sfield, ele)
        tablename = self.tablename
        keys = data.keys()
        fields = &#39;,&#39;.join(keys)
        vals = &#39;,&#39;.join([&#39;&quot;%s&quot;&#39;% val for val in data.values()])
        sql = f&#39;INSERT INTO {tablename}({fields}) VALUES({vals})&#39;
        return sql</code></pre><p>RESULT</p>
<pre><code>dstram&quot;,&quot;18&quot;,&quot;https://cdn.sofifa.org/players/4/18/238813.png&quot;,&quot;England&quot;,&quot;https://cdn.sofifa.org/flags/14.png&quot;,&quot;47&quot;,&quot;65&quot;,&quot;Crewe Alexandra&quot;,&quot;https://cdn.sofifa.org/teams/2/18/light/121.png&quot;,&quot;€60K&quot;,&quot;€1K&quot;,&quot;1305&quot;)
INSERT INTO player(player_id,name,age,poster,nationality,flag,overall,potential,club,club_logo,value,wage,special) 
VALUES(&quot;238306&quot;,&quot;A. Conway&quot;,&quot;19&quot;,&quot;https://cdn.sofifa.org/players/4/18/238306.png&quot;,&quot;Republic of Ireland&quot;,&quot;https://cdn.sofifa.org/flags/25.png&quot;,&quot;47&quot;,&quot;63&quot;,&quot;Galway United&quot;,&quot;https://cdn.sofifa.org/teams/2/18/light/1571.png&quot;,&quot;€60K&quot;,&quot;€1K&quot;,&quot;1314&quot;)
disconnect sql
1555235373.5942054 1555235392.2122808</code></pre><p>插入18000条数据，花费时间大概为20S左右；后续优化：每次插入500条数据，然后在查看花费时间，这个大家可以参考前面案例自己实现。  </p>
<h1 id="查询数据"><a href="#查询数据" class="headerlink" title="查询数据"></a>查询数据</h1><p>需求：查询player表中阿根廷国家球员姓名，年龄，头像信息。读者朋友可以自己尝试去实现，考虑使用继承。<br>①sql中查询数据我们步骤：连接数据库，执行sql语句，关闭数据库；<br>②查询与写入很多方法通用，考虑继承LoadDataFromCsvToMysql类；<br>③需要重载init，process，processSql方法；<br>代码：</p>
<pre><code>
class QueryMysql(LoadDataFromCsvToMysql):
    def __init__(self, sqlconfig):
        #调用父类方法，初始化传一些无效参数
        super(QueryMysql, self).__init__(&#39;&#39;,[], [], &#39;&#39;, dbconfig)
    def genSql(self, table, fields, condition=None):
        #查询语句生成
        fds = &#39;,&#39;.join(fields)
        cond = &#39;&#39;
        print(condition)
        if condition:
            cond = f&#39; where {condition}&#39;
        sql = f&#39;select {fds} from {table}{cond}&#39;
        return sql
    def process(self, tablename, fields, condition=None):
        #对外接口
        #调用父类中的连接数据库，关闭数据库方法
        self.connectSql()
        sql = self.genSql(tablename, fields, condition)
        self.processSql(sql)
        items = self.cursor.fetchall()
        for item in items:
            print(item)
        print(&#39;all Argentina player:&#39;, len(items))
        self.disconnectSql()        dbconfig= {&#39;host&#39;:&#39;localhost&#39;,&#39;port&#39;:3306,&#39;user&#39;:&#39;root&#39;,&#39;passwd&#39;:&#39;abc123&#39;,&#39;db&#39;:&#39;fifa18_db&#39;}
tablename = &#39;player&#39;
files = [&#39;name&#39;,&#39;poster&#39;, &#39;age&#39;]
obj = QueryMysql(dbconfig)
cond = &#39;nationality=&quot;Argentina&quot;&#39;
obj.process(tablename, files, cond)



RESULT 



(&#39;L. Messi&#39;, &#39;https://cdn.sofifa.org/players/4/18/158023.png&#39;, 30)
(&#39;G. Higuaín&#39;, &#39;https://cdn.sofifa.org/players/4/18/167664.png&#39;, 29)
(&#39;P. Dybala&#39;, &#39;https://cdn.sofifa.org/players/4/18/211110.png&#39;, 23)...(&#39;A. Miño&#39;, &#39;https://cdn.sofifa.org/players/4/18/243298.png&#39;, 23)
(&#39;T. Durso&#39;, &#39;https://cdn.sofifa.org/players/4/18/240955.png&#39;, 18)
(&#39;K. Humeler&#39;, &#39;https://cdn.sofifa.org/players/4/18/240291.png&#39;, 20)
(&#39;J. Mendive&#39;, &#39;https://cdn.sofifa.org/players/4/18/241584.png&#39;, 20)
all Argentina player: 966</code></pre><h1 id="得出结果"><a href="#得出结果" class="headerlink" title="得出结果"></a>得出结果</h1><p>数据集中一共有966名Argentina球员</p>
]]></content>
      <categories>
        <category>技术资讯</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>面向对象Demo-PYTHON</title>
    <url>/2020/03/27/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1Demo-PYTHON/</url>
    <content><![CDATA[<h1 id="属性"><a href="#属性" class="headerlink" title="属性"></a>属性</h1><p>小游戏案例。</p>
<a id="more"></a>
<h1 id="1-人类"><a href="#1-人类" class="headerlink" title="1. 人类"></a>1. 人类</h1><p>属性<br>姓名<br>血量<br>持有的枪<br>方法<br>安子弹<br>安弹夹<br>拿枪（持有抢）<br>开枪</p>
<h1 id="2-子弹类"><a href="#2-子弹类" class="headerlink" title="2. 子弹类"></a>2. 子弹类</h1><p>属性<br>杀伤力<br>方法<br>伤害敌人(让敌人掉血)  </p>
<h1 id="3-弹夹类"><a href="#3-弹夹类" class="headerlink" title="3. 弹夹类"></a>3. 弹夹类</h1><p>属性<br>容量（子弹存储的最大值）<br>当前保存的子弹<br>方法<br>保存子弹（安装子弹的时候）<br>弹出子弹（开枪的时候）  </p>
<h1 id="4-枪类"><a href="#4-枪类" class="headerlink" title="4. 枪类"></a>4. 枪类</h1><p>属性<br>弹夹（默认没有弹夹，需要安装）<br>方法<br>连接弹夹（保存弹夹）<br>射子弹  </p>
<h1 id="代码参考"><a href="#代码参考" class="headerlink" title="代码参考"></a>代码参考</h1><pre><code>class Person(object):
    def __init__(self, new_name):
        self.name = new_name
        self.gun = None
        self.ph = 100

    def anzhuang_zidan(self, danjian_temp, zidan_temp):
        # 让弹夹存储子弹
        danjian_temp.baocun(zidan_temp)

    def anzhuang_danjia(self, gun_temp, danjia_temp):
        gun_temp.baocun(danjia_temp)

    def na_gun(self, gun_temp):
        self.gun = gun_temp

    def __str__(self):
        if self.gun:
            return &quot;%s 的ph为:%d, 他一把%s：&quot; % (self.name, self.ph, self.gun)
        else:
            return &quot;%s 的ph为:%d, 他么有枪...&quot; % (self.name, self.ph)

    def kaiqiang(self, diren):
        # 让枪向敌人开火
        self.gun.fire(diren)

    def diaoxue(self, shashangli):
        self.ph -= shashangli


class Gun(object):
    def __init__(self, new_name):
        self.name = new_name
        self.danjia = None

    def baocun(self, danjia_temp):
        self.danjia = danjia_temp

    def __str__(self):
        if self.danjia:
            return &quot;%s有弹夹，%s&quot; % (self.name, self.danjia)
        else:
            return &quot;%s没有弹夹&quot;

    def fire(self, diren):
        # 从弹夹中拿出一个子弹
        zidan_temp = self.danjia.tanchu_zidan()
        if zidan_temp:
            # 让子弹去伤害敌人
            zidan_temp.shanghai(diren)
        else:
            print(&quot;%s没子弹了&quot; % self.name)


class Danjia(object):
    def __init__(self, new_max_num):
        self.max_num = new_max_num
        self.zidan_list = []

    def baocun(self, zidan_temp):
        self.zidan_list.append(zidan_temp)

    def __str__(self):
        return &quot;弹夹：%d/%d&quot; % (len(self.zidan_list), self.max_num)

    def tanchu_zidan(self):
        if len(self.zidan_list) &gt; 0:
            return self.zidan_list.pop()
        else:
            return None


class Bullet(object):
    def __init__(self, new_shashangli):
        self.shashangli = new_shashangli

    def shanghai(self, diren):
        diren.diaoxue(self.shashangli)

# 创建老王对象
lao_wang = Person(&quot;老王&quot;)

# 创建一把枪
ak47 = Gun(&quot;AK47&quot;)

# 创建一个弹夹
dan_jia = Danjia(20)  # 表示最大能够容纳20发子弹

# 创建一颗子弹
bullet = Bullet(10)  # 表示每颗子弹的杀伤力

# 老王把一个子弹放到弹夹中
lao_wang.anzhuang_zidan(dan_jia, bullet)

# 测试弹夹的信息
print(dan_jia)

# 老王把弹夹放到枪中
lao_wang.anzhuang_danjia(ak47, dan_jia)

# 测试枪的信息
print(ak47)

# 老王拿起枪
lao_wang.na_gun(ak47)

# 测试老王的信息
print(lao_wang)

# 创建一个敌人
gebi_laowang = Person(&quot;隔壁老王&quot;)

# 老王向隔壁老王开枪
lao_wang.kaiqiang(gebi_laowang)

# 测试隔壁老王
print(gebi_laowang)

# 创建一些子弹
for i in range(5):
    bullet = Bullet(10)  # 表示每颗子弹的杀伤力
    # 每创建一颗子弹就让老王把它放到弹夹中
    lao_wang.anzhuang_zidan(dan_jia, bullet)

lao_wang.kaiqiang(gebi_laowang)
print(gebi_laowang)
lao_wang.kaiqiang(gebi_laowang)
print(gebi_laowang)
lao_wang.kaiqiang(gebi_laowang)
print(gebi_laowang)
lao_wang.kaiqiang(gebi_laowang)
print(gebi_laowang)
lao_wang.kaiqiang(gebi_laowang)
print(gebi_laowang)
lao_wang.kaiqiang(gebi_laowang)
print(gebi_laowang)</code></pre>]]></content>
      <categories>
        <category>代码案例</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>迭代器生成器-PYTHON</title>
    <url>/2020/03/20/%E8%BF%AD%E4%BB%A3%E5%99%A8%E7%94%9F%E6%88%90%E5%99%A8-PYTHON/</url>
    <content><![CDATA[<p>Python 迭代器与生成器<br>可以被next()函数调用并不断返回下一个值的对象称为迭代器：Iterator。<br>在Python中，这种一边循环一边计算的机制，称为生成器：generator</p>
<a id="more"></a>
<h1 id="迭代器"><a href="#迭代器" class="headerlink" title="迭代器"></a>迭代器</h1><p>迭代是Python最强大的功能之一，是访问集合元素的一种方式。<br>迭代器是一个可以记住遍历的位置的对象。<br>迭代器对象从集合的第一个元素开始访问，直到所有的元素被访问完结束。<br>迭代器只能往前不会后退。<br>迭代器有两个基本的方法：iter() 和 next()。<br>字符串，列表或元组对象都可用于创建迭代器：</p>
<pre><code>&gt;&gt;&gt;list=[1,2,3,4]
&gt;&gt;&gt; it = iter(list)    # 创建迭代器对象
&gt;&gt;&gt; print (next(it))   # 输出迭代器的下一个元素
1
&gt;&gt;&gt; print (next(it))
2
&gt;&gt;&gt;</code></pre><h1 id="迭代器对象可以使用常规for语句进行遍历："><a href="#迭代器对象可以使用常规for语句进行遍历：" class="headerlink" title="迭代器对象可以使用常规for语句进行遍历："></a>迭代器对象可以使用常规for语句进行遍历：</h1><pre><code>#!/usr/bin/python3

list=[1,2,3,4]
it = iter(list)    # 创建迭代器对象
for x in it:
    print (x, end=&quot; &quot;)
执行以上程序，输出结果如下：

1 2 3 4</code></pre><p>也可以使用 next() 函数：</p>
<pre><code>#!/usr/bin/python3

import sys         # 引入 sys 模块

list=[1,2,3,4]
it = iter(list)    # 创建迭代器对象

while True:
    try:
        print (next(it))
    except StopIteration:
        sys.exit()
执行以上程序，输出结果如下：

1
2
3
4</code></pre><h1 id="创建一个迭代器"><a href="#创建一个迭代器" class="headerlink" title="创建一个迭代器"></a>创建一个迭代器</h1><p>把一个类作为一个迭代器使用需要在类中实现两个方法 <strong>iter</strong>() 与 <strong>next</strong>() 。<br>如果你已经了解的面向对象编程，就知道类都有一个构造函数，Python 的构造函数为 <strong>init</strong>(), 它会在对象初始化的时候执行。<br>更多内容查阅：Python 面向对象<br><strong>iter</strong>() 方法返回一个特殊的迭代器对象， 这个迭代器对象实现了 <strong>next</strong>() 方法并通过 StopIteration 异常标识迭代的完成。<br><strong>next</strong>() 方法（Python 2 里是 next()）会返回下一个迭代器对象。<br>创建一个返回数字的迭代器，初始值为 1，逐步递增 1：</p>
<pre><code>class MyNumbers:
  def __iter__(self):
    self.a = 1
    return self

  def __next__(self):
    x = self.a
    self.a += 1
    return x

myclass = MyNumbers()
myiter = iter(myclass)

print(next(myiter))
print(next(myiter))
print(next(myiter))
print(next(myiter))
print(next(myiter))
执行输出结果为：

1
2
3
4
5</code></pre><h1 id="StopIteration"><a href="#StopIteration" class="headerlink" title="StopIteration"></a>StopIteration</h1><p>StopIteration 异常用于标识迭代的完成，防止出现无限循环的情况，在 <strong>next</strong>() 方法中我们可以设置在完成指定循环次数后触发 StopIteration 异常来结束迭代。<br>在 20 次迭代后停止执行：</p>
<pre><code>class MyNumbers:
  def __iter__(self):
    self.a = 1
    return self

  def __next__(self):
    if self.a &lt;= 20:
      x = self.a
      self.a += 1
      return x
    else:
      raise StopIteration

myclass = MyNumbers()
myiter = iter(myclass)

for x in myiter:
  print(x)
执行输出结果为：

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20</code></pre><h1 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h1><p>在 Python 中，使用了 yield 的函数被称为生成器（generator）。<br>跟普通函数不同的是，生成器是一个返回迭代器的函数，只能用于迭代操作，更简单点理解生成器就是一个迭代器。<br>在调用生成器运行的过程中，每次遇到 yield 时函数会暂停并保存当前所有的运行信息，返回 yield 的值, 并在下一次执行 next() 方法时从当前位置继续运行。<br>调用一个生成器函数，返回的是一个迭代器对象。<br>以下实例使用 yield 实现斐波那契数列：</p>
<pre><code>#!/usr/bin/python3

import sys

def fibonacci(n): # 生成器函数 - 斐波那契
    a, b, counter = 0, 1, 0
    while True:
        if (counter &gt; n): 
            return
        yield a
        a, b = b, a + b
        counter += 1
f = fibonacci(10) # f 是一个迭代器，由生成器返回生成

while True:
    try:
        print (next(f), end=&quot; &quot;)
    except StopIteration:
        sys.exit()
执行以上程序，输出结果如下：

0 1 1 2 3 5 8 13 21 34 55</code></pre>]]></content>
      <categories>
        <category>基础进阶</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>面向对象-PYTHON</title>
    <url>/2020/03/20/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1-PYTHON/</url>
    <content><![CDATA[<p>Python 面向对象class<br>类就是一个模板，模板里可以包含多个函数，函数里实现一些功能<br>对象则是根据模板创建的实例，通过实例对象可以执行类中的函数</p>
<a id="more"></a>

<p>Python从设计之初就已经是一门面向对象的语言，正因为如此，在Python中创建一个类和对象是很容易的。</p>
<p>如果你以前没有接触过面向对象的编程语言，那你可能需要先了解一些面向对象语言的一些基本特征，在头脑里头形成一个基本的面向对象的概念，这样有助于你更容易的学习Python的面向对象编程。</p>
<p>接下来我们先来简单的了解下面向对象的一些基本特征。</p>
<h1 id="面向对象技术简介"><a href="#面向对象技术简介" class="headerlink" title="面向对象技术简介"></a>面向对象技术简介</h1><p>类(Class): 用来描述具有相同的属性和方法的对象的集合。它定义了该集合中每个对象所共有的属性和方法。对象是类的实例。<br>方法：类中定义的函数。<br>类变量：类变量在整个实例化的对象中是公用的。类变量定义在类中且在函数体之外。类变量通常不作为实例变量使用。<br>数据成员：类变量或者实例变量用于处理类及其实例对象的相关的数据。<br>方法重写：如果从父类继承的方法不能满足子类的需求，可以对其进行改写，这个过程叫方法的覆盖（override），也称为方法的重写。<br>局部变量：定义在方法中的变量，只作用于当前实例的类。<br>实例变量：在类的声明中，属性是用变量来表示的。这种变量就称为实例变量，是在类声明的内部但是在类的其他成员方法之外声明的。<br>继承：即一个派生类（derived class）继承基类（base class）的字段和方法。继承也允许把一个派生类的对象作为一个基类对象对待。例如，有这样一个设计：一个Dog类型的对象派生自Animal类，这是模拟”是一个（is-a）”关系（例图，Dog是一个Animal）。<br>实例化：创建一个类的实例，类的具体对象。<br>对象：通过类定义的数据结构实例。对象包括两个数据成员（类变量和实例变量）和方法。<br>和其它编程语言相比，Python 在尽可能不增加新的语法和语义的情况下加入了类机制。</p>
<p>Python中的类提供了面向对象编程的所有基本功能：类的继承机制允许多个基类，派生类可以覆盖基类中的任何方法，方法中可以调用基类中的同名方法。</p>
<p>对象可以包含任意数量和类型的数据。</p>
<h1 id="类定义"><a href="#类定义" class="headerlink" title="类定义"></a>类定义</h1><p>语法格式如下：</p>
<pre><code>class ClassName:
    &lt;statement-1&gt;
    .
    .
    .
    &lt;statement-N&gt;
类实例化后，可以使用其属性，实际上，创建一个类之后，可以通过类名访问其属性。

类对象
类对象支持两种操作：属性引用和实例化。
属性引用使用和 Python 中所有的属性引用一样的标准语法：obj.name。
类对象创建后，类命名空间中所有的命名都是有效属性名。所以如果类定义是这样:

#!/usr/bin/python3

class MyClass:
    &quot;&quot;&quot;一个简单的类实例&quot;&quot;&quot;
    i = 12345
    def f(self):
        return &#39;hello world&#39;

# 实例化类
x = MyClass()

# 访问类的属性和方法
print(&quot;MyClass 类的属性 i 为：&quot;, x.i)
print(&quot;MyClass 类的方法 f 输出为：&quot;, x.f())
以上创建了一个新的类实例并将该对象赋给局部变量 x，x 为空的对象。

执行以上程序输出结果为：

MyClass 类的属性 i 为： 12345
MyClass 类的方法 f 输出为： hello world</code></pre><p>类有一个名为 <strong>init</strong>() 的特殊方法（构造方法），该方法在类实例化时会自动调用，像下面这样：</p>
<pre><code>def __init__(self):
    self.data = []
类定义了 __init__() 方法，类的实例化操作会自动调用 __init__() 方法。如下实例化类 MyClass，对应的 __init__() 方法就会被调用:

x = MyClass()
当然， __init__() 方法可以有参数，参数通过 __init__() 传递到类的实例化操作上。例如:

#!/usr/bin/python3

class Complex:
    def __init__(self, realpart, imagpart):
        self.r = realpart
        self.i = imagpart
x = Complex(3.0, -4.5)
print(x.r, x.i)   # 输出结果：3.0 -4.5</code></pre><h1 id="self代表类的实例，而非类"><a href="#self代表类的实例，而非类" class="headerlink" title="self代表类的实例，而非类"></a>self代表类的实例，而非类</h1><p>类的方法与普通的函数只有一个特别的区别——它们必须有一个额外的第一个参数名称, 按照惯例它的名称是 self。</p>
<pre><code>class Test:
    def prt(self):
        print(self)
        print(self.__class__)

t = Test()
t.prt()
以上实例执行结果为：

&lt;__main__.Test instance at 0x100771878&gt;
__main__.Test
从执行结果可以很明显的看出，self 代表的是类的实例，代表当前对象的地址，而 self.class 则指向类。

self 不是 python 关键字，我们把他换成 ai8py也是可以正常执行的:

class Test:
    def prt(ai8py):
        print(ai8py)
        print(ai8py.__class__)

t = Test()
t.prt()
以上实例执行结果为：

&lt;__main__.Test instance at 0x100771878&gt;
__main__.Test</code></pre><h1 id="类的方法"><a href="#类的方法" class="headerlink" title="类的方法"></a>类的方法</h1><p>在类的内部，使用 def 关键字来定义一个方法，与一般函数定义不同，类方法必须包含参数 self, 且为第一个参数，self 代表的是类的实例。</p>
<pre><code>#!/usr/bin/python3

#类定义
class people:
    #定义基本属性
    name = &#39;&#39;
    age = 0
    #定义私有属性,私有属性在类外部无法直接进行访问
    __weight = 0
    #定义构造方法
    def __init__(self,n,a,w):
        self.name = n
        self.age = a
        self.__weight = w
    def speak(self):
        print(&quot;%s 说: 我 %d 岁。&quot; %(self.name,self.age))

# 实例化类
p = people(&#39;ai8py&#39;,10,30)
p.speak()
执行以上程序输出结果为：

ai8py 说: 我 10 岁。</code></pre><h1 id="继承"><a href="#继承" class="headerlink" title="继承"></a>继承</h1><p>Python 同样支持类的继承，如果一种语言不支持继承，类就没有什么意义。派生类的定义如下所示:</p>
<pre><code>class DerivedClassName(BaseClassName1):
    &lt;statement-1&gt;
    .
    .
    .
    &lt;statement-N&gt;
需要注意圆括号中基类的顺序，若是基类中有相同的方法名，而在子类使用时未指定，python从左至右搜索 即方法在子类中未找到时，从左到右查找基类中是否包含方法。

BaseClassName（示例中的基类名）必须与派生类定义在一个作用域内。除了类，还可以用表达式，基类定义在另一个模块中时这一点非常有用:

class DerivedClassName(modname.BaseClassName):
#!/usr/bin/python3

#类定义
class people:
    #定义基本属性
    name = &#39;&#39;
    age = 0
    #定义私有属性,私有属性在类外部无法直接进行访问
    __weight = 0
    #定义构造方法
    def __init__(self,n,a,w):
        self.name = n
        self.age = a
        self.__weight = w
    def speak(self):
        print(&quot;%s 说: 我 %d 岁。&quot; %(self.name,self.age))

#单继承示例
class student(people):
    grade = &#39;&#39;
    def __init__(self,n,a,w,g):
        #调用父类的构函
        people.__init__(self,n,a,w)
        self.grade = g
    #覆写父类的方法
    def speak(self):
        print(&quot;%s 说: 我 %d 岁了，我在读 %d 年级&quot;%(self.name,self.age,self.grade))



s = student(&#39;ken&#39;,10,60,3)
s.speak()
执行以上程序输出结果为：

ken 说: 我 10 岁了，我在读 3 年级</code></pre><h1 id="多继承"><a href="#多继承" class="headerlink" title="多继承"></a>多继承</h1><p>Python同样有限的支持多继承形式。多继承的类定义形如下例:</p>
<pre><code>class DerivedClassName(Base1, Base2, Base3):
    &lt;statement-1&gt;
    .
    .
    .
    &lt;statement-N&gt;
需要注意圆括号中父类的顺序，若是父类中有相同的方法名，而在子类使用时未指定，python从左至右搜索 即方法在子类中未找到时，从左到右查找父类中是否包含方法。

#!/usr/bin/python3

#类定义
class people:
    #定义基本属性
    name = &#39;&#39;
    age = 0
    #定义私有属性,私有属性在类外部无法直接进行访问
    __weight = 0
    #定义构造方法
    def __init__(self,n,a,w):
        self.name = n
        self.age = a
        self.__weight = w
    def speak(self):
        print(&quot;%s 说: 我 %d 岁。&quot; %(self.name,self.age))

#单继承示例
class student(people):
    grade = &#39;&#39;
    def __init__(self,n,a,w,g):
        #调用父类的构函
        people.__init__(self,n,a,w)
        self.grade = g
    #覆写父类的方法
    def speak(self):
        print(&quot;%s 说: 我 %d 岁了，我在读 %d 年级&quot;%(self.name,self.age,self.grade))

#另一个类，多重继承之前的准备
class speaker():
    topic = &#39;&#39;
    name = &#39;&#39;
    def __init__(self,n,t):
        self.name = n
        self.topic = t
    def speak(self):
        print(&quot;我叫 %s，我是一个演说家，我演讲的主题是 %s&quot;%(self.name,self.topic))

#多重继承
class sample(speaker,student):
    a =&#39;&#39;
    def __init__(self,n,a,w,g,t):
        student.__init__(self,n,a,w,g)
        speaker.__init__(self,n,t)

test = sample(&quot;Tim&quot;,25,80,4,&quot;Python&quot;)
test.speak()   #方法名同，默认调用的是在括号中排前地父类的方法
执行以上程序输出结果为：

我叫 Tim，我是一个演说家，我演讲的主题是 Python</code></pre><h1 id="方法重写"><a href="#方法重写" class="headerlink" title="方法重写"></a>方法重写</h1><p>如果你的父类方法的功能不能满足你的需求，你可以在子类重写你父类的方法，实例如下：</p>
<pre><code>#!/usr/bin/python3

class Parent:        # 定义父类
   def myMethod(self):
      print (&#39;调用父类方法&#39;)

class Child(Parent): # 定义子类
   def myMethod(self):
      print (&#39;调用子类方法&#39;)

c = Child()          # 子类实例
c.myMethod()         # 子类调用重写方法
super(Child,c).myMethod() #用子类对象调用父类已被覆盖的方法
super() 函数是用于调用父类(超类)的一个方法。

执行以上程序输出结果为：

调用子类方法
调用父类方法</code></pre><h1 id="类属性与方法"><a href="#类属性与方法" class="headerlink" title="类属性与方法"></a>类属性与方法</h1><p>类的私有属性<br><strong>private_attrs：两个下划线开头，声明该属性为私有，不能在类的外部被使用或直接访问。在类内部的方法中使用时 self.</strong>private_attrs。</p>
<p>类的方法<br>在类的内部，使用 def 关键字来定义一个方法，与一般函数定义不同，类方法必须包含参数 self，且为第一个参数，self 代表的是类的实例。</p>
<p>self 的名字并不是规定死的，也可以使用 this，但是最好还是按照约定是用 self。</p>
<p>类的私有方法<br><strong>private_method：两个下划线开头，声明该方法为私有方法，只能在类的内部调用 ，不能在类的外部调用。self.</strong>private_methods。</p>
<p>类的私有属性实例如下：</p>
<pre><code>#!/usr/bin/python3

class JustCounter:
    __secretCount = 0  # 私有变量
    publicCount = 0    # 公开变量

    def count(self):
        self.__secretCount += 1
        self.publicCount += 1
        print (self.__secretCount)

counter = JustCounter()
counter.count()
counter.count()
print (counter.publicCount)
print (counter.__secretCount)  # 报错，实例不能访问私有变量
执行以上程序输出结果为：

1
2
2
Traceback (most recent call last):
  File &quot;test.py&quot;, line 16, in &lt;module&gt;
    print (counter.__secretCount)  # 报错，实例不能访问私有变量
AttributeError: &#39;JustCounter&#39; object has no attribute &#39;__secretCount&#39;
类的私有方法实例如下：

#!/usr/bin/python3

class Site:
    def __init__(self, name, url):
        self.name = name       # public
        self.__url = url   # private

    def who(self):
        print(&#39;name  : &#39;, self.name)
        print(&#39;url : &#39;, self.__url)

    def __foo(self):          # 私有方法
        print(&#39;这是私有方法&#39;)

    def foo(self):            # 公共方法
        print(&#39;这是公共方法&#39;)
        self.__foo()

x = Site(&#39;蟒蛇教程&#39;, &#39;www.ai8py.com&#39;)
x.who()        # 正常输出
x.foo()        # 正常输出
x.__foo()      # 报错
以上实例执行结果：

Traceback (most recent call last):
  File &quot;D:\code\eclipse-workspace\ai8py\src\test1.py&quot;, line 22, in &lt;module&gt;
name  :  蟒蛇教程
url :  www.ai8py.com
这是公共方法
这是私有方法
    x.__foo()      # 报错
AttributeError: &#39;Site&#39; object has no attribute &#39;__foo&#39;</code></pre><h1 id="类的专有方法："><a href="#类的专有方法：" class="headerlink" title="类的专有方法："></a>类的专有方法：</h1><p><strong>init</strong> : 构造函数，在生成对象时调用<br><strong>del</strong> : 析构函数，释放对象时使用<br><strong>repr</strong> : 打印，转换<br><strong>setitem</strong> : 按照索引赋值<br><strong>getitem</strong>: 按照索引获取值<br><strong>len</strong>: 获得长度<br><strong>cmp</strong>: 比较运算<br><strong>call</strong>: 函数调用<br><strong>add</strong>: 加运算<br><strong>sub</strong>: 减运算<br><strong>mul</strong>: 乘运算<br><strong>truediv</strong>: 除运算<br><strong>mod</strong>: 求余运算<br><strong>pow</strong>: 乘方</p>
<h1 id="运算符重载"><a href="#运算符重载" class="headerlink" title="运算符重载"></a>运算符重载</h1><p>Python同样支持运算符重载，我们可以对类的专有方法进行重载，实例如下：</p>
<pre><code>#!/usr/bin/python3

class Vector:
   def __init__(self, a, b):
      self.a = a
      self.b = b

   def __str__(self):
      return &#39;Vector (%d, %d)&#39; % (self.a, self.b)

   def __add__(self,other):
      return Vector(self.a + other.a, self.b + other.b)

v1 = Vector(2,10)
v2 = Vector(5,-2)
print (v1 + v2)
以上代码执行结果如下所示:

Vector(7,8)</code></pre>]]></content>
      <categories>
        <category>基础进阶</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>错误和异常-PYTHON</title>
    <url>/2020/03/19/%E9%94%99%E8%AF%AF%E5%92%8C%E5%BC%82%E5%B8%B8-PYTHON/</url>
    <content><![CDATA[<p>Python 错误和异常<br>Python内置了一套异常处理机制，来帮助我们进行错误处理。<br>代码运行前的语法或逻辑错误<br>语法错误在执行前修改，逻辑错误无法修改<br>异常分为两个步骤：<br>异常产生，检查到错误且解释器认为是异常，抛出异常<br>异常处理，截获异常，忽略或终止程序处理异常</p>
<a id="more"></a>

<p>Python有两种错误很容易辨认：语法错误和异常。</p>
<h1 id="语法错误"><a href="#语法错误" class="headerlink" title="语法错误"></a>语法错误</h1><p>Python 的语法错误或者称之为解析错，是初学者经常碰到的，如下实例</p>
<blockquote>
<blockquote>
<blockquote>
<p>while True print(‘Hello world’)<br>  File “<stdin>“, line 1, in ?<br>    while True print(‘Hello world’)<br>                   ^<br>SyntaxError: invalid syntax<br>这个例子中，函数 print() 被检查到有错误，是它前面缺少了一个冒号（:）。<br>语法分析器指出了出错的一行，并且在最先找到的错误的位置标记了一个小小的箭头。</stdin></p>
</blockquote>
</blockquote>
</blockquote>
<h1 id="异常"><a href="#异常" class="headerlink" title="异常"></a>异常</h1><p>即便Python程序的语法是正确的，在运行它的时候，也有可能发生错误。运行期检测到的错误被称为异常。<br>大多数的异常都不会被程序处理，都以错误信息的形式展现在这里:</p>
<blockquote>
<blockquote>
<blockquote>
<p>10 * (1/0)<br>Traceback (most recent call last):<br>  File “<stdin>“, line 1, in ?<br>ZeroDivisionError: division by zero<br>4 + spam*3<br>Traceback (most recent call last):<br>  File “<stdin>“, line 1, in ?<br>NameError: name ‘spam’ is not defined<br>‘2’ + 2<br>Traceback (most recent call last):<br>  File “<stdin>“, line 1, in ?<br>TypeError: Can’t convert ‘int’ object to str implicitly<br>异常以不同的类型出现，这些类型都作为信息的一部分打印出来: 例子中的类型有 ZeroDivisionError，NameError 和 TypeError。<br>错误信息的前面部分显示了异常发生的上下文，并以调用栈的形式显示具体信息。</stdin></stdin></stdin></p>
</blockquote>
</blockquote>
</blockquote>
<h1 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h1><p>以下例子中，让用户输入一个合法的整数，但是允许用户中断这个程序（使用 Control-C 或者操作系统提供的方法）。用户中断的信息会引发一个 KeyboardInterrupt 异常。</p>
<blockquote>
<blockquote>
<blockquote>
<p>while True:<br>        try:<br>            x = int(input(“Please enter a number: “))<br>            break<br>        except ValueError:<br>            print(“Oops!  That was no valid number.  Try again   “)<br>try语句按照如下方式工作；</p>
</blockquote>
</blockquote>
</blockquote>
<p>首先，执行try子句（在关键字try和关键字except之间的语句）<br>如果没有异常发生，忽略except子句，try子句执行后结束。<br>如果在执行try子句的过程中发生了异常，那么try子句余下的部分将被忽略。如果异常的类型和 except 之后的名称相符，那么对应的except子句将被执行。最后执行 try 语句之后的代码。<br>如果一个异常没有与任何的except匹配，那么这个异常将会传递给上层的try中。<br>一个 try 语句可能包含多个except子句，分别来处理不同的特定的异常。最多只有一个分支会被执行。<br>处理程序将只针对对应的try子句中的异常进行处理，而不是其他的 try 的处理程序中的异常。<br>一个except子句可以同时处理多个异常，这些异常将被放在一个括号里成为一个元组，例如:</p>
<p>except (RuntimeError, TypeError, NameError):<br>        pass<br>最后一个except子句可以忽略异常的名称，它将被当作通配符使用。你可以使用这种方法打印一个错误信息，然后再次把异常抛出。</p>
<p>import sys</p>
<p>try:<br>    f = open(‘myfile.txt’)<br>    s = f.readline()<br>    i = int(s.strip())<br>except OSError as err:<br>    print(“OS error: {0}”.format(err))<br>except ValueError:<br>    print(“Could not convert data to an integer.”)<br>except:<br>    print(“Unexpected error:”, sys.exc_info()[0])<br>    raise<br>try except 语句还有一个可选的else子句，如果使用这个子句，那么必须放在所有的except子句之后。这个子句将在try子句没有发生任何异常的时候执行。例如:</p>
<p>for arg in sys.argv[1:]:<br>    try:<br>        f = open(arg, ‘r’)<br>    except IOError:<br>        print(‘cannot open’, arg)<br>    else:<br>        print(arg, ‘has’, len(f.readlines()), ‘lines’)<br>        f.close()<br>使用 else 子句比把所有的语句都放在 try 子句里面要好，这样可以避免一些意想不到的、而except又没有捕获的异常。</p>
<p>异常处理并不仅仅处理那些直接发生在try子句中的异常，而且还能处理子句中调用的函数（甚至间接调用的函数）里抛出的异常。例如:</p>
<blockquote>
<blockquote>
<blockquote>
<p>def this_fails():<br>        x = 1/0</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p>try:<br>        this_fails()<br>    except ZeroDivisionError as err:<br>        print(‘Handling run-time error:’, err)</p>
</blockquote>
</blockquote>
</blockquote>
<p>Handling run-time error: int division or modulo by zero</p>
<h1 id="抛出异常"><a href="#抛出异常" class="headerlink" title="抛出异常"></a>抛出异常</h1><p>Python 使用 raise 语句抛出一个指定的异常。例如:</p>
<blockquote>
<blockquote>
<blockquote>
<p>raise NameError(‘HiThere’)<br>Traceback (most recent call last):<br>  File “<stdin>“, line 1, in ?<br>NameError: HiThere<br>raise 唯一的一个参数指定了要被抛出的异常。它必须是一个异常的实例或者是异常的类（也就是 Exception 的子类）。</stdin></p>
</blockquote>
</blockquote>
</blockquote>
<p>如果你只想知道这是否抛出了一个异常，并不想去处理它，那么一个简单的 raise 语句就可以再次把它抛出。</p>
<blockquote>
<blockquote>
<blockquote>
<p>try:<br>        raise NameError(‘HiThere’)<br>    except NameError:<br>        print(‘An exception flew by!’)<br>        raise</p>
</blockquote>
</blockquote>
</blockquote>
<p>An exception flew by!<br>Traceback (most recent call last):<br>  File “<stdin>“, line 2, in ?<br>NameError: HiThere</stdin></p>
<h1 id="用户自定义异常"><a href="#用户自定义异常" class="headerlink" title="用户自定义异常"></a>用户自定义异常</h1><p>你可以通过创建一个新的异常类来拥有自己的异常。异常类继承自 Exception 类，可以直接继承，或者间接继承，例如:</p>
<blockquote>
<blockquote>
<blockquote>
<p>class MyError(Exception):<br>        def <strong>init</strong>(self, value):<br>            self.value = value<br>        def <strong>str</strong>(self):<br>            return repr(self.value)</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p>try:<br>        raise MyError(2*2)<br>    except MyError as e:<br>        print(‘My exception occurred, value:’, e.value)</p>
</blockquote>
</blockquote>
</blockquote>
<p>My exception occurred, value: 4</p>
<blockquote>
<blockquote>
<blockquote>
<p>raise MyError(‘oops!’)<br>Traceback (most recent call last):<br>  File “<stdin>“, line 1, in ?<br><strong>main</strong>.MyError: ‘oops!’<br>在这个例子中，类 Exception 默认的 <strong>init</strong>() 被覆盖。</stdin></p>
</blockquote>
</blockquote>
</blockquote>
<p>当创建一个模块有可能抛出多种不同的异常时，一种通常的做法是为这个包建立一个基础异常类，然后基于这个基础类为不同的错误情况创建不同的子类:</p>
<p>class Error(Exception):<br>    “””Base class for exceptions in this module.”””<br>    pass</p>
<p>class InputError(Error):<br>    “””Exception raised for errors in the input.</p>
<pre><code>Attributes:
    expression -- input expression in which the error occurred
    message -- explanation of the error
&quot;&quot;&quot;

def __init__(self, expression, message):
    self.expression = expression
    self.message = message</code></pre><p>class TransitionError(Error):<br>    “””Raised when an operation attempts a state transition that’s not<br>    allowed.</p>
<pre><code>Attributes:
    previous -- state at beginning of transition
    next -- attempted new state
    message -- explanation of why the specific transition is not allowed
&quot;&quot;&quot;

def __init__(self, previous, next, message):
    self.previous = previous
    self.next = next
    self.message = message</code></pre><p>大多数的异常的名字都以”Error”结尾，就跟标准的异常命名一样。</p>
<h1 id="定义清理行为"><a href="#定义清理行为" class="headerlink" title="定义清理行为"></a>定义清理行为</h1><p>try 语句还有另外一个可选的子句，它定义了无论在任何情况下都会执行的清理行为。 例如:</p>
<blockquote>
<blockquote>
<blockquote>
<p>try:<br>…     raise KeyboardInterrupt<br>… finally:<br>…     print(‘Goodbye, world!’)<br>…<br>Goodbye, world!<br>Traceback (most recent call last):<br>  File “<stdin>“, line 2, in <module><br>KeyboardInterrupt<br>以上例子不管 try 子句里面有没有发生异常，finally 子句都会执行。</module></stdin></p>
</blockquote>
</blockquote>
</blockquote>
<p>如果一个异常在 try 子句里（或者在 except 和 else 子句里）被抛出，而又没有任何的 except 把它截住，那么这个异常会在 finally 子句执行后被抛出。</p>
<p>下面是一个更加复杂的例子（在同一个 try 语句里包含 except 和 finally 子句）:</p>
<blockquote>
<blockquote>
<blockquote>
<p>def divide(x, y):<br>        try:<br>            result = x / y<br>        except ZeroDivisionError:<br>            print(“division by zero!”)<br>        else:<br>            print(“result is”, result)<br>        finally:<br>            print(“executing finally clause”)</p>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p>divide(2, 1)<br>result is 2.0<br>executing finally clause<br>divide(2, 0)<br>division by zero!<br>executing finally clause<br>divide(“2”, “1”)<br>executing finally clause<br>Traceback (most recent call last):<br>  File “<stdin>“, line 1, in ?<br>  File “<stdin>“, line 3, in divide<br>TypeError: unsupported operand type(s) for /: ‘str’ and ‘str’</stdin></stdin></p>
</blockquote>
</blockquote>
</blockquote>
<h1 id="预定义的清理行为"><a href="#预定义的清理行为" class="headerlink" title="预定义的清理行为"></a>预定义的清理行为</h1><p>一些对象定义了标准的清理行为，无论系统是否成功的使用了它，一旦不需要它了，那么这个标准的清理行为就会执行。<br>下面这个例子展示了尝试打开一个文件，然后把内容打印到屏幕上:</p>
<p>for line in open(“myfile.txt”):<br>    print(line, end=””)<br>以上这段代码的问题是，当执行完毕后，文件会保持打开状态，并没有被关闭。</p>
<p>关键词 with 语句就可以保证诸如文件之类的对象在使用完之后一定会正确的执行他的清理方法:</p>
<p>with open(“myfile.txt”) as f:<br>    for line in f:<br>        print(line, end=””)<br>以上这段代码执行完毕后，就算在处理过程中出问题了，文件 f 总是会关闭。</p>
]]></content>
      <categories>
        <category>基础进阶</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>面向对象的编程思想和Python的类 访问 属性和继承-PYTHON</title>
    <url>/2020/05/17/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%9A%84%E7%BC%96%E7%A8%8B%E6%80%9D%E6%83%B3%E5%92%8CPython%E7%9A%84%E7%B1%BB-%E8%AE%BF%E9%97%AE-%E5%B1%9E%E6%80%A7%E5%92%8C%E7%BB%A7%E6%89%BF-PYTHON/</url>
    <content><![CDATA[<p>面向对象的编程思想和Python的类，类的方法和属性，实例方法；这次我将从面向对象的角度介绍类的定义、属性和自定义方法。</p>
<a id="more"></a>
<h1 id="一、访问权限"><a href="#一、访问权限" class="headerlink" title="一、访问权限"></a>一、访问权限</h1><p>Python中在类的内部定义属性和方法，在类的外部是可以直接调用或进行访问的，例如：</p>
<pre><code>from selenium import webdriver
import time
class Commonshare:
    url = &#39;https://mail.126.com/&#39;
    def __init__(self):#初始化浏览器
        self.driver=webdriver.Chrome()
        self.driver.maximize_window()
if __name__ == &#39;__main__&#39;:
    com = Commonshare()
    com.driver.get(com.url)</code></pre><p>url就是在类中定义的属性，在类的外部通过com的对象可以直接进行使用。因此Python中没有对属性和方法设置访问权限。为了保证类内部的某些属性不被外部访问，可以进行如下的访问限制：</p>
<p>1.<strong>url</strong> ：收尾双下划线表示定义特殊方法，一般是系统定义的方法</p>
<p>2._url: 在开头加单下划线表示保护类型的成员，仅允许类本身和子类进行访问。</p>
<pre><code>from selenium import webdriver
import time
class Commonshare:
    _url = &#39;https://mail.126.com/&#39;
    def __init__(self):#初始化浏览器
        self.driver=webdriver.Chrome()
        self.driver.maximize_window()
if __name__ == &#39;__main__&#39;:
    com = Commonshare()
    com.driver.get(com._url)</code></pre><p>从以上的运行结果可以得出：保护属性可以通过实例名访问</p>
<p>3.__url:双下划线表示（私有）类型的成员，只允许定义该方法的类本身进行访问，不能通过类的实例进行访问</p>
<pre><code>from selenium import webdriver
class Commonshare:
    __url = &#39;https://mail.126.com/&#39;
    def __init__(self):#初始化浏览器
        self.driver=webdriver.Chrome()
        self.driver.maximize_window()
        print(&#39;类内部的&#39;,Commonshare._url)
if __name__ == &#39;__main__&#39;:
    com = Commonshare()
    com.driver.get(com._Commonshare__url)#可以访问
    com.driver.get(com.__url)#不能访问</code></pre><p>从以上的结果可以看出：私有属性可以通过“类名.属性名”的方式访问，也可以通过”实例名.类名__url”访问。不能直接通过“实例名.属性名”访问。<br>上文中介绍实例属性，实例属性在方法体外，是无法访问的，但是我们又想访问怎么办呢？  </p>
<h1 id="二、属性"><a href="#二、属性" class="headerlink" title="二、属性"></a>二、属性</h1><p>（一）Python中，可通过@property（装饰器）将一个方法转为属性。转换后，可通过方法名来访问，不需要再加()访问。</p>
<pre><code>class Avg_Score():# 平均成绩类

    def __init__(self,num1,num2,num3):
        self.num1=num1 #英语成绩
        self.num2=num2 #语文成绩
        self.num3=num3 #数学成绩
    @property#将方法转换为属性
    def num_avg(self): #计算机求平均数的方法
        return (self.num3+self.num2+self.num1)/3 #返回平均成绩
avg=Avg_Score(60,50,90)#创建类的实例
print(&#39;三科成绩之和为：&#39;,avg.num_avg)#类的实例，调用属性，得到属性值</code></pre><p>不将方法转换成属性，如下，调用方法</p>
<pre><code>class Avg_Score():# 平均成绩类

    def __init__(self,num1,num2,num3):
        self.num1=num1 #英语成绩
        self.num2=num2 #语文成绩
        self.num3=num3 #数学成绩
    def num_avg(self): #计算机求平均数的方法
        return (self.num3+self.num2+self.num1)/3 #返回平均成绩
avg=Avg_Score(60,50,90)#创建类的实例
print(&#39;三科成绩之和为：&#39;,avg.num_avg())#调用实例方法，得到平均值</code></pre><p>（二）在Python中，类的属性或者实例，是可以在类体外修改的。@property将一个方法转为属性为只读属性，不能更改。</p>
<pre><code>class Avg_Score():# 平均成绩类
    def __init__(self,num1,num2,num3):
        self.num1=num1 #英语成绩
        self.num2=num2 #语文成绩
        self.num3=num3 #数学成绩
    @property#将方法转换为属性
    def num_avg(self): #计算机求平均数的方法
        return (self.num3+self.num2+self.num1)/3 #返回平均成绩
avg=Avg_Score(60,50,90)#创建类的实例
print(&#39;三科成绩之和为：&#39;,avg.num_avg)#类的实例，调用属性，得到属性值
avg.num1=3
print(avg.num_avg)
avg.num_avg=&#39;55&#39;#不能更改，出错
print(avg.num_avg)</code></pre><h1 id="三、继承"><a href="#三、继承" class="headerlink" title="三、继承"></a>三、继承</h1><p>继承是面向对象编程思想的重要特征之一，继承可以实现代码的重用，同时还可以进行类之间关系的梳理。</p>
<p>（一）继承的语法</p>
<p>class 类名（父类的类名）</p>
<p>（二）子类调用父类的方法实现如下：</p>
<pre><code>class Avg_Score():# 平均成绩类
    def __init__(self,num1,num2,num3):
        self.num1=num1 #英语成绩
        self.num2=num2 #语文成绩
        self.num3=num3 #数学成绩
    # @property#将方法转换为属性
    def num_avg(self): #计算机求平均数的方法
        return (self.num3+self.num2+self.num1)/3 #返回平均成绩

class Student_Sort(Avg_Score):#Student_Sort类继承了Avg_Score类，，
    pass
if __name__ == &#39;__main__&#39;:
    stu=Student_Sort(99,100,80)
    print(stu.num_avg())# Student_Sort可以直接调用Avg_Score类的方法</code></pre><p>（三）子类可以重写父类的方法</p>
<pre><code>class Avg_Score():# 平均成绩类
    def __init__(self,num1,num2,num3):
        self.num1=num1 #英语成绩
        self.num2=num2 #语文成绩
        self.num3=num3 #数学成绩
    # @property#将方法转换为属性
    def num_avg(self): #计算机求平均数的方法
        print((self.num3+self.num2+self.num1)/3 ) #返回平均成绩
class Student_Sort(Avg_Score):
    def num_avg(self):#重写父类的方法
        print(self.num1+self.num2)
if __name__ == &#39;__main__&#39;:
    stu=Student_Sort(99,100,80)
    stu.num_avg()#仅打印子类方法的结果</code></pre><p>注意重写的方法，调用该方法时不会再进行父类方法的调用和结果显示</p>
<p>四、子类调用父类的<strong>init</strong>()方法</p>
<pre><code>class Avg_Score():# 平均成绩类
    def __init__(self,num1,num2,num3):
        self.num1=num1 #英语成绩
        self.num2=num2 #语文成绩
        self.num3=num3 #数学成绩
    # @property#将方法转换为属性
    def num_avg(self): #计算机求平均数的方法
        print((self.num3+self.num2+self.num1)/3 ) #返回平均成绩
class Student_Sort(Avg_Score):
    def __init__(self):
        print(&quot;结果&quot;)
    # def num_avg(self):#重写父类的方法
    #     print(self.num1+self.num2)
if __name__ == &#39;__main__&#39;:
    stu=Student_Sort()
    stu.num_avg()</code></pre><p>当我们定义的属性在<strong>init</strong>()方法中时，子类同时改写了<strong>init</strong>()时，那么父类定义的方法中的属性就会找不到，出现程序错误。</p>
<p>（二）不重写<strong>init</strong>()方法，子类中的方法是可以直接使用父类的属性，例如：</p>
<pre><code>class Avg_Score():# 平均成绩类
    def __init__(self,num1,num2,num3):
        self.num1=num1 #英语成绩
        self.num2=num2 #语文成绩
        self.num3=num3 #数学成绩
    # @property#将方法转换为属性
    def num_avg(self): #计算机求平均数的方法
        print((self.num3+self.num2+self.num1)/3 ) #返回平均成绩
class Student_Sort(Avg_Score):

    def sum(self):
        print(self.num1+self.num2)#可以使用父类的属性。

if __name__ == &#39;__main__&#39;:
    stu=Student_Sort(78,89,58)
    stu.num_avg()</code></pre><p>（三）通过super()函数调用父类中的__init()方法</p>
<pre><code>class Avg_Score():# 平均成绩类
    def __init__(self,num1,num2,num3):
        self.num1=num1 #英语成绩
        self.num2=num2 #语文成绩
        self.num3=num3 #数学成绩
    def num_avg(self): #计算机求平均数的方法
        print((self.num3+self.num2+self.num1)/3 ) #返回平均成绩
class Student_Sort(Avg_Score):
    def __init__(self):
        print(&quot;结果&quot;)
        super().__init__(58,58,59)#调用父类的__init__()方法
if __name__ == &#39;__main__&#39;:
    stu=Student_Sort()
    stu.num_avg()</code></pre>]]></content>
      <categories>
        <category>代码案例</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>PyTorch专栏开篇</title>
    <url>/2020/07/02/Pytorch%E4%B8%93%E6%A0%8F%E5%BC%80%E7%AF%87/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>目前研究人员正在使用的深度学习框架不尽相同，有TensorFlow、PyTorch、Keras等，这些深度学习框架被应用于计算机视觉、语音识别、自然语言处理与生物信息学等领域，并获得了极好的效果。其中PyTorch是当前难得的简洁优雅且高效快速的框架，当前开源的框架中，没有哪一个框架能够在灵活性、易用性、速度这三个方面有两个能够同时超过PyTorch。<a id="more"></a><br>因此在接下来的时间里 我会给大家带来关于PyTorch的专栏。<br>这个专栏主要是针对想要学习Pytorch的学生群体或者深度学习爱好者。通过专栏的学习能力，能够实现零基础想要了解深度学习，降低自学难度，快速学习PyTorch。</p>
<h1 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h1><p>PyTorch是一个基于Torch的Python开源机器学习库，用于自然语言处理等应用程序。它主要由Facebookd的人工智能小组开发，不仅能够 实现强大的GPU加速，同时还支持动态神经网络，这一点是现在很多主流框架如TensorFlow都不支持的。PyTorch提供了两个高级功能：<br>具有强大的GPU加速的张量计算（如Numpy）<br>包含自动求导系统的深度神经网络</p>
<p>除了Facebook之外，Twitter、GMU和Salesforce等机构都采用了PyTorch。</p>
<p>官方教程包含了 PyTorch 介绍，安装教程；60分钟快速入门教程，可以迅速从小白阶段完成一个分类器模型；计算机视觉常用模型，方便基于自己的数据进行调整，不再需要从头开始写；自然语言处理模型，聊天机器人，文本生成等生动有趣的项目。</p>
<p>总而言之：<br>如果你想了解一下 PyTorch，可以看介绍部分。<br>如果你想快速入门 PyTorch，可以看60分钟快速入门。<br>如果你想解决计算机视觉问题，可以看计算机视觉部分。<br>如果你想解决自然语言处理问题，可以看NLP 部分。<br>后续会更新强化学习和生成对抗网络部分内容。</p>
<h1 id="专栏目录"><a href="#专栏目录" class="headerlink" title="专栏目录"></a>专栏目录</h1><p>第一章：PyTorch之简介与下载<br>PyTorch简介<br>PyTorch环境搭建</p>
<p>第二章：PyTorch之60min入门<br>PyTorch 入门<br>PyTorch 自动微分<br>PyTorch 神经网络<br>PyTorch 图像分类器<br>PyTorch 数据并行处理</p>
<p>第三章：PyTorch之入门强化<br>数据加载和处理<br>PyTorch小试牛刀<br>迁移学习<br>混合前端的seq2seq模型部署<br>保存和加载模型</p>
<p>第四章：PyTorch之图像篇<br>微调基于torchvision 0.3的目标检测模型<br>微调TorchVision模型<br>空间变换器网络<br>使用PyTorch进行Neural-Transfer<br>生成对抗示例<br>使用ONNX将模型转移至Caffe2和移动端</p>
<p>第五章：PyTorch之文本篇<br>聊天机器人教程<br>使用字符级RNN生成名字<br>使用字符级RNN进行名字分类<br>在深度学习和NLP中使用Pytorch<br>使用Sequence2Sequence网络和注意力进行翻译</p>
<p>第六章：PyTorch之生成对抗网络</p>
<p>第七章：PyTorch之强化学习</p>
<h1 id="更新时间"><a href="#更新时间" class="headerlink" title="更新时间"></a>更新时间</h1><p>更新频率：一周四篇<br>开始时间：下周开始</p>
<h1 id="学习交流"><a href="#学习交流" class="headerlink" title="学习交流"></a>学习交流</h1><p>为了方便大家更好地与作者进行沟通交流，为此针对这个专栏成立了QQ读者交流群，大家想近距离与我沟通，都可以来加入。</p>
<p>加入方式：扫描下方QQ群二维码，即可加入交流群&lt;群满可在右下方在线与我沟通&gt;。</p>
<p align="left">
    <img src= "/img/loading.gif" data-src="/images/qun.jpg" alt="Sample" width="300" height="350">
    <!-- <img src= "/img/loading.gif" data-src="/images/TIM.jpg" alt="Sample"  width="300" height="250"> -->
</p>
]]></content>
      <categories>
        <category>PyTorch专栏</category>
      </categories>
      <tags>
        <tag>Python深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch专栏（一）</title>
    <url>/2020/07/03/Pytorch%E4%B8%93%E6%A0%8F%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>本片将文章讲解了专栏的第一章简单介绍了PyTorch的环境搭建，希望对大家有所帮助。想要学习更多深度学习机器学习的朋友们可以扫上一篇文章落脚的二维码进群探讨学习。欢迎大家推广此链接至需要的朋友们！<a id="more"></a>  </p>
<h1 id="PyTorch简介"><a href="#PyTorch简介" class="headerlink" title="PyTorch简介"></a>PyTorch简介</h1><p>PyTorch是一个基于Torch的Python开源机器学习库，用于自然语言处理等应用程序。它主要由Facebookd的人工智能小组开发，不仅能够实现强大的GPU加速，同时还支持动态神经网络，这一点是现在很多主流框架如TensorFlow都不支持的。PyTorch提供了两个高级功能：<br>1、具有强大的GPU加速的张量计算（如Numpy）<br>2、包含自动求导系统的深度神经网络<br>除了Facebook之外，Twitter、GMU和Salesforce等机构都采用了PyTorch。<br>TensorFlow和Caffe都是命令式的编程语言，而且是静态的，首先必须构建一个神经网络，然后一次又一次使用相同的结构，如果想要改变网络的结构，就必须从头开始。但是对于PyTorch，通过反向求导技术，可以让你零延迟地任意改变神经网络的行为，而且其实现速度快。正是这一灵活性是PyTorch对比TensorFlow的最大优势。<br>另外，PyTorch的代码对比TensorFlow而言，更加简洁直观，底层代码也更容易看懂，这对于使用它的人来说理解底层肯定是一件令人激动的事。</p>
<h1 id="PyTorch的优点："><a href="#PyTorch的优点：" class="headerlink" title="PyTorch的优点："></a>PyTorch的优点：</h1><p>1、支持GPU<br>2、灵活，支持动态神经网络<br>3、底层代码易于理解<br>4、命令式体验<br>5、自定义扩展<br>当然，现今任何一个深度学习框架都有其缺点，PyTorch也不例外，对比TensorFlow，其全面性处于劣势，目前PyTorch还不支持快速傅里叶、沿维翻转张量和检查无穷与非数值张量；针对移动端、嵌入式部署以及高性能服务器端的部署其性能表现有待提升；其次因为这个框架较新，使得他的社区没有那么强大，在文档方面其C库大多数没有文档。</p>
<h1 id="安装Anaconda-3-5"><a href="#安装Anaconda-3-5" class="headerlink" title="安装Anaconda 3.5"></a>安装Anaconda 3.5</h1><p>Anaconda是一个用于科学计算的Python发行版，支持Linux、Mac和Window系统，提供了包管理与环境管理的功能，可以很方便地解决Python并存、切换，以及各种第三方包安装的问题。</p>
<h1 id="下载："><a href="#下载：" class="headerlink" title="下载："></a>下载：</h1><p>直接从 Anaconda官网下载，但因为Anaconda的服务器在国外，所以下载速度会很慢，这里推荐使用清华的镜像来下载。选择合适你的版本下载，我这里选择Anaconda3-5.1.0-Windows-x86_64.exe</p>
<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>下载之后，点击安装即可，步骤依次如下：<br><img src= "/img/loading.gif" data-src="/images/p1.jpg"><br><img src= "/img/loading.gif" data-src="/images/p2.jpg"><br><img src= "/img/loading.gif" data-src="/images/p3.jpg"><br><img src= "/img/loading.gif" data-src="/images/p4.jpg"><br><img src= "/img/loading.gif" data-src="/images/p5.jpg"><br><img src= "/img/loading.gif" data-src="/images/p6.jpg"><br><img src= "/img/loading.gif" data-src="/images/p7.jpg"><br><img src= "/img/loading.gif" data-src="/images/p8.jpg"><br>安装完成后，进行Anaconda的环境变量配置，打开控制面板-&gt;高级系统设置-&gt;环境变量-&gt;系统变量找到Path，点击编辑，加入三个文件夹的存储路径（注意三个路径之间需用分号隔开）</p>
<h1 id="安装PyTorch-amp-torchvision"><a href="#安装PyTorch-amp-torchvision" class="headerlink" title="安装PyTorch &amp; torchvision"></a>安装PyTorch &amp; torchvision</h1><p>命令获取<br>进入 PyTorch官网，依次选择你电脑的配置（我这里已经下载了python3.7），这里提供使用pip和conda两种环境下安装的步骤截图<br>(1)使用pip：windows+pip+python3.7+None<br><img src= "/img/loading.gif" data-src="/images/p9.jpg"><br>拷贝给出的命令在cmd下运行<br><img src= "/img/loading.gif" data-src="/images/p10.jpg"><br>(2)使用conda：windows+conda+python3.7+None<br><img src= "/img/loading.gif" data-src="/images/p11.jpg"><br>拷贝给出的命令在cmd下运行<br><img src= "/img/loading.gif" data-src="/images/p12.jpg"></p>
<h1 id="安装成功"><a href="#安装成功" class="headerlink" title="安装成功"></a>安装成功</h1><pre><code>import torch
torch.__version__
显示版本号、不报错就说明安装成功了</code></pre><p>至此PyTorch1.0 &amp; Anaconda3.5已经安装成功。</p>
<h1 id="学习交流"><a href="#学习交流" class="headerlink" title="学习交流"></a>学习交流</h1><p>为了方便大家更好地与作者进行沟通交流，为此针对这个专栏成立了QQ读者交流群，大家想近距离与我沟通，都可以来加入。</p>
<p>加入方式：扫描下方QQ群二维码，即可加入交流群&lt;群满可在右下方在线与我沟通&gt;。</p>
<p align="left">
    <img src= "/img/loading.gif" data-src="/images/qun.jpg" alt="Sample" width="300" height="350">
    <!-- <img src= "/img/loading.gif" data-src="/images/TIM.jpg" alt="Sample"  width="300" height="250"> -->
</p>]]></content>
      <categories>
        <category>PyTorch专栏</category>
      </categories>
      <tags>
        <tag>Python深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch专栏（二）</title>
    <url>/2020/07/06/Pytorch%E4%B8%93%E6%A0%8F%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>本篇文章讲解了PyTorch专栏的第二章中的PyTorch 自动微分和PyTorch 神经网络，查看第二章中的其他内容，请点击查看专栏目录里相应的内容，希望对大家有所帮助。查看关于本专栏的介绍：PyTorch专栏开篇。<a id="more"></a>  </p>
<h1 id="PyTorch之60min入门"><a href="#PyTorch之60min入门" class="headerlink" title="PyTorch之60min入门"></a>PyTorch之60min入门</h1><h1 id="PyTorch-自动微分"><a href="#PyTorch-自动微分" class="headerlink" title="PyTorch 自动微分"></a>PyTorch 自动微分</h1><p>autograd 包是 PyTorch 中所有神经网络的核心。首先让我们简要地介绍它，然后我们将会去训练我们的第一个神经网络。该 autograd 软件包为 Tensors 上的所有操作提供自动微分。它是一个由运行定义的框架，这意味着以代码运行方式定义你的后向传播，并且每次迭代都可以不同。我们从 tensor 和 gradients 来举一些例子。</p>
<h1 id="1、TENSOR"><a href="#1、TENSOR" class="headerlink" title="1、TENSOR"></a>1、TENSOR</h1><p>torch.Tensor 是包的核心类。如果将其属性 .requires_grad 设置为 True，则会开始跟踪针对 tensor 的所有操作。完成计算后，您可以调用 .backward() 来自动计算所有梯度。该张量的梯度将累积到 .grad 属性中。</p>
<p>要停止 tensor 历史记录的跟踪，您可以调用 .detach()，它将其与计算历史记录分离，并防止将来的计算被跟踪。</p>
<p>要停止跟踪历史记录（和使用内存），您还可以将代码块使用 with torch.no_grad(): 包装起来。在评估模型时，这是特别有用，因为模型在训练阶段具有 requires_grad = True 的可训练参数有利于调参，但在评估阶段我们不需要梯度。</p>
<p>还有一个类对于 autograd 实现非常重要那就是 Function。Tensor 和 Function 互相连接并构建一个非循环图，它保存整个完整的计算过程的历史信息。每个张量都有一个 .grad_fn 属性保存着创建了张量的 Function 的引用，（如果用户自己创建张量，则g rad_fn 是 None ）。</p>
<p>如果你想计算导数，你可以调用 Tensor.backward()。如果 Tensor 是标量（即它包含一个元素数据），则不需要指定任何参数backward()，但是如果它有更多元素，则需要指定一个gradient 参数来指定张量的形状。</p>
<pre><code>import torch</code></pre><p>创建一个张量，设置 requires_grad=True 来跟踪与它相关的计算</p>
<pre><code>x = torch.ones(2, 2, requires_grad=True)
print(x)</code></pre><p>输出：</p>
<pre><code>tensor([[1., 1.],
        [1., 1.]], requires_grad=True)</code></pre><p>针对张量做一个操作</p>
<pre><code>y = x + 2
print(y)</code></pre><p>输出：</p>
<pre><code>tensor([[3., 3.],
        [3., 3.]], grad_fn=&lt;AddBackward0&gt;)</code></pre><p>y 作为操作的结果被创建，所以它有 grad_fn</p>
<pre><code>print(y.grad_fn)</code></pre><p>输出：</p>
<pre><code>&lt;AddBackward0 object at 0x7fe1db427470&gt;</code></pre><p>针对 y 做更多的操作：</p>
<pre><code>z = y * y * 3
out = z.mean()

print(z, out)</code></pre><p>输出：</p>
<pre><code>tensor([[27., 27.],
        [27., 27.]], grad_fn=&lt;MulBackward0&gt;) tensor(27., grad_fn=&lt;MeanBackward0&gt;)</code></pre><p>.requires_grad_(…) 会改变张量的requires_gra 标记。输入的标记默认为False ，如果没有提供相应的参数。</p>
<pre><code>a = torch.randn(2, 2)
a = ((a * 3) / (a - 1))
print(a.requires_grad)
a.requires_grad_(True)
print(a.requires_grad)
b = (a * a).sum()
print(b.grad_fn)</code></pre><p>输出：</p>
<pre><code>False
True
&lt;SumBackward0 object at 0x7fe1db427dd8&gt;</code></pre><p>梯度：</p>
<p>我们现在后向传播，因为输出包含了一个标量，out.backward() 等同于out.backward(torch.tensor(1.))。</p>
<pre><code>out.backward()</code></pre><p>打印梯度  d(out)/dx</p>
<pre><code>print(x.grad)</code></pre><p>输出：</p>
<pre><code>tensor([[4.5000, 4.5000],
        [4.5000, 4.5000]])</code></pre><p>原理解释：<br><img src= "/img/loading.gif" data-src="/images/p13.jpg"></p>
<p>现在让我们看一个雅可比向量积的例子：</p>
<pre><code>x = torch.randn(3, requires_grad=True)

y = x * 2
while y.data.norm() &lt; 1000:
    y = y * 2

print(y)</code></pre><p>输出：</p>
<pre><code>tensor([ -444.6791,   762.9810, -1690.0941], grad_fn=&lt;MulBackward0&gt;)</code></pre><p>现在在这种情况下，y 不再是一个标量。torch.autograd 不能够直接计算整个雅可比，但是如果我们只想要雅可比向量积，只需要简单的传递向量给 backward 作为参数。</p>
<pre><code>v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)
y.backward(v)

print(x.grad)</code></pre><p>输出：</p>
<pre><code>tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])</code></pre><p>你可以通过将代码包裹在 with torch.no_grad()，来停止对从跟踪历史中 的 .requires_grad=True 的张量自动求导。</p>
<pre><code>print(x.requires_grad)
print((x ** 2).requires_grad)

with torch.no_grad():
    print((x ** 2).requires_grad)</code></pre><p>输出：</p>
<pre><code>True
True
False</code></pre><p>下载 Python 源代码：</p>
<pre><code>autograd_tutorial.py</code></pre><p>下载 Jupyter 源代码：</p>
<pre><code>autograd_tutorial.ipynb</code></pre><h1 id="PyTorch神经网络"><a href="#PyTorch神经网络" class="headerlink" title="PyTorch神经网络"></a>PyTorch神经网络</h1><p>神经网络可以通过 torch.nn 包来构建。</p>
<p>现在对于自动梯度(autograd)有一些了解，神经网络是基于自动梯度 (autograd)来定义一些模型。一个 nn.Module 包括层和一个方法 forward(input) 它会返回输出(output)。</p>
<p>例如，看一下数字图片识别的网络:<br><img src= "/img/loading.gif" data-src="/images/p14.jpg"><br>这是一个简单的前馈神经网络，它接收输入，让输入一个接着一个的通过一些层，最后给出输出。</p>
<p>一个典型的神经网络训练过程包括以下几点：</p>
<p>1.定义一个包含可训练参数的神经网络</p>
<p>2.迭代整个输入</p>
<p>3.通过神经网络处理输入</p>
<p>4.计算损失(loss)</p>
<p>5.反向传播梯度到神经网络的参数</p>
<p>6.更新网络的参数，典型的用一个简单的更新方法：weight = weight - learning_rate *gradient</p>
<p>定义神经网络</p>
<pre><code>import torch
import torch.nn as nn
import torch.nn.functional as F


class Net(nn.Module):

    def __init__(self):
        super(Net, self).__init__()
        # 1 input image channel, 6 output channels, 5x5 square convolution
        # kernel
        self.conv1 = nn.Conv2d(1, 6, 5)
        self.conv2 = nn.Conv2d(6, 16, 5)
        # an affine operation: y = Wx + b
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        # Max pooling over a (2, 2) window
        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))
        # If the size is a square you can only specify a single number
        x = F.max_pool2d(F.relu(self.conv2(x)), 2)
        x = x.view(-1, self.num_flat_features(x))
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x

    def num_flat_features(self, x):
        size = x.size()[1:]  # all dimensions except the batch dimension
        num_features = 1
        for s in size:
            num_features *= s
        return num_features


net = Net()
print(net)</code></pre><p>输出:</p>
<pre><code>Net(
  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)</code></pre><p>你刚定义了一个前馈函数，然后反向传播函数被自动通过 autograd 定义了。你可以使用任何张量操作在前馈函数上。</p>
<p>一个模型可训练的参数可以通过调用 net.parameters() 返回：</p>
<pre><code>params = list(net.parameters())
print(len(params))
print(params[0].size())  # conv1&#39;s .weight</code></pre><p>输出：</p>
<pre><code>10
torch.Size([6, 1, 5, 5])</code></pre><p>让我们尝试随机生成一个 32x32 的输入。注意：期望的输入维度是 32x32 。为了使用这个网络在 MNIST 数据及上，你需要把数据集中的图片维度修改为 32x32。</p>
<pre><code>input = torch.randn(1, 1, 32, 32)
out = net(input)
print(out)</code></pre><p>输出：</p>
<pre><code>tensor([[-0.0233,  0.0159, -0.0249,  0.1413,  0.0663,  0.0297, -0.0940, -0.0135,
          0.1003, -0.0559]], grad_fn=&lt;AddmmBackward&gt;)</code></pre><p>把所有参数梯度缓存器置零，用随机的梯度来反向传播</p>
<pre><code>net.zero_grad()
out.backward(torch.randn(1, 10))</code></pre><p>在继续之前，让我们复习一下所有见过的类。</p>
<pre><code>torch.Tensor - A multi-dimensional array with support for autograd operations like backward(). Also holds the gradient w.r.t. the tensor.
nn.Module - Neural network module. Convenient way of encapsulating parameters, with helpers for moving them to GPU, exporting, loading, etc.
nn.Parameter - A kind of Tensor, that is automatically registered as a parameter when assigned as an attribute to a Module.
autograd.Function - Implements forward and backward definitions of an autograd operation. Every Tensor operation, creates at least a single Function node, that connects to functions that created a Tensor and encodes its history.</code></pre><p>在此，我们完成了：</p>
<p>1.定义一个神经网络</p>
<p>2.处理输入以及调用反向传播</p>
<p>还剩下：</p>
<p>1.计算损失值</p>
<p>2.更新网络中的权重</p>
<p>损失函数</p>
<p>一个损失函数需要一对输入：模型输出和目标，然后计算一个值来评估输出距离目标有多远。</p>
<p>有一些不同的损失函数在 nn 包中。一个简单的损失函数就是 nn.MSELoss ，这计算了均方误差。</p>
<p>例如：</p>
<pre><code>output = net(input)
target = torch.randn(10)  # a dummy target, for example
target = target.view(1, -1)  # make it the same shape as output
criterion = nn.MSELoss()

loss = criterion(output, target)
print(loss)</code></pre><p>输出：</p>
<pre><code>tensor(1.3389, grad_fn=&lt;MseLossBackward&gt;)</code></pre><p>现在，如果你跟随损失到反向传播路径，可以使用它的 .grad_fn 属性，你将会看到一个这样的计算图：</p>
<pre><code>input -&gt; conv2d -&gt; relu -&gt; maxpool2d -&gt; conv2d -&gt; relu -&gt; maxpool2d
      -&gt; view -&gt; linear -&gt; relu -&gt; linear -&gt; relu -&gt; linear
      -&gt; MSELoss
      -&gt; loss</code></pre><p>所以，当我们调用 loss.backward()，整个图都会微分，而且所有的在图中的requires_grad=True 的张量将会让他们的 grad 张量累计梯度。</p>
<p>为了演示，我们将跟随以下步骤来反向传播。</p>
<pre><code>print(loss.grad_fn)  # MSELoss
print(loss.grad_fn.next_functions[0][0])  # Linear
print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU</code></pre><p>输出：</p>
<pre><code>&lt;MseLossBackward object at 0x7fab77615278&gt;
&lt;AddmmBackward object at 0x7fab77615940&gt;
&lt;AccumulateGrad object at 0x7fab77615940&gt;</code></pre><p>反向传播</p>
<p>为了实现反向传播损失，我们所有需要做的事情仅仅是使用 loss.backward()。你需要清空现存的梯度，要不然帝都将会和现存的梯度累计到一起。</p>
<p>现在我们调用 loss.backward() ，然后看一下 con1 的偏置项在反向传播之前和之后的变化。</p>
<pre><code>net.zero_grad()     # zeroes the gradient buffers of all parameters

print(&#39;conv1.bias.grad before backward&#39;)
print(net.conv1.bias.grad)

loss.backward()

print(&#39;conv1.bias.grad after backward&#39;)
print(net.conv1.bias.grad)</code></pre><p>输出：</p>
<pre><code>conv1.bias.grad before backward
tensor([0., 0., 0., 0., 0., 0.])
conv1.bias.grad after backward
tensor([-0.0054,  0.0011,  0.0012,  0.0148, -0.0186,  0.0087])</code></pre><p>现在我们看到了，如何使用损失函数。</p>
<p>唯一剩下的事情就是更新神经网络的参数。</p>
<p>更新神经网络参数：</p>
<p>最简单的更新规则就是随机梯度下降。</p>
<pre><code>weight = weight - learning_rate * gradient</code></pre><p>我们可以使用 python 来实现这个规则：</p>
<pre><code>learning_rate = 0.01
for f in net.parameters():
    f.data.sub_(f.grad.data * learning_rate)</code></pre><p>尽管如此，如果你是用神经网络，你想使用不同的更新规则，类似于 SGD, Nesterov-SGD, Adam, RMSProp, 等。为了让这可行，我们建立了一个小包：torch.optim 实现了所有的方法。使用它非常的简单。</p>
<pre><code>import torch.optim as optim

# create your optimizer
optimizer = optim.SGD(net.parameters(), lr=0.01)

# in your training loop:
optimizer.zero_grad()   # zero the gradient buffers
output = net(input)
loss = criterion(output, target)
loss.backward()
optimizer.step()    # Does the update</code></pre><p>下载 Python 源代码：</p>
<pre><code>neural_networks_tutorial.py</code></pre><p>下载 Jupyter 源代码：</p>
<pre><code>neural_networks_tutorial.ipynb</code></pre><h1 id="学习交流"><a href="#学习交流" class="headerlink" title="学习交流"></a>学习交流</h1><p>为了方便大家更好地与作者进行沟通交流，为此针对这个专栏成立了QQ读者交流群，大家想近距离与我沟通，都可以来加入。<br>扫描二维码进群可获得 自动微分 章节的Python 源代码和Jupyter 源代码链接<br>扫描二维码进群可获得 神经网络 章节的Python 源代码和Jupyter 源代码链接<br>加入方式：扫描下方QQ群二维码，即可加入交流群&lt;群满可在右下方在线与我沟通&gt;。</p>
<p align="left">
    <img src= "/img/loading.gif" data-src="/images/qun.jpg" alt="Sample" width="300" height="350">
    <!-- <img src= "/img/loading.gif" data-src="/images/TIM.jpg" alt="Sample"  width="300" height="250"> -->
</p>]]></content>
      <categories>
        <category>PyTorch专栏</category>
      </categories>
      <tags>
        <tag>Python深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>PyTorch专栏（三）</title>
    <url>/2020/07/10/PyTorch%E4%B8%93%E6%A0%8F%EF%BC%88%E4%B8%89%EF%BC%89/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>本篇文章讲解了PyTorch专栏的第三章中的数据加载与预处理。查看专栏历史文章，请点击下方推荐链接进入相应链接阅读。查看关于本专栏的介绍：PyTorch专栏开篇。</p>
<a id="more"></a>  
<h1 id="PyTorch之数据加载和处理"><a href="#PyTorch之数据加载和处理" class="headerlink" title="PyTorch之数据加载和处理"></a>PyTorch之数据加载和处理</h1><p>PyTorch提供了许多工具来简化和希望数据加载，使代码更具可读性。  </p>
<h2 id="下载安装包"><a href="#下载安装包" class="headerlink" title="下载安装包"></a>下载安装包</h2><p>scikit-image：用于图像的IO和变换<br>pandas：用于更容易地进行csv解析</p>
<pre><code>from __future__ import print_function, division
import os
import torch
import pandas as pd #用于更容易地进行csv解析
from skimage import io, transform #用于图像的IO和变换
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, utils

# 忽略警告
import warnings
warnings.filterwarnings(&quot;ignore&quot;)

plt.ion() # interactive mode</code></pre><h1 id="下载数据集"><a href="#下载数据集" class="headerlink" title="下载数据集"></a>下载数据集</h1><p>从此处(<a href="https://download.pytorch.org/tutorial/faces.zip)下载数据集，数据存于“data" target="_blank" rel="noopener">https://download.pytorch.org/tutorial/faces.zip)下载数据集，数据存于“data</a> / faces /”的目录中。这个数据集实际上是imagenet数据集标注为face的图片当中在 dlib 面部检测(dlib’s pose estimation) 表现良好的图片。我们要处理的是一个面部姿态的数据集。也就是按如下方式标注的人脸:<br><img src= "/img/loading.gif" data-src="/images/p15.jpg"></p>
<h2 id="数据集注释"><a href="#数据集注释" class="headerlink" title="数据集注释"></a>数据集注释</h2><p>数据集是按如下规则打包成的csv文件:</p>
<pre><code>image_name,part_0_x,part_0_y,part_1_x,part_1_y,part_2_x, ... ,part_67_x,part_67_y
0805personali01.jpg,27,83,27,98, ... 84,134
1084239450_e76e00b7e7.jpg,70,236,71,257, ... ,128,312</code></pre><h1 id="读取数据集"><a href="#读取数据集" class="headerlink" title="读取数据集"></a>读取数据集</h1><p>将csv中的标注点数据读入（N，2）数组中，其中N是特征点的数量。读取数据代码如下：</p>
<pre><code>landmarks_frame = pd.read_csv(&#39;data/faces/face_landmarks.csv&#39;)

n = 65
img_name = landmarks_frame.iloc[n, 0]
landmarks = landmarks_frame.iloc[n, 1:].as_matrix()
landmarks = landmarks.astype(&#39;float&#39;).reshape(-1, 2)

print(&#39;Image name: {}&#39;.format(img_name))
print(&#39;Landmarks shape: {}&#39;.format(landmarks.shape))
print(&#39;First 4 Landmarks: {}&#39;.format(landmarks[:4]))</code></pre><h1 id="数据结果"><a href="#数据结果" class="headerlink" title="数据结果"></a>数据结果</h1><p>输出：</p>
<pre><code>Image name: person-7.jpg
Landmarks shape: (68, 2)
First 4 Landmarks: [[32. 65.]
 [33. 76.]
 [34. 86.]
 [34. 97.]]</code></pre><h1 id="编写函数"><a href="#编写函数" class="headerlink" title="编写函数"></a>编写函数</h1><p>写一个简单的函数来展示一张图片和它对应的标注点作为例子。</p>
<pre><code>def show_landmarks(image, landmarks):
    &quot;&quot;&quot;显示带有地标的图片&quot;&quot;&quot;
    plt.imshow(image)
    plt.scatter(landmarks[:, 0], landmarks[:, 1], s=10, marker=&#39;.&#39;, c=&#39;r&#39;)
    plt.pause(0.001)  # pause a bit so that plots are updated

plt.figure()
show_landmarks(io.imread(os.path.join(&#39;data/faces/&#39;, img_name)),
               landmarks)
plt.show()</code></pre><p>函数展示结果如下图所示:<br><img src= "/img/loading.gif" data-src="/images/p16.jpg"></p>
<h1 id="数据集类"><a href="#数据集类" class="headerlink" title="数据集类"></a>数据集类</h1><p>torch.utils.data.Dataset是表示数据集的抽象类，因此自定义数据集应继承Dataset并覆盖以下方法</p>
<p>len 实现 len(dataset) 返还数据集的尺寸。<br>getitem用来获取一些索引数据，例如 dataset[i] 中的(i)。</p>
<h2 id="建立数据集类"><a href="#建立数据集类" class="headerlink" title="建立数据集类"></a>建立数据集类</h2><p>为面部数据集创建一个数据集类。我们将在 <strong>init</strong>中读取csv的文件内容，在 <strong>getitem</strong>中读取图片。这么做是为了节省内存<br>空间。只有在需要用到图片的时候才读取它而不是一开始就把图片全部存进内存里。</p>
<p>我们的数据样本将按这样一个字典{‘image’: image, ‘landmarks’: landmarks}组织。我们的数据集类将添加一个可选参数transform<br>以方便对样本进行预处理。下一节我们会看到什么时候需要用到transform参数。<br><strong>init</strong>方法如下图所示：</p>
<pre><code>class FaceLandmarksDataset(Dataset):
    &quot;&quot;&quot;面部标记数据集.&quot;&quot;&quot;

    def __init__(self, csv_file, root_dir, transform=None):
        &quot;&quot;&quot;
        csv_file（string）：带注释的csv文件的路径。
        root_dir（string）：包含所有图像的目录。
        transform（callable， optional）：一个样本上的可用的可选变换
        &quot;&quot;&quot;
        self.landmarks_frame = pd.read_csv(csv_file)
        self.root_dir = root_dir
        self.transform = transform

    def __len__(self):
        return len(self.landmarks_frame)

    def __getitem__(self, idx):
        img_name = os.path.join(self.root_dir,
                                self.landmarks_frame.iloc[idx, 0])
        image = io.imread(img_name)
        landmarks = self.landmarks_frame.iloc[idx, 1:]
        landmarks = np.array([landmarks])
        landmarks = landmarks.astype(&#39;float&#39;).reshape(-1, 2)
        sample = {&#39;image&#39;: image, &#39;landmarks&#39;: landmarks}

        if self.transform:
            sample = self.transform(sample)

        return sample</code></pre><h1 id="数据可视化"><a href="#数据可视化" class="headerlink" title="数据可视化"></a>数据可视化</h1><p>实例化这个类并遍历数据样本。我们将会打印出前四个例子的尺寸并展示标注的特征点。<br>代码如下图所示：</p>
<pre><code>face_dataset = FaceLandmarksDataset(csv_file=&#39;data/faces/face_landmarks.csv&#39;,
                                    root_dir=&#39;data/faces/&#39;)

fig = plt.figure()

for i in range(len(face_dataset)):
    sample = face_dataset[i]

    print(i, sample[&#39;image&#39;].shape, sample[&#39;landmarks&#39;].shape)

    ax = plt.subplot(1, 4, i + 1)
    plt.tight_layout()
    ax.set_title(&#39;Sample #{}&#39;.format(i))
    ax.axis(&#39;off&#39;)
    show_landmarks(**sample)

    if i == 3:
        plt.show()
        break</code></pre><p>数据结果：</p>
<h2 id="图形展示结果"><a href="#图形展示结果" class="headerlink" title="图形展示结果"></a>图形展示结果</h2><img src= "/img/loading.gif" data-src="/images/p17.jpg">
控制台输出结果:
```
0 (324, 215, 3) (68, 2)
1 (500, 333, 3) (68, 2)
2 (250, 258, 3) (68, 2)
3 (434, 290, 3) (68, 2)
```
# 数据变换

<p>通过上面的例子我们会发现图片并不是同样的尺寸。绝大多数神经网络都假定图片的尺寸相同。因此我们需要做一些预处理。让我们创建三个转换:</p>
<p>Rescale：缩放图片<br>RandomCrop：对图片进行随机裁剪。这是一种数据增强操作<br>ToTensor：把numpy格式图片转为torch格式图片 (我们需要交换坐标轴).<br>我们会把它们写成可调用的类的形式而不是简单的函数，这样就不需要每次调用时传递一遍参数。我们只需要实现<strong>call</strong>方法，必<br>要的时候实现 <strong>init</strong>方法。我们可以这样调用这些转换:</p>
<pre><code>tsfm = Transform(params)
transformed_sample = tsfm(sample)</code></pre><p>观察下面这些转换是如何应用在图像和标签上的。</p>
<pre><code>class Rescale(object):
    &quot;&quot;&quot;将样本中的图像重新缩放到给定大小。.

    Args:
        output_size（tuple或int）：所需的输出大小。 如果是元组，则输出为
         与output_size匹配。 如果是int，则匹配较小的图像边缘到output_size保持纵横比相同。
    &quot;&quot;&quot;

    def __init__(self, output_size):
        assert isinstance(output_size, (int, tuple))
        self.output_size = output_size

    def __call__(self, sample):
        image, landmarks = sample[&#39;image&#39;], sample[&#39;landmarks&#39;]

        h, w = image.shape[:2]
        if isinstance(self.output_size, int):
            if h &gt; w:
                new_h, new_w = self.output_size * h / w, self.output_size
            else:
                new_h, new_w = self.output_size, self.output_size * w / h
        else:
            new_h, new_w = self.output_size

        new_h, new_w = int(new_h), int(new_w)

        img = transform.resize(image, (new_h, new_w))

        # h and w are swapped for landmarks because for images,
        # x and y axes are axis 1 and 0 respectively
        landmarks = landmarks * [new_w / w, new_h / h]

        return {&#39;image&#39;: img, &#39;landmarks&#39;: landmarks}


class RandomCrop(object):
    &quot;&quot;&quot;随机裁剪样本中的图像.

    Args:
       output_size（tuple或int）：所需的输出大小。 如果是int，方形裁剪是。         
    &quot;&quot;&quot;

    def __init__(self, output_size):
        assert isinstance(output_size, (int, tuple))
        if isinstance(output_size, int):
            self.output_size = (output_size, output_size)
        else:
            assert len(output_size) == 2
            self.output_size = output_size

    def __call__(self, sample):
        image, landmarks = sample[&#39;image&#39;], sample[&#39;landmarks&#39;]

        h, w = image.shape[:2]
        new_h, new_w = self.output_size

        top = np.random.randint(0, h - new_h)
        left = np.random.randint(0, w - new_w)

        image = image[top: top + new_h,
                      left: left + new_w]

        landmarks = landmarks - [left, top]

        return {&#39;image&#39;: image, &#39;landmarks&#39;: landmarks}


class ToTensor(object):
    &quot;&quot;&quot;将样本中的ndarrays转换为Tensors.&quot;&quot;&quot;

    def __call__(self, sample):
        image, landmarks = sample[&#39;image&#39;], sample[&#39;landmarks&#39;]

        # 交换颜色轴因为
        # numpy包的图片是: H * W * C
        # torch包的图片是: C * H * W
        image = image.transpose((2, 0, 1))
        return {&#39;image&#39;: torch.from_numpy(image),
                &#39;landmarks&#39;: torch.from_numpy(landmarks)}</code></pre><h1 id="组合转换"><a href="#组合转换" class="headerlink" title="组合转换"></a>组合转换</h1><p>接下来我们把这些转换应用到一个例子上。</p>
<p>我们想要把图像的短边调整为256，然后随机裁剪(randomcrop)为224大小的正方形。也就是说，我们打算组合一个Rescale和RandomCrop的变换。我们可以调用一个简单的类 torchvision.transforms.Compose来实现这一操作。具体实现如下图：</p>
<pre><code>scale = Rescale(256)
crop = RandomCrop(128)
composed = transforms.Compose([Rescale(256),
                               RandomCrop(224)])

# 在样本上应用上述的每个变换。
fig = plt.figure()
sample = face_dataset[65]
for i, tsfrm in enumerate([scale, crop, composed]):
    transformed_sample = tsfrm(sample)

    ax = plt.subplot(1, 3, i + 1)
    plt.tight_layout()
    ax.set_title(type(tsfrm).__name__)
    show_landmarks(**transformed_sample)

plt.show()</code></pre><p>输出效果：<br><img src= "/img/loading.gif" data-src="/images/p18.jpg"></p>
<h1 id="迭代数据集"><a href="#迭代数据集" class="headerlink" title="迭代数据集"></a>迭代数据集</h1><p>让我们把这些整合起来以创建一个带组合转换的数据集。总结一下，每次这个数据集被采样时:</p>
<p>及时地从文件中读取图片<br>对读取的图片应用转换<br>由于其中一步操作是随机的 (randomcrop) , 数据被增强了<br>我们可以像之前那样使用for i in range循环来对所有创建的数据集执行同样的操作。</p>
<pre><code>transformed_dataset = FaceLandmarksDataset(csv_file=&#39;data/faces/face_landmarks.csv&#39;,
                                           root_dir=&#39;data/faces/&#39;,
                                           transform=transforms.Compose([
                                               Rescale(256),
                                               RandomCrop(224),
                                               ToTensor()
                                           ]))

for i in range(len(transformed_dataset)):
    sample = transformed_dataset[i]

    print(i, sample[&#39;image&#39;].size(), sample[&#39;landmarks&#39;].size())

    if i == 3:
        break</code></pre><p>输出结果：</p>
<pre><code>0 torch.Size([3, 224, 224]) torch.Size([68, 2])
1 torch.Size([3, 224, 224]) torch.Size([68, 2])
2 torch.Size([3, 224, 224]) torch.Size([68, 2])
3 torch.Size([3, 224, 224]) torch.Size([68, 2])</code></pre><p>但是，对所有数据集简单的使用for循环牺牲了许多功能，尤其是:</p>
<p>批量处理数据<br>打乱数据<br>使用多线程multiprocessingworker 并行加载数据。<br>torch.utils.data.DataLoader是一个提供上述所有这些功能的迭代器。下面使用的参数必须是清楚的。一个值得关注的参数是collate_fn,可以通过它来决定如何对数据进行批处理。但是绝大多数情况下默认值就能运行良好。</p>
<pre><code>dataloader = DataLoader(transformed_dataset, batch_size=4,
                        shuffle=True, num_workers=4)


# 辅助功能：显示批次
def show_landmarks_batch(sample_batched):
    &quot;&quot;&quot;Show image with landmarks for a batch of samples.&quot;&quot;&quot;
    images_batch, landmarks_batch = \
            sample_batched[&#39;image&#39;], sample_batched[&#39;landmarks&#39;]
    batch_size = len(images_batch)
    im_size = images_batch.size(2)
    grid_border_size = 2

    grid = utils.make_grid(images_batch)
    plt.imshow(grid.numpy().transpose((1, 2, 0)))

    for i in range(batch_size):
        plt.scatter(landmarks_batch[i, :, 0].numpy() + i * im_size + (i + 1) * grid_border_size,
                    landmarks_batch[i, :, 1].numpy() + grid_border_size,
                    s=10, marker=&#39;.&#39;, c=&#39;r&#39;)

        plt.title(&#39;Batch from dataloader&#39;)

for i_batch, sample_batched in enumerate(dataloader):
    print(i_batch, sample_batched[&#39;image&#39;].size(),
          sample_batched[&#39;landmarks&#39;].size())

    # 观察第4批次并停止。
    if i_batch == 3:
        plt.figure()
        show_landmarks_batch(sample_batched)
        plt.axis(&#39;off&#39;)
        plt.ioff()
        plt.show()
        break</code></pre><p>输出</p>
<pre><code>0 torch.Size([4, 3, 224, 224]) torch.Size([4, 68, 2])
1 torch.Size([4, 3, 224, 224]) torch.Size([4, 68, 2])
2 torch.Size([4, 3, 224, 224]) torch.Size([4, 68, 2])
3 torch.Size([4, 3, 224, 224]) torch.Size([4, 68, 2])</code></pre><h1 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h1><p>在这篇教程中我们学习了如何构造和使用数据集类(datasets),转换(transforms)和数据加载器(dataloader)。torchvision包提供了常用的数据集类(datasets)和转换(transforms)。你可能不需要自己构造这些类。torchvision中还有一个更常用的数据集类ImageFolder。它假定了数据集是以如下方式构造的:</p>
<pre><code>root/ants/xxx.png
root/ants/xxy.jpeg
root/ants/xxz.png
.
.
.
root/bees/123.jpg
root/bees/nsdf3.png
root/bees/asd932_.png</code></pre><p>其中’ants’,bees’等是分类标签。在PIL.Image中你也可以使用类似的转换(transforms)例如</p>
<pre><code>RandomHorizontalFlip,Scale。利用这些你可以按如下的方式创建一个数据加载器(dataloader) :

import torch
from torchvision import transforms, datasets

data_transform = transforms.Compose([
        transforms.RandomSizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225])
    ])
hymenoptera_dataset = datasets.ImageFolder(root=&#39;hymenoptera_data/train&#39;,
                                           transform=data_transform)
dataset_loader = torch.utils.data.DataLoader(hymenoptera_dataset,
                                             batch_size=4, shuffle=True,
                                             num_workers=4)</code></pre><h1 id="学习交流"><a href="#学习交流" class="headerlink" title="学习交流"></a>学习交流</h1><p>为了方便大家更好地与作者进行沟通交流，为此针对这个专栏成立了QQ读者交流群，大家想近距离与我沟通，都可以来加入。<br>扫描二维码进群可获得 自动微分 章节的Python 源代码和Jupyter 源代码链接<br>扫描二维码进群可获得 神经网络 章节的Python 源代码和Jupyter 源代码链接<br>加入方式：扫描下方QQ群二维码，即可加入交流群&lt;群满可在右下方在线与我沟通&gt;。</p>
<p align="left">
    <img src= "/img/loading.gif" data-src="/images/qun.jpg" alt="Sample" width="300" height="350">
    <!-- <img src= "/img/loading.gif" data-src="/images/TIM.jpg" alt="Sample"  width="300" height="250"> -->
</p>]]></content>
      <categories>
        <category>PyTorch专栏</category>
      </categories>
      <tags>
        <tag>Python深度学习</tag>
      </tags>
  </entry>
</search>
